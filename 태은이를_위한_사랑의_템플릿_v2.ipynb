{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ══════════════════════════════════════════════════════════════\n",
    "# Cell 0: 설정\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "\"\"\"\n",
    "채권 금리 기술적 분석 시스템 — 통합 설정\n",
    "\n",
    "모든 사용자 설정을 이 셀에서 관리합니다.\n",
    "- 데이터 소스 / 분석 대상 / 기간\n",
    "- 상관분석 파라미터\n",
    "- 대시보드 오버레이 / 서브패널\n",
    "- 시그널 게이지 기간\n",
    "- 저장 경로 / 토글\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 1. 사용자 실행 설정 (★ 여기만 수정하세요 ★)\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class ExecutionConfig:\n",
    "    \"\"\"실행 시 사용자가 변경하는 설정\"\"\"\n",
    "\n",
    "    # ── 공통 ──\n",
    "    data_source: str = 'bond_ohlcv'\n",
    "    # 'bond_close' : Rates시트 종가만 (Tier 2)\n",
    "    # 'bond_ohlcv' : 국고지표정보 수익률 OHLCV (Tier 1b)\n",
    "    # 'futures_price' : 선물 가격 OHLCV (Tier 1a)\n",
    "    # 'futures_yield' : 선물 내재수익률 (Tier 1a, yield만)\n",
    "\n",
    "    target: str = '국고 3Y'\n",
    "    start_date: Optional[str] = None   # 'YYYY-MM-DD' 또는 None(전체)\n",
    "    end_date: Optional[str] = None\n",
    "\n",
    "    # ── 저장 ──\n",
    "    save_dir: Path = Path('output')\n",
    "    save_excel: bool = True\n",
    "    save_graphs: bool = True\n",
    "\n",
    "    # ── 상관분석 (Cell 3) ──\n",
    "    corr_columns: List[str] = field(default_factory=lambda: [\n",
    "        '국고채RF_3Y', '산금채AAA_5Y', '카드채AA+_3Y',\n",
    "    ])\n",
    "    corr_mode: str = 'spreads_changes'\n",
    "    # 'rates', 'rates_changes', 'spreads', 'spreads_changes',\n",
    "    # 'spreads_vs_ktb', 'spreads_vs_ktb_changes'\n",
    "\n",
    "    compare_columns: List[str] = field(default_factory=lambda: [\n",
    "        '국고채RF_3Y', '국고채RF_5Y', '국고채RF_10Y',\n",
    "        '카드채AA+_1Y', '카드채AA+_2Y', '카드채AA+_3Y',\n",
    "    ])\n",
    "    compare_start: Optional[str] = '2024-01-01'\n",
    "    compare_end: Optional[str] = None\n",
    "\n",
    "    rolling_window: int = 20   # 롤링 상관계수 윈도우\n",
    "\n",
    "    # ── 대시보드 (Cell 4) ──\n",
    "    show_special_charts: bool = True\n",
    "\n",
    "    # ── 시그널 (Cell 5) ──\n",
    "    gauge_short: int = 20     # 약 1개월\n",
    "    gauge_medium: int = 120   # 약 6개월\n",
    "    gauge_long: int = 250     # 약 1년\n",
    "\n",
    "\n",
    "# 전역 실행 설정 인스턴스\n",
    "CFG = ExecutionConfig()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 2. 파일 및 데이터 설정\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class DataConfig:\n",
    "    \"\"\"데이터 소스 관련 설정\"\"\"\n",
    "    file_path: Path = Path(\"TA_rawdata.xlsb\")\n",
    "    rates_sheet: str = \"Rates\"\n",
    "    spread_sheet: str = \"Spread\"\n",
    "    header_row: int = 4\n",
    "    data_start_row: int = 5\n",
    "    date_column: str = \"A\"\n",
    "    date_format: str = \"%Y-%m-%d\"\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 3. 컬럼명 파싱 규칙\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class ColumnParsingConfig:\n",
    "    known_sectors: Tuple[str, ...] = (\n",
    "        \"국고채\", \"통안채\", \"공사채\", \"은행채\", \"회사채\",\n",
    "        \"카드채\", \"캐피탈\", \"여전채\", \"지방채\", \"특수채\",\n",
    "        \"산금채\", \"수출입\", \"한전채\", \"도로공\", \"주금공\",\n",
    "        \"CD\", \"CP\", \"콜\", \"REPO\"\n",
    "    )\n",
    "    known_ratings: Tuple[str, ...] = (\n",
    "        \"AAA\", \"AA+\", \"AA0\", \"AA-\", \"AA\",\n",
    "        \"A+\", \"A0\", \"A-\", \"A\",\n",
    "        \"BBB+\", \"BBB0\", \"BBB-\", \"BBB\",\n",
    "        \"BB+\", \"BB0\", \"BB-\", \"BB\",\n",
    "        \"B+\", \"B0\", \"B-\", \"B\",\n",
    "        \"RF\", \"무등급\"\n",
    "    )\n",
    "    maturity_pattern: str = r\"(\\d+)(D|W|M|Y)\"\n",
    "    maturity_to_years: Dict[str, float] = field(default_factory=lambda: {\n",
    "        \"D\": 1/365, \"W\": 1/52, \"M\": 1/12, \"Y\": 1.0\n",
    "    })\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 4. 분석 파라미터\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class AnalysisConfig:\n",
    "    rolling_windows: Dict[str, int] = field(default_factory=lambda: {\n",
    "        \"short\": 20, \"medium\": 60, \"long\": 120\n",
    "    })\n",
    "    correlation_threshold: float = 0.7\n",
    "    min_observations: int = 30\n",
    "    coint_significance: float = 0.05\n",
    "    adf_max_lags: int = 12\n",
    "    zscore_entry_threshold: float = 2.0\n",
    "    zscore_exit_threshold: float = 0.5\n",
    "    lookback_period: int = 60\n",
    "    regime_window: int = 60\n",
    "    volatility_percentile: float = 0.75\n",
    "    max_lag: int = 20\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 5. 시각화 설정\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class VisualizationConfig:\n",
    "    figure_dpi: int = 100\n",
    "    figure_facecolor: str = \"white\"\n",
    "    figsize_single: Tuple[float, float] = (10, 6)\n",
    "    figsize_double: Tuple[float, float] = (12, 8)\n",
    "    figsize_multi: Tuple[float, float] = (14, 10)\n",
    "    figsize_heatmap: Tuple[float, float] = (12, 10)\n",
    "    colors: Dict[str, str] = field(default_factory=lambda: {\n",
    "        \"primary\": \"#1f77b4\", \"secondary\": \"#ff7f0e\",\n",
    "        \"positive\": \"#2ca02c\", \"negative\": \"#d62728\",\n",
    "        \"neutral\": \"#7f7f7f\", \"highlight\": \"#9467bd\",\n",
    "        \"background\": \"#f0f0f0\", \"grid\": \"#d0d0d0\",\n",
    "    })\n",
    "    line_colors: Tuple[str, ...] = (\n",
    "        \"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\",\n",
    "        \"#9467bd\", \"#8c564b\", \"#e377c2\", \"#7f7f7f\"\n",
    "    )\n",
    "    font_family: str = \"Malgun Gothic\"\n",
    "    font_size_title: int = 14\n",
    "    font_size_label: int = 11\n",
    "    font_size_tick: int = 9\n",
    "    font_size_legend: int = 9\n",
    "    font_size_annotation: int = 8\n",
    "    linewidth_main: float = 1.5\n",
    "    linewidth_secondary: float = 1.0\n",
    "    linewidth_reference: float = 0.8\n",
    "    linestyle_reference: str = \"--\"\n",
    "    grid_alpha: float = 0.3\n",
    "    grid_linestyle: str = \"-\"\n",
    "    grid_linewidth: float = 0.5\n",
    "    legend_loc: str = \"best\"\n",
    "    legend_frameon: bool = True\n",
    "    legend_framealpha: float = 0.9\n",
    "    tight_layout_pad: float = 2.0\n",
    "    subplot_hspace: float = 0.3\n",
    "    subplot_wspace: float = 0.3\n",
    "\n",
    "\n",
    "def apply_professional_style():\n",
    "    viz = VisualizationConfig()\n",
    "    plt.rcParams.update({\n",
    "        \"font.family\": viz.font_family,\n",
    "        \"font.size\": viz.font_size_tick,\n",
    "        \"axes.titlesize\": viz.font_size_title,\n",
    "        \"axes.labelsize\": viz.font_size_label,\n",
    "        \"xtick.labelsize\": viz.font_size_tick,\n",
    "        \"ytick.labelsize\": viz.font_size_tick,\n",
    "        \"legend.fontsize\": viz.font_size_legend,\n",
    "        \"figure.dpi\": viz.figure_dpi,\n",
    "        \"figure.facecolor\": viz.figure_facecolor,\n",
    "        \"figure.autolayout\": False,\n",
    "        \"axes.facecolor\": \"white\",\n",
    "        \"axes.edgecolor\": \"black\",\n",
    "        \"axes.linewidth\": 0.8,\n",
    "        \"axes.grid\": True,\n",
    "        \"axes.axisbelow\": True,\n",
    "        \"grid.alpha\": viz.grid_alpha,\n",
    "        \"grid.linestyle\": viz.grid_linestyle,\n",
    "        \"grid.linewidth\": viz.grid_linewidth,\n",
    "        \"grid.color\": viz.colors[\"grid\"],\n",
    "        \"lines.linewidth\": viz.linewidth_main,\n",
    "        \"lines.markersize\": 4,\n",
    "        \"legend.frameon\": viz.legend_frameon,\n",
    "        \"legend.framealpha\": viz.legend_framealpha,\n",
    "        \"legend.edgecolor\": \"black\",\n",
    "        \"xtick.direction\": \"out\",\n",
    "        \"ytick.direction\": \"out\",\n",
    "        \"xtick.major.size\": 4,\n",
    "        \"ytick.major.size\": 4,\n",
    "        \"axes.unicode_minus\": False,\n",
    "    })\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 6. 기술적 지표 설정\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class IndicatorConfig:\n",
    "    sma_periods: List[int] = field(default_factory=lambda: [5, 10, 20, 60, 120])\n",
    "    ema_periods: List[int] = field(default_factory=lambda: [12, 26])\n",
    "    bb_period: int = 20\n",
    "    bb_std: float = 2.0\n",
    "    macd_fast: int = 12\n",
    "    macd_slow: int = 26\n",
    "    macd_signal: int = 9\n",
    "    rsi_period: int = 14\n",
    "    stoch_k: int = 14\n",
    "    stoch_d: int = 3\n",
    "    stoch_smooth: int = 3\n",
    "    williams_period: int = 14\n",
    "    cci_period: int = 20\n",
    "    dmi_period: int = 14\n",
    "    atr_period: int = 14\n",
    "    chaikin_ema_period: int = 10\n",
    "    chaikin_roc_period: int = 10\n",
    "    ichimoku_tenkan: int = 9\n",
    "    ichimoku_kijun: int = 26\n",
    "    ichimoku_senkou_b: int = 52\n",
    "    sar_af_init: float = 0.02\n",
    "    sar_af_step: float = 0.02\n",
    "    sar_af_max: float = 0.20\n",
    "    dema_period: int = 20\n",
    "    t3_period: int = 5\n",
    "    t3_vfactor: float = 0.7\n",
    "    vidya_period: int = 20\n",
    "    sonar_period: int = 14\n",
    "    cmf_period: int = 21\n",
    "    mcclellan_short: int = 19\n",
    "    mcclellan_long: int = 39\n",
    "    three_line_break_lines: int = 3\n",
    "    pnf_box_size: float = 0.01\n",
    "    pnf_reversal: int = 3\n",
    "    rsi_overbought: float = 70.0\n",
    "    rsi_oversold: float = 30.0\n",
    "    stoch_overbought: float = 80.0\n",
    "    stoch_oversold: float = 20.0\n",
    "    cci_overbought: float = 100.0\n",
    "    cci_oversold: float = -100.0\n",
    "    williams_overbought: float = -20.0\n",
    "    williams_oversold: float = -80.0\n",
    "    gauge_short: int = 20\n",
    "    gauge_medium: int = 120\n",
    "    gauge_long: int = 250\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 7. OHLCV / 선물 설정\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class OHLCVConfig:\n",
    "    sheet_name: str = \"국고지표정보\"\n",
    "    instruments: Dict[str, int] = field(default_factory=lambda: {\n",
    "        \"국고 2Y\": 1, \"국고 3Y\": 27, \"국고 5Y\": 52, \"국고 10Y\": 77,\n",
    "        \"국고 20Y\": 102, \"국고 30Y\": 127, \"국고 50Y\": 152,\n",
    "        \"통안 2Y\": 177, \"통안 3Y\": 202,\n",
    "    })\n",
    "    date_col_offset: int = 0\n",
    "    block_size_first: int = 26\n",
    "    block_size_rest: int = 25\n",
    "    col_map_first: Dict[str, int] = field(default_factory=lambda: {\n",
    "        \"open\": 7, \"high\": 8, \"low\": 9, \"close\": 10,\n",
    "        \"close_eval\": 1, \"price\": 2, \"duration\": 3, \"net_volume\": 11,\n",
    "    })\n",
    "    col_map_rest: Dict[str, int] = field(default_factory=lambda: {\n",
    "        \"open\": 6, \"high\": 7, \"low\": 8, \"close\": 9,\n",
    "        \"close_eval\": 0, \"price\": 1, \"duration\": 2, \"net_volume\": 10,\n",
    "    })\n",
    "    header_row: int = 3\n",
    "    data_start_row: int = 4\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FuturesConfig:\n",
    "    sheet_name: str = \"Futures\"\n",
    "    instruments: Dict[str, int] = field(default_factory=lambda: {\n",
    "        \"3년국채 연결\": 1, \"5년국채 연결\": 51,\n",
    "        \"10년국채 연결\": 100, \"30년국채 연결\": 149,\n",
    "    })\n",
    "    block_size_first: int = 51\n",
    "    block_size_rest: int = 50\n",
    "    col_map_first: Dict[str, int] = field(default_factory=lambda: {\n",
    "        \"close\": 1, \"open\": 2, \"high\": 3, \"low\": 4, \"volume\": 5,\n",
    "        \"yield\": 6, \"settle\": 7, \"volatility\": 10, \"oi\": 21, \"duration\": 18,\n",
    "    })\n",
    "    col_map_rest: Dict[str, int] = field(default_factory=lambda: {\n",
    "        \"close\": 0, \"open\": 1, \"high\": 2, \"low\": 3, \"volume\": 4,\n",
    "        \"yield\": 5, \"settle\": 6, \"volatility\": 9, \"oi\": 20, \"duration\": 17,\n",
    "    })\n",
    "    header_row: int = 3\n",
    "    data_start_row: int = 4\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 8. 전역 설정 인스턴스\n",
    "# ============================================================================\n",
    "\n",
    "DATA_CONFIG = DataConfig()\n",
    "COLUMN_CONFIG = ColumnParsingConfig()\n",
    "ANALYSIS_CONFIG = AnalysisConfig()\n",
    "VIZ_CONFIG = VisualizationConfig()\n",
    "INDICATOR_CONFIG = IndicatorConfig()\n",
    "OHLCV_CONFIG = OHLCVConfig()\n",
    "FUTURES_CONFIG = FuturesConfig()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 9. 공통 차트 유틸리티\n",
    "# ============================================================================\n",
    "\n",
    "A4_PORTRAIT = (8.27, 11.69)    # inches (210mm x 297mm)\n",
    "A4_LANDSCAPE = (11.69, 8.27)   # inches (297mm x 210mm)\n",
    "\n",
    "CHART_STYLE = {\n",
    "    'linewidth': 0.75,\n",
    "    'grid_alpha': 0.3,\n",
    "    'grid_linewidth': 0.5,\n",
    "    'title_fontsize': 9,\n",
    "    'label_fontsize': 7,\n",
    "    'tick_fontsize': 6,\n",
    "    'legend_fontsize': 6,\n",
    "    'color_primary': 'black',\n",
    "    'color_secondary': '#1a5276',\n",
    "}\n",
    "\n",
    "\n",
    "def apply_chart_style(ax):\n",
    "    \"\"\"공통 차트 스타일 적용\"\"\"\n",
    "    ax.grid(True, alpha=CHART_STYLE['grid_alpha'], linewidth=CHART_STYLE['grid_linewidth'])\n",
    "    ax.tick_params(axis='both', labelsize=CHART_STYLE['tick_fontsize'])\n",
    "    for spine in ['top', 'right']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "\n",
    "\n",
    "def setup_date_axis(ax, dates):\n",
    "    \"\"\"기간 길이에 따른 자동 날짜 포맷\"\"\"\n",
    "    if len(dates) < 2:\n",
    "        return\n",
    "    span_days = (dates[-1] - dates[0]).days\n",
    "    if span_days <= 180:\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%y.%m.%d'))\n",
    "        ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "    elif span_days <= 730:\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%y.%m'))\n",
    "        ax.xaxis.set_major_locator(mdates.MonthLocator(interval=2))\n",
    "    else:\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%y.%m'))\n",
    "        ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "    ax.tick_params(axis='x', rotation=30, labelsize=CHART_STYLE['tick_fontsize'])\n",
    "\n",
    "\n",
    "# 스타일 적용\n",
    "apply_professional_style()\n",
    "\n",
    "print(\"Cell 0 완료: 설정 로딩\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ══════════════════════════════════════════════════════════════\n",
    "# Cell 1: 모듈 로딩 (유틸리티 + 엔진 + 렌더러 + 시그널)\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "\"\"\"\n",
    "통합 모듈: 데이터 로더, 전처리, 상관분석, 공적분, 시각화,\n",
    "         기술적 지표 엔진, 차트 렌더러, 시그널 분류\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.patches import Rectangle\n",
    "import re\n",
    "import warnings\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Optional, Dict, List, Tuple, Any, Union, Set\n",
    "from dataclasses import dataclass, field\n",
    "from functools import cached_property\n",
    "from enum import Enum\n",
    "from scipy import stats\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "try:\n",
    "    from statsmodels.tsa.stattools import adfuller, coint\n",
    "    from statsmodels.regression.linear_model import OLS\n",
    "    from statsmodels.tools import add_constant\n",
    "    HAS_STATSMODELS = True\n",
    "except ImportError:\n",
    "    HAS_STATSMODELS = False\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Part 1: pyxlsb 데이터 로더 유틸리티\n",
    "# ============================================================================\n",
    "\n",
    "def excel_serial_to_datetime(serial):\n",
    "    \"\"\"Excel 날짜 시리얼 번호를 datetime으로 변환\"\"\"\n",
    "    if serial is None:\n",
    "        return None\n",
    "    if isinstance(serial, str):\n",
    "        return None\n",
    "    try:\n",
    "        serial = float(serial)\n",
    "        if serial < 1 or serial > 100000:\n",
    "            return None\n",
    "        base = datetime(1899, 12, 30)\n",
    "        return base + timedelta(days=serial)\n",
    "    except (ValueError, TypeError, OverflowError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def read_xlsb_raw(file_path, sheet_name):\n",
    "    \"\"\"pyxlsb로 xlsb 시트의 전체 데이터를 행 리스트로 읽기\"\"\"\n",
    "    from pyxlsb import open_workbook\n",
    "    rows = []\n",
    "    with open_workbook(str(file_path)) as wb:\n",
    "        with wb.get_sheet(sheet_name) as ws:\n",
    "            for row in ws.rows():\n",
    "                rows.append(tuple(c.v for c in row))\n",
    "    return rows\n",
    "\n",
    "\n",
    "def read_rates_dataframe(file_path, sheet_name, header_row=4, data_start_row=5):\n",
    "    \"\"\"금리/스프레드 시트를 DataFrame으로 읽기\"\"\"\n",
    "    raw_rows = read_xlsb_raw(file_path, sheet_name)\n",
    "    if len(raw_rows) < data_start_row:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    header_idx = header_row - 1\n",
    "    headers = []\n",
    "    for i, v in enumerate(raw_rows[header_idx]):\n",
    "        if v is not None and str(v).strip():\n",
    "            headers.append(str(v).strip())\n",
    "        else:\n",
    "            headers.append(f'_col_{i}')\n",
    "\n",
    "    data_idx = data_start_row - 1\n",
    "    dates = []\n",
    "    data_rows = []\n",
    "\n",
    "    for row in raw_rows[data_idx:]:\n",
    "        if not row or row[0] is None:\n",
    "            continue\n",
    "        dt = excel_serial_to_datetime(row[0])\n",
    "        if dt is None:\n",
    "            continue\n",
    "        dates.append(pd.Timestamp(dt))\n",
    "        vals = []\n",
    "        for v in row[1:len(headers)]:\n",
    "            try:\n",
    "                vals.append(float(v) if v is not None else np.nan)\n",
    "            except (ValueError, TypeError):\n",
    "                vals.append(np.nan)\n",
    "        while len(vals) < len(headers) - 1:\n",
    "            vals.append(np.nan)\n",
    "        data_rows.append(vals)\n",
    "\n",
    "    if not dates:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df = pd.DataFrame(data_rows, index=pd.DatetimeIndex(dates, name='Date'),\n",
    "                      columns=headers[1:len(headers)])\n",
    "    df = df.sort_index()\n",
    "    df = df.dropna(how='all')\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_date_column(df, date_col):\n",
    "    \"\"\"DataFrame의 날짜 컬럼 변환\"\"\"\n",
    "    df = df.copy()\n",
    "    if date_col not in df.columns:\n",
    "        raise ValueError(f\"날짜 컬럼 '{date_col}'을 찾을 수 없습니다.\")\n",
    "    df[date_col] = df[date_col].apply(\n",
    "        lambda v: pd.Timestamp(excel_serial_to_datetime(v)) if not isinstance(v, (pd.Timestamp, datetime)) else v\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Part 2: 데이터 전처리 및 컬럼 파싱\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class BondInfo:\n",
    "    \"\"\"채권 정보 데이터 클래스\"\"\"\n",
    "    raw_name: str\n",
    "    sector: Optional[str] = None\n",
    "    rating: Optional[str] = None\n",
    "    maturity: Optional[str] = None\n",
    "    maturity_years: Optional[float] = None\n",
    "    is_bond: bool = False\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.is_bond:\n",
    "            return f\"{self.sector}({self.rating}) {self.maturity}\"\n",
    "        return self.raw_name\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"raw_name\": self.raw_name, \"sector\": self.sector,\n",
    "            \"rating\": self.rating, \"maturity\": self.maturity,\n",
    "            \"maturity_years\": self.maturity_years, \"is_bond\": self.is_bond\n",
    "        }\n",
    "\n",
    "\n",
    "class ColumnParser:\n",
    "    \"\"\"채권 컬럼명 파서\"\"\"\n",
    "\n",
    "    def __init__(self, config=None):\n",
    "        self.config = config or COLUMN_CONFIG\n",
    "        self._maturity_regex = re.compile(self.config.maturity_pattern)\n",
    "        self._sorted_sectors = sorted(self.config.known_sectors, key=len, reverse=True)\n",
    "        self._sorted_ratings = sorted(self.config.known_ratings, key=len, reverse=True)\n",
    "\n",
    "    def parse(self, column_name):\n",
    "        info = BondInfo(raw_name=column_name)\n",
    "        name = column_name.strip()\n",
    "\n",
    "        sector = None\n",
    "        remaining = name\n",
    "        for s in self._sorted_sectors:\n",
    "            if name.startswith(s):\n",
    "                sector = s\n",
    "                remaining = name[len(s):]\n",
    "                break\n",
    "        if sector is None:\n",
    "            return info\n",
    "        info.sector = sector\n",
    "\n",
    "        if \"_\" in remaining:\n",
    "            parts = remaining.split(\"_\", 1)\n",
    "            rating_part, maturity_part = parts[0], parts[1]\n",
    "        else:\n",
    "            match = re.search(r'\\d', remaining)\n",
    "            if match:\n",
    "                rating_part = remaining[:match.start()]\n",
    "                maturity_part = remaining[match.start():]\n",
    "            else:\n",
    "                rating_part, maturity_part = remaining, \"\"\n",
    "\n",
    "        rating = None\n",
    "        for r in self._sorted_ratings:\n",
    "            if rating_part.upper() == r.upper() or rating_part.startswith(r):\n",
    "                rating = r\n",
    "                break\n",
    "        if rating is None:\n",
    "            rating = rating_part if rating_part else \"무등급\"\n",
    "        info.rating = rating\n",
    "\n",
    "        maturity_match = self._maturity_regex.search(maturity_part)\n",
    "        if maturity_match:\n",
    "            num = int(maturity_match.group(1))\n",
    "            unit = maturity_match.group(2).upper()\n",
    "            info.maturity = f\"{num}{unit}\"\n",
    "            info.maturity_years = num * self.config.maturity_to_years.get(unit, 1.0)\n",
    "            info.is_bond = True\n",
    "        else:\n",
    "            info.maturity = maturity_part if maturity_part else None\n",
    "        return info\n",
    "\n",
    "    def parse_all(self, columns):\n",
    "        return {col: self.parse(col) for col in columns}\n",
    "\n",
    "    def parse_to_dataframe(self, columns):\n",
    "        parsed = self.parse_all(columns)\n",
    "        return pd.DataFrame([info.to_dict() for info in parsed.values()])\n",
    "\n",
    "\n",
    "class BondDataPreprocessor:\n",
    "    \"\"\"채권 데이터 전처리기\"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self._original_data = data.copy()\n",
    "        self._data = data.copy()\n",
    "        self._parser = ColumnParser()\n",
    "        self._column_info = self._parser.parse_all(data.columns.tolist())\n",
    "        self._info_df = self._parser.parse_to_dataframe(data.columns.tolist())\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._data.copy()\n",
    "\n",
    "    @property\n",
    "    def columns(self):\n",
    "        return self._data.columns.tolist()\n",
    "\n",
    "    @property\n",
    "    def column_info(self):\n",
    "        return self._info_df.copy()\n",
    "\n",
    "    @cached_property\n",
    "    def sectors(self):\n",
    "        return sorted(self._info_df[self._info_df[\"is_bond\"]][\"sector\"].unique())\n",
    "\n",
    "    @cached_property\n",
    "    def ratings(self):\n",
    "        return sorted(self._info_df[self._info_df[\"is_bond\"]][\"rating\"].unique())\n",
    "\n",
    "    @cached_property\n",
    "    def maturities(self):\n",
    "        df = self._info_df[self._info_df[\"is_bond\"]].copy()\n",
    "        df = df.sort_values(\"maturity_years\")\n",
    "        return df[\"maturity\"].unique().tolist()\n",
    "\n",
    "    def reset(self):\n",
    "        self._data = self._original_data.copy()\n",
    "        return self\n",
    "\n",
    "    def filter_bonds_only(self):\n",
    "        bond_cols = [col for col, info in self._column_info.items() if info.is_bond]\n",
    "        self._data = self._data[bond_cols]\n",
    "        return self\n",
    "\n",
    "    def filter_sector(self, sectors):\n",
    "        if isinstance(sectors, str):\n",
    "            sectors = [sectors]\n",
    "        cols = [col for col, info in self._column_info.items()\n",
    "                if info.sector in sectors and col in self._data.columns]\n",
    "        self._data = self._data[cols]\n",
    "        return self\n",
    "\n",
    "    def filter_rating(self, ratings):\n",
    "        if isinstance(ratings, str):\n",
    "            ratings = [ratings]\n",
    "        cols = [col for col, info in self._column_info.items()\n",
    "                if info.rating in ratings and col in self._data.columns]\n",
    "        self._data = self._data[cols]\n",
    "        return self\n",
    "\n",
    "    def filter_maturity(self, maturities=None, min_years=None, max_years=None):\n",
    "        if maturities is not None:\n",
    "            if isinstance(maturities, str):\n",
    "                maturities = [maturities]\n",
    "            cols = [col for col, info in self._column_info.items()\n",
    "                    if info.maturity in maturities and col in self._data.columns]\n",
    "        else:\n",
    "            cols = []\n",
    "            for col, info in self._column_info.items():\n",
    "                if col not in self._data.columns or not info.is_bond:\n",
    "                    continue\n",
    "                if info.maturity_years is None:\n",
    "                    continue\n",
    "                if min_years is not None and info.maturity_years < min_years:\n",
    "                    continue\n",
    "                if max_years is not None and info.maturity_years > max_years:\n",
    "                    continue\n",
    "                cols.append(col)\n",
    "        self._data = self._data[cols]\n",
    "        return self\n",
    "\n",
    "    def filter_date_range(self, start=None, end=None):\n",
    "        if start is not None:\n",
    "            self._data = self._data[self._data.index >= str(start)[:10]]\n",
    "        if end is not None:\n",
    "            self._data = self._data[self._data.index <= str(end)[:10]]\n",
    "        return self\n",
    "\n",
    "    def select_columns(self, columns):\n",
    "        valid_cols = [c for c in columns if c in self._data.columns]\n",
    "        self._data = self._data[valid_cols]\n",
    "        return self\n",
    "\n",
    "    def dropna(self, how=\"any\", thresh=None):\n",
    "        if thresh is not None:\n",
    "            self._data = self._data.dropna(thresh=thresh)\n",
    "        else:\n",
    "            self._data = self._data.dropna(how=how)\n",
    "        return self\n",
    "\n",
    "    def fillna(self, method=\"ffill\", limit=None):\n",
    "        if method == \"interpolate\":\n",
    "            self._data = self._data.interpolate(method=\"linear\", limit=limit)\n",
    "        elif method == \"ffill\":\n",
    "            self._data = self._data.ffill(limit=limit)\n",
    "        elif method == \"bfill\":\n",
    "            self._data = self._data.bfill(limit=limit)\n",
    "        else:\n",
    "            self._data = self._data.fillna(value=method)\n",
    "        return self\n",
    "\n",
    "    def get_data(self):\n",
    "        return self._data.copy()\n",
    "\n",
    "    def get_yield_curve(self, sector, rating=None, date=None):\n",
    "        prep = BondDataPreprocessor(self._original_data)\n",
    "        prep.filter_sector(sector)\n",
    "        if rating:\n",
    "            prep.filter_rating(rating)\n",
    "        data = prep.get_data()\n",
    "        if date is None:\n",
    "            date = data.index.max()\n",
    "        row = data.loc[date]\n",
    "        result = {}\n",
    "        for col in row.index:\n",
    "            info = self._column_info.get(col)\n",
    "            if info and info.maturity_years is not None:\n",
    "                result[info.maturity_years] = row[col]\n",
    "        curve = pd.Series(result).sort_index()\n",
    "        curve.name = f\"{sector} Yield Curve ({date})\"\n",
    "        return curve\n",
    "\n",
    "    def get_spread(self, col1, col2):\n",
    "        spread = self._original_data[col1] - self._original_data[col2]\n",
    "        spread.name = f\"{col1} - {col2}\"\n",
    "        return spread\n",
    "\n",
    "    def get_summary(self):\n",
    "        return self._data.describe()\n",
    "\n",
    "\n",
    "def create_spread_matrix(data, base_column):\n",
    "    \"\"\"기준 금리 대비 스프레드 매트릭스 생성\"\"\"\n",
    "    spread_df = data.sub(data[base_column], axis=0)\n",
    "    spread_df = spread_df.drop(columns=[base_column])\n",
    "    return spread_df\n",
    "\n",
    "\n",
    "def calculate_changes(data, periods=1):\n",
    "    \"\"\"금리 변화 계산 (bp 단위)\"\"\"\n",
    "    return data.diff(periods) * 100\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Part 3: 상관관계 분석\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class CorrelationResult:\n",
    "    correlation_matrix: pd.DataFrame\n",
    "    pvalue_matrix: pd.DataFrame\n",
    "    method: str\n",
    "    n_observations: int\n",
    "    start_date: pd.Timestamp\n",
    "    end_date: pd.Timestamp\n",
    "\n",
    "    def get_significant_pairs(self, threshold=0.7, pvalue_threshold=0.05):\n",
    "        pairs = []\n",
    "        cols = self.correlation_matrix.columns\n",
    "        n = len(cols)\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                corr = self.correlation_matrix.iloc[i, j]\n",
    "                pval = self.pvalue_matrix.iloc[i, j]\n",
    "                if abs(corr) >= threshold and pval <= pvalue_threshold:\n",
    "                    pairs.append({\"pair_1\": cols[i], \"pair_2\": cols[j],\n",
    "                                  \"correlation\": corr, \"p_value\": pval})\n",
    "        result = pd.DataFrame(pairs)\n",
    "        if not result.empty:\n",
    "            result = result.sort_values(\"correlation\", key=abs, ascending=False)\n",
    "        return result\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CrossCorrelationResult:\n",
    "    series1_name: str\n",
    "    series2_name: str\n",
    "    correlations: pd.Series\n",
    "    optimal_lag: int\n",
    "    max_correlation: float\n",
    "\n",
    "    def interpret(self):\n",
    "        if self.optimal_lag > 0:\n",
    "            return f\"'{self.series1_name}'이 '{self.series2_name}'를 {self.optimal_lag}일 선행\"\n",
    "        elif self.optimal_lag < 0:\n",
    "            return f\"'{self.series1_name}'이 '{self.series2_name}'를 {abs(self.optimal_lag)}일 후행\"\n",
    "        return \"동시 움직임\"\n",
    "\n",
    "\n",
    "class StaticCorrelationAnalyzer:\n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "\n",
    "    def calculate(self, method=\"pearson\", min_periods=None):\n",
    "        if min_periods is None:\n",
    "            min_periods = ANALYSIS_CONFIG.min_observations\n",
    "        corr_matrix = self.data.corr(method=method, min_periods=min_periods)\n",
    "        pval_matrix = self._calculate_pvalues(method)\n",
    "        return CorrelationResult(\n",
    "            correlation_matrix=corr_matrix, pvalue_matrix=pval_matrix,\n",
    "            method=method, n_observations=len(self.data),\n",
    "            start_date=self.data.index.min(), end_date=self.data.index.max()\n",
    "        )\n",
    "\n",
    "    def _calculate_pvalues(self, method):\n",
    "        cols = self.data.columns\n",
    "        n = len(cols)\n",
    "        pvals = np.ones((n, n))\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                mask = self.data[[cols[i], cols[j]]].notna().all(axis=1)\n",
    "                x, y = self.data.loc[mask, cols[i]], self.data.loc[mask, cols[j]]\n",
    "                if len(x) < 3:\n",
    "                    continue\n",
    "                if method == \"pearson\":\n",
    "                    _, pval = stats.pearsonr(x, y)\n",
    "                else:\n",
    "                    _, pval = stats.spearmanr(x, y)\n",
    "                pvals[i, j] = pvals[j, i] = pval\n",
    "        return pd.DataFrame(pvals, index=cols, columns=cols)\n",
    "\n",
    "    def find_most_correlated(self, column, n=5, method=\"pearson\"):\n",
    "        result = self.calculate(method)\n",
    "        corrs = result.correlation_matrix[column].drop(column)\n",
    "        top_n = corrs.abs().nlargest(n).index\n",
    "        return pd.DataFrame({\n",
    "            \"correlation\": corrs[top_n],\n",
    "            \"abs_correlation\": corrs[top_n].abs()\n",
    "        }).sort_values(\"abs_correlation\", ascending=False)\n",
    "\n",
    "\n",
    "class RollingCorrelationAnalyzer:\n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "\n",
    "    def calculate_pairwise(self, col1, col2, window=None, min_periods=None):\n",
    "        if window is None:\n",
    "            window = ANALYSIS_CONFIG.rolling_windows[\"medium\"]\n",
    "        if min_periods is None:\n",
    "            min_periods = window // 2\n",
    "        rolling_corr = self.data[col1].rolling(window=window, min_periods=min_periods).corr(self.data[col2])\n",
    "        rolling_corr.name = f\"Corr({col1}, {col2})\"\n",
    "        return rolling_corr\n",
    "\n",
    "    def calculate_multi_window(self, col1, col2):\n",
    "        result = pd.DataFrame(index=self.data.index)\n",
    "        for name, window in ANALYSIS_CONFIG.rolling_windows.items():\n",
    "            result[f\"{name}_{window}d\"] = self.calculate_pairwise(col1, col2, window)\n",
    "        return result\n",
    "\n",
    "    def find_regime_changes(self, col1, col2, window=None, threshold=0.3):\n",
    "        corr = self.calculate_pairwise(col1, col2, window)\n",
    "        daily_change = corr.diff()\n",
    "        weekly_change = corr.diff(5)\n",
    "        regime_changes = []\n",
    "        for date in corr.index:\n",
    "            d_change = abs(daily_change.get(date, 0))\n",
    "            w_change = abs(weekly_change.get(date, 0))\n",
    "            if d_change >= threshold or w_change >= threshold * 1.5:\n",
    "                regime_changes.append({\n",
    "                    \"date\": date, \"correlation\": corr[date],\n",
    "                    \"daily_change\": daily_change.get(date, np.nan),\n",
    "                    \"weekly_change\": weekly_change.get(date, np.nan)\n",
    "                })\n",
    "        return pd.DataFrame(regime_changes)\n",
    "\n",
    "\n",
    "class CrossCorrelationAnalyzer:\n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "\n",
    "    def calculate(self, col1, col2, max_lag=None):\n",
    "        if max_lag is None:\n",
    "            max_lag = ANALYSIS_CONFIG.max_lag\n",
    "        s1 = self.data[col1].dropna()\n",
    "        s2 = self.data[col2].dropna()\n",
    "        common_idx = s1.index.intersection(s2.index)\n",
    "        s1, s2 = s1.loc[common_idx], s2.loc[common_idx]\n",
    "        correlations = {}\n",
    "        for lag in range(-max_lag, max_lag + 1):\n",
    "            if lag > 0:\n",
    "                x, y = s1.iloc[:-lag], s2.iloc[lag:]\n",
    "            elif lag < 0:\n",
    "                x, y = s1.iloc[-lag:], s2.iloc[:lag]\n",
    "            else:\n",
    "                x, y = s1, s2\n",
    "            if len(x) > 2:\n",
    "                corr, _ = stats.pearsonr(x, y)\n",
    "                correlations[lag] = corr\n",
    "            else:\n",
    "                correlations[lag] = np.nan\n",
    "        corr_series = pd.Series(correlations)\n",
    "        optimal_lag = corr_series.abs().idxmax()\n",
    "        return CrossCorrelationResult(\n",
    "            series1_name=col1, series2_name=col2,\n",
    "            correlations=corr_series, optimal_lag=optimal_lag,\n",
    "            max_correlation=corr_series[optimal_lag]\n",
    "        )\n",
    "\n",
    "    def analyze_lead_lag_matrix(self, columns=None, max_lag=None):\n",
    "        if columns is None:\n",
    "            columns = self.data.columns.tolist()\n",
    "        if max_lag is None:\n",
    "            max_lag = ANALYSIS_CONFIG.max_lag\n",
    "        n = len(columns)\n",
    "        lag_matrix = pd.DataFrame(np.zeros((n, n)), index=columns, columns=columns)\n",
    "        for i, col1 in enumerate(columns):\n",
    "            for j, col2 in enumerate(columns):\n",
    "                if i >= j:\n",
    "                    continue\n",
    "                result = self.calculate(col1, col2, max_lag)\n",
    "                lag_matrix.iloc[i, j] = result.optimal_lag\n",
    "                lag_matrix.iloc[j, i] = -result.optimal_lag\n",
    "        return lag_matrix\n",
    "\n",
    "\n",
    "class CorrelationClusterer:\n",
    "    def __init__(self, correlation_matrix):\n",
    "        self.corr_matrix = correlation_matrix.copy()\n",
    "        self.distance_matrix = 1 - self.corr_matrix.abs()\n",
    "\n",
    "    def hierarchical_clustering(self, method=\"ward\", n_clusters=None, distance_threshold=None):\n",
    "        dist_array = squareform(self.distance_matrix.values)\n",
    "        linkage_matrix = hierarchy.linkage(dist_array, method=method)\n",
    "        if n_clusters is not None:\n",
    "            labels = hierarchy.fcluster(linkage_matrix, n_clusters, criterion=\"maxclust\")\n",
    "        elif distance_threshold is not None:\n",
    "            labels = hierarchy.fcluster(linkage_matrix, distance_threshold, criterion=\"distance\")\n",
    "        else:\n",
    "            labels = hierarchy.fcluster(linkage_matrix, 0.7, criterion=\"distance\")\n",
    "        columns = self.corr_matrix.columns.tolist()\n",
    "        return dict(zip(columns, labels))\n",
    "\n",
    "    def get_cluster_summary(self, cluster_labels):\n",
    "        df = pd.DataFrame({\"column\": list(cluster_labels.keys()),\n",
    "                           \"cluster\": list(cluster_labels.values())})\n",
    "        summaries = []\n",
    "        for cluster_id in df[\"cluster\"].unique():\n",
    "            members = df[df[\"cluster\"] == cluster_id][\"column\"].tolist()\n",
    "            if len(members) > 1:\n",
    "                sub_corr = self.corr_matrix.loc[members, members]\n",
    "                mask = ~np.eye(len(members), dtype=bool)\n",
    "                avg_corr = sub_corr.values[mask].mean()\n",
    "            else:\n",
    "                avg_corr = 1.0\n",
    "            summaries.append({\n",
    "                \"cluster\": cluster_id, \"n_members\": len(members),\n",
    "                \"avg_internal_corr\": avg_corr,\n",
    "                \"members\": \", \".join(members[:5]) + (\"...\" if len(members) > 5 else \"\")\n",
    "            })\n",
    "        return pd.DataFrame(summaries).sort_values(\"cluster\")\n",
    "\n",
    "\n",
    "class CorrelationAnalysisSuite:\n",
    "    \"\"\"상관관계 분석 통합 클래스\"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "        self._static_analyzer = StaticCorrelationAnalyzer(data)\n",
    "        self._rolling_analyzer = RollingCorrelationAnalyzer(data)\n",
    "        self._cross_analyzer = CrossCorrelationAnalyzer(data)\n",
    "\n",
    "    def static_correlation(self, method=\"pearson\"):\n",
    "        return self._static_analyzer.calculate(method)\n",
    "\n",
    "    def rolling_correlation(self, col1, col2, window=None):\n",
    "        return self._rolling_analyzer.calculate_pairwise(col1, col2, window)\n",
    "\n",
    "    def multi_window_correlation(self, col1, col2):\n",
    "        return self._rolling_analyzer.calculate_multi_window(col1, col2)\n",
    "\n",
    "    def cross_correlation(self, col1, col2, max_lag=None):\n",
    "        return self._cross_analyzer.calculate(col1, col2, max_lag)\n",
    "\n",
    "    def lead_lag_matrix(self, columns=None):\n",
    "        return self._cross_analyzer.analyze_lead_lag_matrix(columns)\n",
    "\n",
    "    def cluster_analysis(self, n_clusters=None, method=\"ward\"):\n",
    "        static = self.static_correlation()\n",
    "        clusterer = CorrelationClusterer(static.correlation_matrix)\n",
    "        labels = clusterer.hierarchical_clustering(method, n_clusters)\n",
    "        summary = clusterer.get_cluster_summary(labels)\n",
    "        return labels, summary\n",
    "\n",
    "    def comprehensive_analysis(self, pairs=None):\n",
    "        results = {}\n",
    "        static = self.static_correlation()\n",
    "        results[\"static_correlation\"] = static\n",
    "        results[\"significant_pairs\"] = static.get_significant_pairs()\n",
    "        labels, summary = self.cluster_analysis()\n",
    "        results[\"clusters\"] = labels\n",
    "        results[\"cluster_summary\"] = summary\n",
    "        if pairs is None:\n",
    "            sig_pairs = static.get_significant_pairs(threshold=0.8)\n",
    "            if not sig_pairs.empty:\n",
    "                pairs = list(zip(sig_pairs[\"pair_1\"][:5], sig_pairs[\"pair_2\"][:5]))\n",
    "            else:\n",
    "                pairs = []\n",
    "        pair_analyses = {}\n",
    "        for col1, col2 in pairs:\n",
    "            pair_analyses[f\"{col1}_vs_{col2}\"] = {\n",
    "                \"rolling\": self.multi_window_correlation(col1, col2),\n",
    "                \"cross_corr\": self.cross_correlation(col1, col2)\n",
    "            }\n",
    "        results[\"pair_analyses\"] = pair_analyses\n",
    "        return results\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Part 4: 공적분 검정 및 페어트레이딩\n",
    "# ============================================================================\n",
    "\n",
    "class SignalType(Enum):\n",
    "    LONG_SPREAD = \"long_spread\"\n",
    "    SHORT_SPREAD = \"short_spread\"\n",
    "    EXIT = \"exit\"\n",
    "    HOLD = \"hold\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class CointegrationTestResult:\n",
    "    series1_name: str\n",
    "    series2_name: str\n",
    "    test_statistic: float\n",
    "    p_value: float\n",
    "    critical_values: Dict[str, float]\n",
    "    alpha: float\n",
    "    beta: float\n",
    "    is_cointegrated: bool\n",
    "    confidence_level: str\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SpreadAnalysis:\n",
    "    spread: pd.Series\n",
    "    zscore: pd.Series\n",
    "    mean: float\n",
    "    std: float\n",
    "    current_zscore: float\n",
    "    half_life: Optional[float] = None\n",
    "    current_signal: SignalType = SignalType.HOLD\n",
    "\n",
    "\n",
    "def adf_test(series, max_lags=None, significance=0.05):\n",
    "    \"\"\"ADF 단위근 검정\"\"\"\n",
    "    if not HAS_STATSMODELS:\n",
    "        raise ImportError(\"statsmodels가 필요합니다.\")\n",
    "    series = series.dropna()\n",
    "    if max_lags is None:\n",
    "        max_lags = ANALYSIS_CONFIG.adf_max_lags\n",
    "    result = adfuller(series, maxlag=max_lags, autolag=\"AIC\")\n",
    "    test_stat, p_value, used_lag, nobs, crit_values, icbest = result\n",
    "    is_stationary = p_value < significance\n",
    "    if p_value < 0.01:\n",
    "        confidence = \"1%\"\n",
    "    elif p_value < 0.05:\n",
    "        confidence = \"5%\"\n",
    "    elif p_value < 0.10:\n",
    "        confidence = \"10%\"\n",
    "    else:\n",
    "        confidence = \"not significant\"\n",
    "    return {\n",
    "        \"test_statistic\": test_stat, \"p_value\": p_value,\n",
    "        \"used_lag\": used_lag, \"n_observations\": nobs,\n",
    "        \"critical_values\": dict(crit_values),\n",
    "        \"is_stationary\": is_stationary, \"confidence\": confidence\n",
    "    }\n",
    "\n",
    "\n",
    "class CointegrationTester:\n",
    "    def __init__(self, significance=None):\n",
    "        if not HAS_STATSMODELS:\n",
    "            raise ImportError(\"statsmodels가 필요합니다.\")\n",
    "        self.significance = significance or ANALYSIS_CONFIG.coint_significance\n",
    "\n",
    "    def test(self, series1, series2):\n",
    "        common_idx = series1.dropna().index.intersection(series2.dropna().index)\n",
    "        y, x = series1.loc[common_idx].values, series2.loc[common_idx].values\n",
    "        X = add_constant(x)\n",
    "        model = OLS(y, X).fit()\n",
    "        alpha, beta = model.params[0], model.params[1]\n",
    "        residuals = y - (alpha + beta * x)\n",
    "        adf_result = adf_test(pd.Series(residuals), significance=self.significance)\n",
    "        return CointegrationTestResult(\n",
    "            series1_name=series1.name or \"Series1\",\n",
    "            series2_name=series2.name or \"Series2\",\n",
    "            test_statistic=adf_result[\"test_statistic\"],\n",
    "            p_value=adf_result[\"p_value\"],\n",
    "            critical_values=adf_result[\"critical_values\"],\n",
    "            alpha=alpha, beta=beta,\n",
    "            is_cointegrated=adf_result[\"is_stationary\"],\n",
    "            confidence_level=adf_result[\"confidence\"]\n",
    "        )\n",
    "\n",
    "    def test_multiple(self, data, columns=None):\n",
    "        if columns is None:\n",
    "            columns = data.columns.tolist()\n",
    "        n = len(columns)\n",
    "        results = pd.DataFrame(np.ones((n, n)), index=columns, columns=columns)\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                try:\n",
    "                    result = self.test(data[columns[i]], data[columns[j]])\n",
    "                    results.iloc[i, j] = results.iloc[j, i] = result.p_value\n",
    "                except Exception:\n",
    "                    results.iloc[i, j] = results.iloc[j, i] = np.nan\n",
    "        return results\n",
    "\n",
    "    def find_cointegrated_pairs(self, data, columns=None):\n",
    "        if columns is None:\n",
    "            columns = data.columns.tolist()\n",
    "        pairs = []\n",
    "        for i in range(len(columns)):\n",
    "            for j in range(i + 1, len(columns)):\n",
    "                try:\n",
    "                    result = self.test(data[columns[i]], data[columns[j]])\n",
    "                    if result.is_cointegrated:\n",
    "                        pairs.append((columns[i], columns[j], result))\n",
    "                except Exception:\n",
    "                    continue\n",
    "        pairs.sort(key=lambda x: x[2].p_value)\n",
    "        return pairs\n",
    "\n",
    "\n",
    "class SpreadAnalyzer:\n",
    "    def __init__(self, lookback=None, entry_threshold=None, exit_threshold=None):\n",
    "        self.lookback = lookback or ANALYSIS_CONFIG.lookback_period\n",
    "        self.entry_threshold = entry_threshold or ANALYSIS_CONFIG.zscore_entry_threshold\n",
    "        self.exit_threshold = exit_threshold or ANALYSIS_CONFIG.zscore_exit_threshold\n",
    "\n",
    "    def calculate_spread(self, series1, series2, beta=None):\n",
    "        if beta is None:\n",
    "            beta = 1.0\n",
    "        common_idx = series1.dropna().index.intersection(series2.dropna().index)\n",
    "        spread = series1.loc[common_idx] - beta * series2.loc[common_idx]\n",
    "        spread.name = f\"Spread({series1.name}, {series2.name})\"\n",
    "        return spread\n",
    "\n",
    "    def analyze(self, series1, series2, coint_result=None):\n",
    "        if coint_result is not None:\n",
    "            beta, alpha = coint_result.beta, coint_result.alpha\n",
    "        else:\n",
    "            beta, alpha = 1.0, 0.0\n",
    "        common_idx = series1.dropna().index.intersection(series2.dropna().index)\n",
    "        spread = series1.loc[common_idx] - alpha - beta * series2.loc[common_idx]\n",
    "        spread.name = \"Spread\"\n",
    "        rolling_mean = spread.rolling(window=self.lookback).mean()\n",
    "        rolling_std = spread.rolling(window=self.lookback).std()\n",
    "        zscore = (spread - rolling_mean) / rolling_std\n",
    "        zscore.name = \"Z-score\"\n",
    "        current_zscore = zscore.iloc[-1] if not zscore.empty else np.nan\n",
    "        half_life = self._calculate_half_life(spread)\n",
    "        current_signal = self._determine_signal(current_zscore)\n",
    "        return SpreadAnalysis(\n",
    "            spread=spread, zscore=zscore, mean=spread.mean(),\n",
    "            std=spread.std(), current_zscore=current_zscore,\n",
    "            half_life=half_life, current_signal=current_signal\n",
    "        )\n",
    "\n",
    "    def _calculate_half_life(self, spread):\n",
    "        try:\n",
    "            spread = spread.dropna()\n",
    "            if len(spread) < 20:\n",
    "                return None\n",
    "            y = spread.diff().dropna()\n",
    "            x = spread.shift(1).dropna()\n",
    "            common_idx = y.index.intersection(x.index)\n",
    "            y, x = y.loc[common_idx], x.loc[common_idx] - spread.mean()\n",
    "            X = add_constant(x)\n",
    "            model = OLS(y, X).fit()\n",
    "            lambda_param = model.params[1]\n",
    "            if lambda_param >= 0:\n",
    "                return None\n",
    "            half_life = -np.log(2) / lambda_param\n",
    "            return half_life if half_life > 0 else None\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    def _determine_signal(self, zscore):\n",
    "        if np.isnan(zscore):\n",
    "            return SignalType.HOLD\n",
    "        if zscore > self.entry_threshold:\n",
    "            return SignalType.SHORT_SPREAD\n",
    "        elif zscore < -self.entry_threshold:\n",
    "            return SignalType.LONG_SPREAD\n",
    "        elif abs(zscore) < self.exit_threshold:\n",
    "            return SignalType.EXIT\n",
    "        return SignalType.HOLD\n",
    "\n",
    "    def generate_signals(self, spread_analysis):\n",
    "        zscore = spread_analysis.zscore.dropna()\n",
    "        spread = spread_analysis.spread\n",
    "        signals = []\n",
    "        for date in zscore.index:\n",
    "            z = zscore[date]\n",
    "            signal_type = self._determine_signal(z)\n",
    "            if signal_type == SignalType.LONG_SPREAD:\n",
    "                pos1, pos2, reason = \"long\", \"short\", f\"Z ({z:.2f}) < -{self.entry_threshold}\"\n",
    "            elif signal_type == SignalType.SHORT_SPREAD:\n",
    "                pos1, pos2, reason = \"short\", \"long\", f\"Z ({z:.2f}) > {self.entry_threshold}\"\n",
    "            elif signal_type == SignalType.EXIT:\n",
    "                pos1, pos2, reason = \"exit\", \"exit\", f\"|Z| ({abs(z):.2f}) < {self.exit_threshold}\"\n",
    "            else:\n",
    "                pos1, pos2, reason = \"hold\", \"hold\", \"No signal\"\n",
    "            signals.append({\"date\": date, \"signal\": signal_type.value,\n",
    "                            \"zscore\": z, \"spread\": spread.get(date, np.nan),\n",
    "                            \"position_1\": pos1, \"position_2\": pos2, \"reason\": reason})\n",
    "        return pd.DataFrame(signals).set_index(\"date\")\n",
    "\n",
    "\n",
    "class PairTradingStrategy:\n",
    "    \"\"\"페어트레이딩 전략 통합\"\"\"\n",
    "\n",
    "    def __init__(self, data, lookback=None, entry_threshold=None, exit_threshold=None):\n",
    "        self.data = data.copy()\n",
    "        self.coint_tester = CointegrationTester()\n",
    "        self.spread_analyzer = SpreadAnalyzer(lookback, entry_threshold, exit_threshold)\n",
    "\n",
    "    def analyze_pair(self, col1, col2):\n",
    "        series1, series2 = self.data[col1], self.data[col2]\n",
    "        coint_result = self.coint_tester.test(series1, series2)\n",
    "        spread_analysis = self.spread_analyzer.analyze(series1, series2, coint_result)\n",
    "        signals = self.spread_analyzer.generate_signals(spread_analysis)\n",
    "        summary = {\n",
    "            \"pair\": f\"{col1} vs {col2}\",\n",
    "            \"is_cointegrated\": coint_result.is_cointegrated,\n",
    "            \"p_value\": coint_result.p_value,\n",
    "            \"hedge_ratio\": coint_result.beta,\n",
    "            \"half_life\": spread_analysis.half_life,\n",
    "            \"current_zscore\": spread_analysis.current_zscore,\n",
    "            \"current_signal\": spread_analysis.current_signal.value,\n",
    "            \"n_entry_signals\": len(signals[signals[\"signal\"].isin([\"long_spread\", \"short_spread\"])])\n",
    "        }\n",
    "        return {\"cointegration\": coint_result, \"spread_analysis\": spread_analysis,\n",
    "                \"signals\": signals, \"summary\": summary}\n",
    "\n",
    "    def find_opportunities(self, columns=None, require_cointegration=True,\n",
    "                           min_half_life=5, max_half_life=60):\n",
    "        if columns is None:\n",
    "            columns = self.data.columns.tolist()\n",
    "        opportunities = []\n",
    "        for i in range(len(columns)):\n",
    "            for j in range(i + 1, len(columns)):\n",
    "                try:\n",
    "                    result = self.analyze_pair(columns[i], columns[j])\n",
    "                    summary = result[\"summary\"]\n",
    "                    if require_cointegration and not summary[\"is_cointegrated\"]:\n",
    "                        continue\n",
    "                    hl = summary[\"half_life\"]\n",
    "                    if hl is None or hl < min_half_life or hl > max_half_life:\n",
    "                        continue\n",
    "                    opportunities.append(summary)\n",
    "                except Exception:\n",
    "                    continue\n",
    "        df = pd.DataFrame(opportunities)\n",
    "        if not df.empty:\n",
    "            df = df.sort_values(\"half_life\")\n",
    "        return df\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Part 5: 시각화 유틸리티\n",
    "# ============================================================================\n",
    "\n",
    "def get_diverging_cmap(center_color=\"white\", low_color=\"#3b4cc0\", high_color=\"#b40426\"):\n",
    "    return LinearSegmentedColormap.from_list(\"diverging\", [low_color, center_color, high_color], N=256)\n",
    "\n",
    "\n",
    "def format_axis_date(ax, rotation=45):\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m\"))\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=3))\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=rotation, ha=\"right\")\n",
    "\n",
    "\n",
    "def plot_correlation_heatmap(corr_matrix, title=\"Correlation Matrix\", figsize=None,\n",
    "                              annot=True, cmap=None, vmin=-1, vmax=1,\n",
    "                              mask_diagonal=True, save_path=None):\n",
    "    if figsize is None:\n",
    "        figsize = VIZ_CONFIG.figsize_heatmap\n",
    "    if cmap is None or cmap == \"diverging\":\n",
    "        cmap = get_diverging_cmap()\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    data = corr_matrix.values.copy()\n",
    "    if mask_diagonal:\n",
    "        np.fill_diagonal(data, np.nan)\n",
    "    im = ax.imshow(data, cmap=cmap, vmin=vmin, vmax=vmax, aspect=\"auto\")\n",
    "    n = len(corr_matrix)\n",
    "    ax.set_xticks(range(n))\n",
    "    ax.set_yticks(range(n))\n",
    "    ax.set_xticklabels(corr_matrix.columns, rotation=45, ha=\"right\")\n",
    "    ax.set_yticklabels(corr_matrix.index)\n",
    "    if annot and n <= 15:\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if mask_diagonal and i == j:\n",
    "                    continue\n",
    "                val = corr_matrix.iloc[i, j]\n",
    "                color = \"white\" if abs(val) > 0.5 else \"black\"\n",
    "                ax.text(j, i, f\"{val:.2f}\", ha=\"center\", va=\"center\",\n",
    "                        color=color, fontsize=VIZ_CONFIG.font_size_annotation)\n",
    "    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label(\"Correlation\", fontsize=VIZ_CONFIG.font_size_label)\n",
    "    ax.set_title(title, fontsize=VIZ_CONFIG.font_size_title, pad=15)\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_time_series(data, columns=None, title=\"Interest Rates\", ylabel=\"Rate (%)\",\n",
    "                     figsize=None, colors=None, highlight_periods=None, save_path=None):\n",
    "    if figsize is None:\n",
    "        figsize = VIZ_CONFIG.figsize_single\n",
    "    if columns is None:\n",
    "        columns = data.columns.tolist()\n",
    "    if colors is None:\n",
    "        colors = list(VIZ_CONFIG.line_colors)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    for i, col in enumerate(columns):\n",
    "        ax.plot(data.index, data[col], label=col, color=colors[i % len(colors)],\n",
    "                linewidth=VIZ_CONFIG.linewidth_main)\n",
    "    if highlight_periods:\n",
    "        for start, end, label in highlight_periods:\n",
    "            ax.axvspan(start, end, alpha=0.2, color=\"gray\", label=label)\n",
    "    format_axis_date(ax)\n",
    "    ax.set_ylabel(ylabel, fontsize=VIZ_CONFIG.font_size_label)\n",
    "    ax.set_title(title, fontsize=VIZ_CONFIG.font_size_title)\n",
    "    ax.legend(loc=VIZ_CONFIG.legend_loc, fontsize=VIZ_CONFIG.font_size_legend,\n",
    "              frameon=VIZ_CONFIG.legend_frameon, framealpha=VIZ_CONFIG.legend_framealpha)\n",
    "    ax.grid(True, alpha=VIZ_CONFIG.grid_alpha, linestyle=VIZ_CONFIG.grid_linestyle,\n",
    "            linewidth=VIZ_CONFIG.grid_linewidth)\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches=\"tight\")\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Part 6: 확장 데이터 로더 (OHLCV, 선물)\n",
    "# ============================================================================\n",
    "\n",
    "class BondOHLCVLoader:\n",
    "    \"\"\"국고지표정보 파서\"\"\"\n",
    "\n",
    "    def __init__(self, config=None):\n",
    "        self.config = config or OHLCV_CONFIG\n",
    "        self._data = {}\n",
    "\n",
    "    def load_from_xlsb(self, file_path=None):\n",
    "        path = Path(file_path) if file_path else DATA_CONFIG.file_path\n",
    "        if not path.exists():\n",
    "            print(f\"[WARNING] 파일 없음: {path}\")\n",
    "            return {}\n",
    "        print(f\"  국고지표 로딩: {path.name} → {self.config.sheet_name}\")\n",
    "        raw_data = read_xlsb_raw(path, self.config.sheet_name)\n",
    "        n_rows = len(raw_data)\n",
    "        n_cols = len(raw_data[0]) if raw_data else 0\n",
    "        print(f\"  시트: {n_rows}행 × {n_cols}열\")\n",
    "        result = self._parse(raw_data)\n",
    "        self._data = result\n",
    "        if result:\n",
    "            print(f\"  국고지표 OHLCV 로딩: {len(result)}종목\")\n",
    "        return result\n",
    "\n",
    "    def _parse(self, raw_data):\n",
    "        data_start = self.config.data_start_row - 1\n",
    "        dates, valid_row_indices = [], []\n",
    "        for idx, row in enumerate(raw_data[data_start:], start=data_start):\n",
    "            val = row[0]\n",
    "            if val is None:\n",
    "                continue\n",
    "            dt = excel_serial_to_datetime(val)\n",
    "            if dt is None:\n",
    "                continue\n",
    "            dates.append(pd.Timestamp(dt))\n",
    "            valid_row_indices.append(idx)\n",
    "\n",
    "        n_rows = len(dates)\n",
    "        if n_rows == 0:\n",
    "            return {}\n",
    "\n",
    "        last_idx = valid_row_indices[-1]\n",
    "        last_row = raw_data[last_idx]\n",
    "        close_offset = self.config.col_map_first.get('close', 10)\n",
    "        if close_offset < len(last_row) and last_row[close_offset] is None:\n",
    "            n_rows -= 1\n",
    "            dates = dates[:n_rows]\n",
    "            valid_row_indices = valid_row_indices[:n_rows]\n",
    "        if n_rows == 0:\n",
    "            return {}\n",
    "\n",
    "        if len(dates) > 1 and dates[0] > dates[-1]:\n",
    "            dates = list(reversed(dates))\n",
    "            valid_row_indices = list(reversed(valid_row_indices))\n",
    "\n",
    "        date_index = pd.DatetimeIndex(dates)\n",
    "        data_rows = [raw_data[i] for i in valid_row_indices]\n",
    "\n",
    "        result = {}\n",
    "        for name, col_start in self.config.instruments.items():\n",
    "            is_first = (col_start == min(self.config.instruments.values()))\n",
    "            col_map = self.config.col_map_first if is_first else self.config.col_map_rest\n",
    "            df = pd.DataFrame(index=date_index)\n",
    "            df.index.name = '일자'\n",
    "            for field_name, offset in col_map.items():\n",
    "                col_idx = (col_start - 1) + offset\n",
    "                values = []\n",
    "                for row in data_rows:\n",
    "                    if col_idx < len(row):\n",
    "                        v = row[col_idx]\n",
    "                        values.append(None if isinstance(v, str) else v)\n",
    "                    else:\n",
    "                        values.append(None)\n",
    "                df[field_name] = pd.to_numeric(pd.Series(values, index=date_index), errors='coerce')\n",
    "            if 'close' in df.columns and 'close_eval' in df.columns:\n",
    "                df['close'] = df['close'].fillna(df['close_eval'])\n",
    "            if 'net_volume' in df.columns:\n",
    "                df['volume'] = df['net_volume'].abs()\n",
    "            result[name] = df\n",
    "\n",
    "        if n_rows > 0:\n",
    "            print(f\"  기간: {date_index[0].date()} ~ {date_index[-1].date()}, {n_rows}일\")\n",
    "        return result\n",
    "\n",
    "    def get(self, name):\n",
    "        return self._data.get(name)\n",
    "\n",
    "    def list_instruments(self):\n",
    "        return list(self._data.keys())\n",
    "\n",
    "\n",
    "class FuturesLoader:\n",
    "    \"\"\"국고선물정보 파서\"\"\"\n",
    "\n",
    "    def __init__(self, config=None):\n",
    "        self.config = config or FUTURES_CONFIG\n",
    "        self._data = {}\n",
    "\n",
    "    def load_from_xlsb(self, file_path=None):\n",
    "        path = Path(file_path) if file_path else DATA_CONFIG.file_path\n",
    "        if not path.exists():\n",
    "            print(f\"[WARNING] 파일 없음: {path}\")\n",
    "            return {}\n",
    "        print(f\"  국고선물 로딩: {path.name} → {self.config.sheet_name}\")\n",
    "        raw_data = read_xlsb_raw(path, self.config.sheet_name)\n",
    "        n_rows = len(raw_data)\n",
    "        n_cols = len(raw_data[0]) if raw_data else 0\n",
    "        print(f\"  시트: {n_rows}행 × {n_cols}열\")\n",
    "        result = self._parse(raw_data)\n",
    "        self._data = result\n",
    "        if result:\n",
    "            print(f\"  국고선물 OHLCV 로딩: {len(result)}종목\")\n",
    "        return result\n",
    "\n",
    "    def _parse(self, raw_data):\n",
    "        data_start = self.config.data_start_row - 1\n",
    "        dates, valid_row_indices = [], []\n",
    "        for idx, row in enumerate(raw_data[data_start:], start=data_start):\n",
    "            val = row[0]\n",
    "            if val is None:\n",
    "                continue\n",
    "            dt = excel_serial_to_datetime(val)\n",
    "            if dt is None:\n",
    "                continue\n",
    "            dates.append(pd.Timestamp(dt))\n",
    "            valid_row_indices.append(idx)\n",
    "\n",
    "        n_rows = len(dates)\n",
    "        if n_rows == 0:\n",
    "            return {}\n",
    "\n",
    "        last_idx = valid_row_indices[-1]\n",
    "        last_row = raw_data[last_idx]\n",
    "        close_offset = self.config.col_map_first.get('close', 1)\n",
    "        if close_offset < len(last_row) and last_row[close_offset] is None:\n",
    "            n_rows -= 1\n",
    "            dates = dates[:n_rows]\n",
    "            valid_row_indices = valid_row_indices[:n_rows]\n",
    "        if n_rows == 0:\n",
    "            return {}\n",
    "\n",
    "        if len(dates) > 1 and dates[0] > dates[-1]:\n",
    "            dates = list(reversed(dates))\n",
    "            valid_row_indices = list(reversed(valid_row_indices))\n",
    "\n",
    "        date_index = pd.DatetimeIndex(dates)\n",
    "        data_rows = [raw_data[i] for i in valid_row_indices]\n",
    "\n",
    "        result = {}\n",
    "        for name, col_start in self.config.instruments.items():\n",
    "            is_first = (col_start == min(self.config.instruments.values()))\n",
    "            col_map = self.config.col_map_first if is_first else self.config.col_map_rest\n",
    "            df = pd.DataFrame(index=date_index)\n",
    "            df.index.name = '일자'\n",
    "            for field_name, offset in col_map.items():\n",
    "                col_idx = (col_start - 1) + offset\n",
    "                values = []\n",
    "                for row in data_rows:\n",
    "                    if col_idx < len(row):\n",
    "                        v = row[col_idx]\n",
    "                        values.append(None if isinstance(v, str) else v)\n",
    "                    else:\n",
    "                        values.append(None)\n",
    "                df[field_name] = pd.to_numeric(pd.Series(values, index=date_index), errors='coerce')\n",
    "            if 'close' in df.columns and 'settle' in df.columns:\n",
    "                df['close'] = df['close'].fillna(df['settle'])\n",
    "            result[name] = df\n",
    "\n",
    "        if n_rows > 0:\n",
    "            print(f\"  기간: {date_index[0].date()} ~ {date_index[-1].date()}, {n_rows}일\")\n",
    "        return result\n",
    "\n",
    "    def get(self, name):\n",
    "        return self._data.get(name)\n",
    "\n",
    "    def list_instruments(self):\n",
    "        return list(self._data.keys())\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataTier:\n",
    "    tier: str\n",
    "    has_ohlc: bool\n",
    "    has_volume: bool\n",
    "    source: str\n",
    "    available_indicators: int\n",
    "\n",
    "\n",
    "class DataTierDetector:\n",
    "    \"\"\"종목별 데이터 가용성 판별\"\"\"\n",
    "\n",
    "    def __init__(self, bond_ohlcv_loader, futures_loader):\n",
    "        self.bond_ohlcv = bond_ohlcv_loader\n",
    "        self.futures = futures_loader\n",
    "        self.futures_map = {\n",
    "            '3년국채 연결': '국고 3Y', '5년국채 연결': '국고 5Y',\n",
    "            '10년국채 연결': '국고 10Y', '30년국채 연결': '국고 30Y',\n",
    "        }\n",
    "\n",
    "    def detect(self, name):\n",
    "        for fut_name in self.futures.list_instruments():\n",
    "            if fut_name == name or self.futures_map.get(fut_name) == name:\n",
    "                return DataTier(tier='1a', has_ohlc=True, has_volume=True,\n",
    "                                source='futures', available_indicators=29)\n",
    "        if name in self.bond_ohlcv.list_instruments():\n",
    "            return DataTier(tier='1b', has_ohlc=True, has_volume=True,\n",
    "                            source='bond_ohlcv', available_indicators=25)\n",
    "        return DataTier(tier='2', has_ohlc=False, has_volume=False,\n",
    "                        source='bond_close', available_indicators=13)\n",
    "\n",
    "    def get_ohlcv(self, name, mode='auto', source_preference=None):\n",
    "        \"\"\"\n",
    "        종목의 OHLCV 데이터 반환 (통합 인터페이스)\n",
    "\n",
    "        Args:\n",
    "            name: 종목명\n",
    "            mode: 'auto' | 'price' | 'yield'\n",
    "            source_preference: 'bond_ohlcv' | 'futures' | None\n",
    "                               None이면 detect() 결과 사용\n",
    "        \"\"\"\n",
    "        # source_preference가 지정되면 detect() 우회\n",
    "        if source_preference == 'bond_ohlcv':\n",
    "            raw = self.bond_ohlcv.get(name)\n",
    "            if raw is not None:\n",
    "                df = pd.DataFrame(index=raw.index)\n",
    "                df['open'] = raw['open']\n",
    "                df['high'] = raw['high']\n",
    "                df['low'] = raw['low']\n",
    "                df['close'] = raw['close']\n",
    "                df['volume'] = raw.get('volume', pd.Series(dtype=float))\n",
    "                return df\n",
    "            return None\n",
    "\n",
    "        tier = self.detect(name)\n",
    "\n",
    "        if tier.source == 'futures':\n",
    "            fut_name = name\n",
    "            for fn, sn in self.futures_map.items():\n",
    "                if sn == name:\n",
    "                    fut_name = fn\n",
    "                    break\n",
    "            raw = self.futures.get(fut_name)\n",
    "            if raw is None:\n",
    "                return None\n",
    "            if mode == 'yield':\n",
    "                df = pd.DataFrame(index=raw.index)\n",
    "                df['close'] = raw['yield']\n",
    "                df['open'] = df['close']\n",
    "                df['high'] = df['close']\n",
    "                df['low'] = df['close']\n",
    "                df['volume'] = raw.get('volume', pd.Series(dtype=float))\n",
    "                return df\n",
    "            else:\n",
    "                df = pd.DataFrame(index=raw.index)\n",
    "                df['open'] = raw['open']\n",
    "                df['high'] = raw['high']\n",
    "                df['low'] = raw['low']\n",
    "                df['close'] = raw['close']\n",
    "                df['volume'] = raw.get('volume', pd.Series(dtype=float))\n",
    "                return df\n",
    "        elif tier.source == 'bond_ohlcv':\n",
    "            raw = self.bond_ohlcv.get(name)\n",
    "            if raw is None:\n",
    "                return None\n",
    "            df = pd.DataFrame(index=raw.index)\n",
    "            df['open'] = raw['open']\n",
    "            df['high'] = raw['high']\n",
    "            df['low'] = raw['low']\n",
    "            df['close'] = raw['close']\n",
    "            df['volume'] = raw.get('volume', pd.Series(dtype=float))\n",
    "            return df\n",
    "        return None\n",
    "\n",
    "    def summary(self):\n",
    "        rows = []\n",
    "        all_names = list(self.bond_ohlcv.list_instruments())\n",
    "        for fn in self.futures.list_instruments():\n",
    "            mapped = self.futures_map.get(fn, fn)\n",
    "            if mapped not in all_names:\n",
    "                all_names.append(mapped)\n",
    "        for name in sorted(all_names):\n",
    "            t = self.detect(name)\n",
    "            rows.append({\n",
    "                '종목': name, '티어': t.tier, 'OHLC': t.has_ohlc,\n",
    "                '거래량': t.has_volume, '소스': t.source, '지표수': t.available_indicators\n",
    "            })\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Part 7: 가격 + 추세 지표 엔진\n",
    "# ============================================================================\n",
    "\n",
    "class PriceTrendEngine:\n",
    "    \"\"\"가격 및 추세 지표 계산 엔진\"\"\"\n",
    "\n",
    "    def __init__(self, config=None):\n",
    "        self.cfg = config or INDICATOR_CONFIG\n",
    "\n",
    "    def sma(self, series, period=None):\n",
    "        n = period or self.cfg.sma_periods[2]\n",
    "        return series.rolling(window=n, min_periods=1).mean()\n",
    "\n",
    "    def ema(self, series, period=20):\n",
    "        return series.ewm(span=period, adjust=False).mean()\n",
    "\n",
    "    def dema(self, series, period=None):\n",
    "        n = period or self.cfg.dema_period\n",
    "        ema1 = self.ema(series, n)\n",
    "        ema2 = self.ema(ema1, n)\n",
    "        return 2 * ema1 - ema2\n",
    "\n",
    "    def t3(self, series, period=None, vfactor=None):\n",
    "        n = period or self.cfg.t3_period\n",
    "        v = vfactor or self.cfg.t3_vfactor\n",
    "        def _gd(s):\n",
    "            e1 = self.ema(s, n)\n",
    "            e2 = self.ema(e1, n)\n",
    "            return e1 * (1 + v) - e2 * v\n",
    "        return _gd(_gd(_gd(series)))\n",
    "\n",
    "    def vidya(self, series, period=None):\n",
    "        n = period or self.cfg.vidya_period\n",
    "        diff = series.diff()\n",
    "        up = diff.clip(lower=0).rolling(n).sum()\n",
    "        down = (-diff.clip(upper=0)).rolling(n).sum()\n",
    "        cmo = ((up - down) / (up + down)).abs()\n",
    "        sc = 2.0 / (n + 1)\n",
    "        result = series.copy()\n",
    "        for i in range(n, len(series)):\n",
    "            if pd.notna(cmo.iloc[i]):\n",
    "                alpha = sc * cmo.iloc[i]\n",
    "                result.iloc[i] = alpha * series.iloc[i] + (1 - alpha) * result.iloc[i - 1]\n",
    "        return result\n",
    "\n",
    "    def vwma(self, close, volume, period=None):\n",
    "        n = period or self.cfg.sma_periods[2]\n",
    "        vol_price = (close * volume).rolling(n, min_periods=1).sum()\n",
    "        vol_sum = volume.rolling(n, min_periods=1).sum()\n",
    "        return vol_price / vol_sum.replace(0, np.nan)\n",
    "\n",
    "    def bollinger_bands(self, series, period=None, std_mult=None):\n",
    "        n = period or self.cfg.bb_period\n",
    "        k = std_mult or self.cfg.bb_std\n",
    "        mid = series.rolling(n, min_periods=1).mean()\n",
    "        std = series.rolling(n, min_periods=1).std()\n",
    "        return {\n",
    "            'middle': mid, 'upper': mid + k * std, 'lower': mid - k * std,\n",
    "            'bandwidth': (2 * k * std) / mid * 100,\n",
    "            'pctb': (series - (mid - k * std)) / (2 * k * std),\n",
    "        }\n",
    "\n",
    "    def ichimoku(self, high, low, close):\n",
    "        t, k, sb = self.cfg.ichimoku_tenkan, self.cfg.ichimoku_kijun, self.cfg.ichimoku_senkou_b\n",
    "        tenkan = (high.rolling(t).max() + low.rolling(t).min()) / 2\n",
    "        kijun = (high.rolling(k).max() + low.rolling(k).min()) / 2\n",
    "        senkou_a = ((tenkan + kijun) / 2).shift(k)\n",
    "        senkou_b = ((high.rolling(sb).max() + low.rolling(sb).min()) / 2).shift(k)\n",
    "        chikou = close.shift(-k)\n",
    "        return {'tenkan': tenkan, 'kijun': kijun, 'senkou_a': senkou_a,\n",
    "                'senkou_b': senkou_b, 'chikou': chikou}\n",
    "\n",
    "    def parabolic_sar(self, high, low):\n",
    "        af_init, af_step, af_max = self.cfg.sar_af_init, self.cfg.sar_af_step, self.cfg.sar_af_max\n",
    "        n = len(high)\n",
    "        sar = pd.Series(np.nan, index=high.index)\n",
    "        af = af_init\n",
    "        is_long = True\n",
    "        ep = low.iloc[0]\n",
    "        sar_val = high.iloc[0]\n",
    "        for i in range(2, n):\n",
    "            if is_long:\n",
    "                sar_val = sar_val + af * (ep - sar_val)\n",
    "                sar_val = min(sar_val, low.iloc[i - 1], low.iloc[i - 2])\n",
    "                if low.iloc[i] < sar_val:\n",
    "                    is_long, sar_val, ep, af = False, ep, low.iloc[i], af_init\n",
    "                elif high.iloc[i] > ep:\n",
    "                    ep = high.iloc[i]\n",
    "                    af = min(af + af_step, af_max)\n",
    "            else:\n",
    "                sar_val = sar_val + af * (ep - sar_val)\n",
    "                sar_val = max(sar_val, high.iloc[i - 1], high.iloc[i - 2])\n",
    "                if high.iloc[i] > sar_val:\n",
    "                    is_long, sar_val, ep, af = True, ep, high.iloc[i], af_init\n",
    "                elif low.iloc[i] < ep:\n",
    "                    ep = low.iloc[i]\n",
    "                    af = min(af + af_step, af_max)\n",
    "            sar.iloc[i] = sar_val\n",
    "        return sar\n",
    "\n",
    "    def dmi(self, high, low, close, period=None):\n",
    "        n = period or self.cfg.dmi_period\n",
    "        tr1 = high - low\n",
    "        tr2 = (high - close.shift(1)).abs()\n",
    "        tr3 = (low - close.shift(1)).abs()\n",
    "        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "        up_move = high - high.shift(1)\n",
    "        down_move = low.shift(1) - low\n",
    "        plus_dm = pd.Series(np.where((up_move > down_move) & (up_move > 0), up_move, 0), index=high.index)\n",
    "        minus_dm = pd.Series(np.where((down_move > up_move) & (down_move > 0), down_move, 0), index=high.index)\n",
    "        atr = tr.ewm(alpha=1/n, adjust=False).mean()\n",
    "        plus_di = 100 * plus_dm.ewm(alpha=1/n, adjust=False).mean() / atr\n",
    "        minus_di = 100 * minus_dm.ewm(alpha=1/n, adjust=False).mean() / atr\n",
    "        dx = 100 * (plus_di - minus_di).abs() / (plus_di + minus_di).replace(0, np.nan)\n",
    "        adx = dx.ewm(alpha=1/n, adjust=False).mean()\n",
    "        return {'plus_di': plus_di, 'minus_di': minus_di, 'adx': adx, 'dx': dx}\n",
    "\n",
    "    def cci(self, high, low, close, period=None):\n",
    "        n = period or self.cfg.cci_period\n",
    "        tp = (high + low + close) / 3\n",
    "        ma = tp.rolling(n).mean()\n",
    "        md = tp.rolling(n).apply(lambda x: np.abs(x - x.mean()).mean(), raw=True)\n",
    "        return (tp - ma) / (0.015 * md)\n",
    "\n",
    "    def macd(self, series, fast=None, slow=None, signal=None):\n",
    "        f = fast or self.cfg.macd_fast\n",
    "        s = slow or self.cfg.macd_slow\n",
    "        sig = signal or self.cfg.macd_signal\n",
    "        ema_fast = self.ema(series, f)\n",
    "        ema_slow = self.ema(series, s)\n",
    "        macd_line = ema_fast - ema_slow\n",
    "        signal_line = self.ema(macd_line, sig)\n",
    "        return {'macd': macd_line, 'signal': signal_line, 'histogram': macd_line - signal_line}\n",
    "\n",
    "    def sonar(self, series, period=None):\n",
    "        n = period or self.cfg.sonar_period\n",
    "        e = self.ema(series, n)\n",
    "        return e - e.shift(n)\n",
    "\n",
    "    def compute_all(self, df, tier='1a'):\n",
    "        result = {}\n",
    "        close = df['close']\n",
    "        for n in self.cfg.sma_periods:\n",
    "            result[f'SMA_{n}'] = self.sma(close, n)\n",
    "        result['DEMA'] = self.dema(close)\n",
    "        result['T3'] = self.t3(close)\n",
    "        result['VIDYA'] = self.vidya(close)\n",
    "        macd_r = self.macd(close)\n",
    "        result['MACD'] = macd_r['macd']\n",
    "        result['MACD_signal'] = macd_r['signal']\n",
    "        result['MACD_hist'] = macd_r['histogram']\n",
    "        result['SONAR'] = self.sonar(close)\n",
    "        bb = self.bollinger_bands(close)\n",
    "        result['BB_upper'] = bb['upper']\n",
    "        result['BB_middle'] = bb['middle']\n",
    "        result['BB_lower'] = bb['lower']\n",
    "        result['BB_bandwidth'] = bb['bandwidth']\n",
    "        result['BB_pctb'] = bb['pctb']\n",
    "        if tier in ('1a', '1b'):\n",
    "            high, low = df['high'], df['low']\n",
    "            ichi = self.ichimoku(high, low, close)\n",
    "            for k, v in ichi.items():\n",
    "                result[f'Ichimoku_{k}'] = v\n",
    "            result['Parabolic_SAR'] = self.parabolic_sar(high, low)\n",
    "            dmi_r = self.dmi(high, low, close)\n",
    "            for k, v in dmi_r.items():\n",
    "                result[f'DMI_{k}'] = v\n",
    "            result['CCI'] = self.cci(high, low, close)\n",
    "            if 'volume' in df.columns and df['volume'].notna().any():\n",
    "                result['VWMA'] = self.vwma(close, df['volume'])\n",
    "        return result\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Part 8: 변동성 + 모멘텀 지표 엔진\n",
    "# ============================================================================\n",
    "\n",
    "class VolatilityMomentumEngine:\n",
    "    \"\"\"변동성 및 모멘텀 지표 계산 엔진\"\"\"\n",
    "\n",
    "    def __init__(self, config=None):\n",
    "        self.cfg = config or INDICATOR_CONFIG\n",
    "\n",
    "    def true_range(self, high, low, close):\n",
    "        tr1 = high - low\n",
    "        tr2 = (high - close.shift(1)).abs()\n",
    "        tr3 = (low - close.shift(1)).abs()\n",
    "        return pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
    "\n",
    "    def atr(self, high, low, close, period=None):\n",
    "        n = period or self.cfg.atr_period\n",
    "        return self.true_range(high, low, close).ewm(alpha=1/n, adjust=False).mean()\n",
    "\n",
    "    def chaikin_volatility(self, high, low, ema_period=None, roc_period=None):\n",
    "        ep = ema_period or self.cfg.chaikin_ema_period\n",
    "        rp = roc_period or self.cfg.chaikin_roc_period\n",
    "        hl_ema = (high - low).ewm(span=ep, adjust=False).mean()\n",
    "        return ((hl_ema - hl_ema.shift(rp)) / hl_ema.shift(rp).replace(0, np.nan)) * 100\n",
    "\n",
    "    def stochastic(self, high, low, close, k_period=None, d_period=None, smooth=None):\n",
    "        kp = k_period or self.cfg.stoch_k\n",
    "        dp = d_period or self.cfg.stoch_d\n",
    "        sm = smooth or self.cfg.stoch_smooth\n",
    "        lowest = low.rolling(kp).min()\n",
    "        highest = high.rolling(kp).max()\n",
    "        fast_k = ((close - lowest) / (highest - lowest).replace(0, np.nan)) * 100\n",
    "        k = fast_k.rolling(sm).mean()\n",
    "        d = k.rolling(dp).mean()\n",
    "        return {'k': k, 'd': d, 'fast_k': fast_k}\n",
    "\n",
    "    def rsi(self, series, period=None):\n",
    "        n = period or self.cfg.rsi_period\n",
    "        delta = series.diff()\n",
    "        gain = delta.clip(lower=0)\n",
    "        loss = (-delta.clip(upper=0))\n",
    "        avg_gain = gain.ewm(alpha=1/n, adjust=False).mean()\n",
    "        avg_loss = loss.ewm(alpha=1/n, adjust=False).mean()\n",
    "        rs = avg_gain / avg_loss.replace(0, np.nan)\n",
    "        return 100 - (100 / (1 + rs))\n",
    "\n",
    "    def williams_r(self, high, low, close, period=None):\n",
    "        n = period or self.cfg.williams_period\n",
    "        highest = high.rolling(n).max()\n",
    "        lowest = low.rolling(n).min()\n",
    "        return ((highest - close) / (highest - lowest).replace(0, np.nan)) * -100\n",
    "\n",
    "    def stochastic_close_only(self, close, k_period=None):\n",
    "        kp = k_period or self.cfg.stoch_k\n",
    "        dp, sm = self.cfg.stoch_d, self.cfg.stoch_smooth\n",
    "        lowest = close.rolling(kp).min()\n",
    "        highest = close.rolling(kp).max()\n",
    "        fast_k = ((close - lowest) / (highest - lowest).replace(0, np.nan)) * 100\n",
    "        k = fast_k.rolling(sm).mean()\n",
    "        d = k.rolling(dp).mean()\n",
    "        return {'k': k, 'd': d, 'fast_k': fast_k}\n",
    "\n",
    "    def williams_r_close_only(self, close, period=None):\n",
    "        n = period or self.cfg.williams_period\n",
    "        highest = close.rolling(n).max()\n",
    "        lowest = close.rolling(n).min()\n",
    "        return ((highest - close) / (highest - lowest).replace(0, np.nan)) * -100\n",
    "\n",
    "    def compute_all(self, df, tier='1a'):\n",
    "        result = {}\n",
    "        close = df['close']\n",
    "        result['RSI'] = self.rsi(close)\n",
    "        if tier in ('1a', '1b'):\n",
    "            high, low = df['high'], df['low']\n",
    "            result['ATR'] = self.atr(high, low, close)\n",
    "            result['Chaikin_Vol'] = self.chaikin_volatility(high, low)\n",
    "            stoch = self.stochastic(high, low, close)\n",
    "            result['Stoch_K'] = stoch['k']\n",
    "            result['Stoch_D'] = stoch['d']\n",
    "            result['Williams_R'] = self.williams_r(high, low, close)\n",
    "        else:\n",
    "            stoch = self.stochastic_close_only(close)\n",
    "            result['Stoch_K'] = stoch['k']\n",
    "            result['Stoch_D'] = stoch['d']\n",
    "            result['Williams_R'] = self.williams_r_close_only(close)\n",
    "        return result\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Part 9: 거래량 + 시장강도 지표 엔진\n",
    "# ============================================================================\n",
    "\n",
    "class VolumeStrengthEngine:\n",
    "    \"\"\"거래량 및 시장강도 지표 계산 엔진\"\"\"\n",
    "\n",
    "    def __init__(self, config=None):\n",
    "        self.cfg = config or INDICATOR_CONFIG\n",
    "\n",
    "    def obv(self, close, volume):\n",
    "        direction = np.sign(close.diff())\n",
    "        return (direction * volume).fillna(0).cumsum()\n",
    "\n",
    "    def ad_line(self, high, low, close, volume):\n",
    "        hl_range = (high - low).replace(0, np.nan)\n",
    "        clv = ((close - low) - (high - close)) / hl_range\n",
    "        return (clv * volume).fillna(0).cumsum()\n",
    "\n",
    "    def chaikin_mf(self, high, low, close, volume, period=None):\n",
    "        n = period or self.cfg.cmf_period\n",
    "        hl_range = (high - low).replace(0, np.nan)\n",
    "        clv = ((close - low) - (high - close)) / hl_range\n",
    "        mfv = clv * volume\n",
    "        return mfv.rolling(n).sum() / volume.rolling(n).sum().replace(0, np.nan)\n",
    "\n",
    "    def compute_all(self, df, tier='1a'):\n",
    "        result = {}\n",
    "        if 'volume' not in df.columns or df['volume'].isna().all():\n",
    "            return result\n",
    "        close, volume = df['close'], df['volume']\n",
    "        result['OBV'] = self.obv(close, volume)\n",
    "        if tier in ('1a', '1b') and 'high' in df.columns:\n",
    "            high, low = df['high'], df['low']\n",
    "            result['AD_Line'] = self.ad_line(high, low, close, volume)\n",
    "            result['CMF'] = self.chaikin_mf(high, low, close, volume)\n",
    "        return result\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Part 10: 차트 렌더러 (특수차트 + 오버레이 + CompositeDashboard)\n",
    "# ============================================================================\n",
    "\n",
    "class SpecialChartRenderer:\n",
    "    \"\"\"특수 차트 렌더러\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.viz = VIZ_CONFIG\n",
    "\n",
    "    def candlestick(self, df, ax=None, title='', is_yield=True):\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(figsize=(14, 7))\n",
    "        dates = mdates.date2num(df.index.to_pydatetime())\n",
    "        o, h, l, c = df['open'], df['high'], df['low'], df['close']\n",
    "        for i in range(len(df)):\n",
    "            if pd.isna(o.iloc[i]) or pd.isna(c.iloc[i]):\n",
    "                continue\n",
    "            if is_yield:\n",
    "                color = self.viz.colors['positive'] if c.iloc[i] < o.iloc[i] else self.viz.colors['negative']\n",
    "            else:\n",
    "                color = self.viz.colors['positive'] if c.iloc[i] > o.iloc[i] else self.viz.colors['negative']\n",
    "            body_bottom = min(o.iloc[i], c.iloc[i])\n",
    "            body_height = abs(c.iloc[i] - o.iloc[i])\n",
    "            rect = mpatches.FancyBboxPatch((dates[i] - 0.3, body_bottom), 0.6, body_height or 0.001,\n",
    "                                            boxstyle=\"square,pad=0\", facecolor=color, edgecolor='black', linewidth=0.5)\n",
    "            ax.add_patch(rect)\n",
    "            if not pd.isna(h.iloc[i]):\n",
    "                ax.plot([dates[i], dates[i]], [body_bottom + body_height, h.iloc[i]], color='black', linewidth=0.5)\n",
    "            if not pd.isna(l.iloc[i]):\n",
    "                ax.plot([dates[i], dates[i]], [body_bottom, l.iloc[i]], color='black', linewidth=0.5)\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))\n",
    "        ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=2))\n",
    "        ax.set_xlim(dates[0] - 1, dates[-1] + 1)\n",
    "        ax.set_ylim(l.min() * 0.999, h.max() * 1.001)\n",
    "        ax.set_title(title, fontsize=self.viz.font_size_title)\n",
    "        ax.grid(alpha=self.viz.grid_alpha)\n",
    "        return ax\n",
    "\n",
    "    def point_and_figure(self, close, box_size=None, reversal=None, ax=None, title=''):\n",
    "        bs = box_size or INDICATOR_CONFIG.pnf_box_size\n",
    "        rev = reversal or INDICATOR_CONFIG.pnf_reversal\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(figsize=(14, 7))\n",
    "        columns = []\n",
    "        prices = close.dropna().values\n",
    "        if len(prices) < 2:\n",
    "            return ax\n",
    "        direction = 'X' if prices[1] > prices[0] else 'O'\n",
    "        col_start = prices[0]\n",
    "        col_end = prices[0]\n",
    "        for p in prices[1:]:\n",
    "            if direction == 'X':\n",
    "                if p >= col_end + bs:\n",
    "                    col_end = p\n",
    "                elif p <= col_end - bs * rev:\n",
    "                    columns.append((col_start, col_end, 'X'))\n",
    "                    direction, col_start, col_end = 'O', col_end, p\n",
    "            else:\n",
    "                if p <= col_end - bs:\n",
    "                    col_end = p\n",
    "                elif p >= col_end + bs * rev:\n",
    "                    columns.append((col_start, col_end, 'O'))\n",
    "                    direction, col_start, col_end = 'X', col_end, p\n",
    "        columns.append((col_start, col_end, direction))\n",
    "        for i, (start, end, dtype) in enumerate(columns):\n",
    "            n_boxes = int(abs(end - start) / bs) + 1\n",
    "            base = min(start, end)\n",
    "            for j in range(n_boxes):\n",
    "                y = base + j * bs\n",
    "                if dtype == 'X':\n",
    "                    ax.plot(i, y, 'x', color=self.viz.colors['positive'], markersize=8)\n",
    "                else:\n",
    "                    ax.plot(i, y, 'o', color=self.viz.colors['negative'], markersize=6, markerfacecolor='none')\n",
    "        ax.set_xlabel('Column')\n",
    "        ax.set_title(title or 'Point & Figure', fontsize=self.viz.font_size_title)\n",
    "        ax.grid(alpha=self.viz.grid_alpha)\n",
    "        return ax\n",
    "\n",
    "    def three_line_break(self, close, n_lines=None, ax=None, title=''):\n",
    "        n = n_lines or INDICATOR_CONFIG.three_line_break_lines\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(figsize=(14, 7))\n",
    "        prices = close.dropna().values\n",
    "        if len(prices) < 2:\n",
    "            return ax\n",
    "        lines = [(prices[0], prices[1], 'up' if prices[1] > prices[0] else 'down')]\n",
    "        for p in prices[2:]:\n",
    "            last = lines[-1]\n",
    "            if last[2] == 'up':\n",
    "                if p > last[1]:\n",
    "                    lines.append((last[1], p, 'up'))\n",
    "                else:\n",
    "                    lookback = [l for l in lines[-n:] if l[2] == 'up']\n",
    "                    if lookback and p < min(l[0] for l in lookback):\n",
    "                        lines.append((last[1], p, 'down'))\n",
    "            else:\n",
    "                if p < last[1]:\n",
    "                    lines.append((last[1], p, 'down'))\n",
    "                else:\n",
    "                    lookback = [l for l in lines[-n:] if l[2] == 'down']\n",
    "                    if lookback and p > max(l[0] for l in lookback):\n",
    "                        lines.append((last[1], p, 'up'))\n",
    "        for i, (o_val, c_val, d) in enumerate(lines):\n",
    "            color = self.viz.colors['positive'] if d == 'down' else self.viz.colors['negative']\n",
    "            bottom = min(o_val, c_val)\n",
    "            height = abs(c_val - o_val)\n",
    "            rect = mpatches.Rectangle((i - 0.4, bottom), 0.8, height or 0.001,\n",
    "                                       facecolor=color, edgecolor='black', linewidth=0.5)\n",
    "            ax.add_patch(rect)\n",
    "        ax.set_xlim(-1, len(lines))\n",
    "        if lines:\n",
    "            all_prices = [v for l in lines for v in [l[0], l[1]]]\n",
    "            ax.set_ylim(min(all_prices) * 0.999, max(all_prices) * 1.001)\n",
    "        ax.set_title(title or '삼선전환도', fontsize=self.viz.font_size_title)\n",
    "        ax.grid(alpha=self.viz.grid_alpha)\n",
    "        return ax\n",
    "\n",
    "    def counter_clockwise(self, close, volume, ax=None, title=''):\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        valid = pd.DataFrame({'price': close, 'volume': volume}).dropna()\n",
    "        if len(valid) < 3:\n",
    "            return ax\n",
    "        p_ma = valid['price'].rolling(5, min_periods=1).mean()\n",
    "        v_ma = valid['volume'].rolling(5, min_periods=1).mean()\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(p_ma)))\n",
    "        ax.scatter(v_ma, p_ma, c=colors, s=10, zorder=3)\n",
    "        ax.plot(v_ma, p_ma, color='gray', alpha=0.3, linewidth=0.5)\n",
    "        ax.scatter(v_ma.iloc[0], p_ma.iloc[0], color='blue', s=80, marker='^', zorder=4, label='시작')\n",
    "        ax.scatter(v_ma.iloc[-1], p_ma.iloc[-1], color='red', s=80, marker='v', zorder=4, label='현재')\n",
    "        ax.set_xlabel('거래량 (MA5)', fontsize=self.viz.font_size_label)\n",
    "        ax.set_ylabel('가격/수익률 (MA5)', fontsize=self.viz.font_size_label)\n",
    "        ax.set_title(title or '역시계곡선', fontsize=self.viz.font_size_title)\n",
    "        ax.legend(fontsize=self.viz.font_size_legend)\n",
    "        ax.grid(alpha=self.viz.grid_alpha)\n",
    "        return ax\n",
    "\n",
    "    def volume_profile(self, close, volume, n_bins=30, ax=None, title=''):\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots(figsize=(10, 7))\n",
    "        valid = pd.DataFrame({'close': close, 'volume': volume}).dropna()\n",
    "        if len(valid) < 5:\n",
    "            return ax\n",
    "        bins = np.linspace(valid['close'].min(), valid['close'].max(), n_bins + 1)\n",
    "        vol_by_price, centers = [], []\n",
    "        for i in range(len(bins) - 1):\n",
    "            mask = (valid['close'] >= bins[i]) & (valid['close'] < bins[i + 1])\n",
    "            vol_by_price.append(valid.loc[mask, 'volume'].sum())\n",
    "            centers.append((bins[i] + bins[i + 1]) / 2)\n",
    "        ax.barh(centers, vol_by_price, height=(bins[1] - bins[0]) * 0.8,\n",
    "                color=self.viz.colors['primary'], alpha=0.6, edgecolor='black', linewidth=0.3)\n",
    "        poc_idx = np.argmax(vol_by_price)\n",
    "        ax.barh(centers[poc_idx], vol_by_price[poc_idx], height=(bins[1] - bins[0]) * 0.8,\n",
    "                color=self.viz.colors['negative'], alpha=0.8, label=f'POC: {centers[poc_idx]:.3f}')\n",
    "        ax.set_ylabel('가격/수익률', fontsize=self.viz.font_size_label)\n",
    "        ax.set_xlabel('거래량', fontsize=self.viz.font_size_label)\n",
    "        ax.set_title(title or '볼륨 프로파일', fontsize=self.viz.font_size_title)\n",
    "        ax.legend(fontsize=self.viz.font_size_legend)\n",
    "        ax.grid(alpha=self.viz.grid_alpha)\n",
    "        return ax\n",
    "\n",
    "    def candle_volume(self, df, ax_price=None, ax_vol=None, title='', is_yield=True):\n",
    "        if ax_price is None:\n",
    "            fig, (ax_price, ax_vol) = plt.subplots(2, 1, figsize=(14, 9),\n",
    "                                                     height_ratios=[3, 1], sharex=True)\n",
    "        self.candlestick(df, ax=ax_price, title=title, is_yield=is_yield)\n",
    "        if 'volume' in df.columns:\n",
    "            colors = []\n",
    "            for i in range(len(df)):\n",
    "                if pd.isna(df['close'].iloc[i]) or pd.isna(df['open'].iloc[i]):\n",
    "                    colors.append('gray')\n",
    "                elif (is_yield and df['close'].iloc[i] < df['open'].iloc[i]) or \\\n",
    "                     (not is_yield and df['close'].iloc[i] > df['open'].iloc[i]):\n",
    "                    colors.append(self.viz.colors['positive'])\n",
    "                else:\n",
    "                    colors.append(self.viz.colors['negative'])\n",
    "            dates = mdates.date2num(df.index.to_pydatetime())\n",
    "            ax_vol.bar(dates, df['volume'], width=0.6, color=colors, alpha=0.7)\n",
    "            ax_vol.set_ylabel('거래량', fontsize=self.viz.font_size_label)\n",
    "            ax_vol.grid(alpha=self.viz.grid_alpha)\n",
    "        return ax_price, ax_vol\n",
    "\n",
    "\n",
    "class IndicatorOverlay:\n",
    "    \"\"\"지표 오버레이 렌더러\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.viz = VIZ_CONFIG\n",
    "\n",
    "    def overlay_ma(self, ax, ma_series, label, color=None, linestyle='-'):\n",
    "        dates = mdates.date2num(ma_series.index.to_pydatetime())\n",
    "        ax.plot(dates, ma_series, label=label, color=color or self.viz.colors['primary'],\n",
    "                linewidth=self.viz.linewidth_secondary, linestyle=linestyle)\n",
    "\n",
    "    def overlay_bollinger(self, ax, bb):\n",
    "        dates = mdates.date2num(bb['middle'].index.to_pydatetime())\n",
    "        ax.plot(dates, bb['middle'], label='BB Mid', color='gray', linewidth=0.8, linestyle='--')\n",
    "        ax.fill_between(dates, bb['lower'], bb['upper'], alpha=0.1,\n",
    "                        color=self.viz.colors['primary'], label='BB Band')\n",
    "\n",
    "    def overlay_ichimoku(self, ax, ichi):\n",
    "        dates = mdates.date2num(ichi['tenkan'].index.to_pydatetime())\n",
    "        ax.plot(dates, ichi['tenkan'], label='전환선', color='blue', linewidth=0.8)\n",
    "        ax.plot(dates, ichi['kijun'], label='기준선', color='red', linewidth=0.8)\n",
    "        sa, sb = ichi['senkou_a'].dropna(), ichi['senkou_b'].dropna()\n",
    "        common = sa.index.intersection(sb.index)\n",
    "        if len(common) > 0:\n",
    "            d = mdates.date2num(common.to_pydatetime())\n",
    "            ax.fill_between(d, sa[common], sb[common], where=sa[common] >= sb[common],\n",
    "                            alpha=0.15, color='green', label='양운')\n",
    "            ax.fill_between(d, sa[common], sb[common], where=sa[common] < sb[common],\n",
    "                            alpha=0.15, color='red', label='음운')\n",
    "\n",
    "    def overlay_sar(self, ax, sar):\n",
    "        dates = mdates.date2num(sar.index.to_pydatetime())\n",
    "        ax.scatter(dates, sar, s=5, color='purple', alpha=0.6, label='SAR', zorder=3)\n",
    "\n",
    "\n",
    "class CompositeDashboard:\n",
    "    \"\"\"종합 멀티패널 대시보드\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.viz = VIZ_CONFIG\n",
    "        self.chart = SpecialChartRenderer()\n",
    "        self.overlay = IndicatorOverlay()\n",
    "\n",
    "    def render(self, df, indicators, overlays, subpanels, title='', is_yield=True, figsize=None):\n",
    "        n_panels = 1 + len(subpanels)\n",
    "        has_volume_panel = 'volume' in df.columns and df['volume'].notna().any()\n",
    "        if has_volume_panel:\n",
    "            n_panels += 1\n",
    "        heights = [4]\n",
    "        if has_volume_panel:\n",
    "            heights.append(1)\n",
    "        for _ in subpanels:\n",
    "            heights.append(2)\n",
    "        total_height = max(10, 3 * n_panels)\n",
    "        fig_w = figsize[0] if figsize else 14\n",
    "        fig_h = figsize[1] if figsize else total_height\n",
    "        fig, axes = plt.subplots(n_panels, 1, figsize=(fig_w, fig_h),\n",
    "                                  height_ratios=heights, sharex=True)\n",
    "        if n_panels == 1:\n",
    "            axes = [axes]\n",
    "        ax_idx = 0\n",
    "\n",
    "        ax_main = axes[ax_idx]\n",
    "        dates = mdates.date2num(df.index.to_pydatetime())\n",
    "        ax_main.plot(dates, df['close'], color='black', linewidth=1.2, label='Close')\n",
    "        ma_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "        ci = 0\n",
    "        for ov in overlays:\n",
    "            if ov.startswith('SMA_') and ov in indicators:\n",
    "                self.overlay.overlay_ma(ax_main, indicators[ov], ov, ma_colors[ci % len(ma_colors)])\n",
    "                ci += 1\n",
    "            elif ov.startswith('DEMA') and 'DEMA' in indicators:\n",
    "                self.overlay.overlay_ma(ax_main, indicators['DEMA'], 'DEMA', ma_colors[ci % len(ma_colors)], '--')\n",
    "                ci += 1\n",
    "            elif ov == 'T3' and 'T3' in indicators:\n",
    "                self.overlay.overlay_ma(ax_main, indicators['T3'], 'T3', ma_colors[ci % len(ma_colors)], '-.')\n",
    "                ci += 1\n",
    "            elif ov == 'VIDYA' and 'VIDYA' in indicators:\n",
    "                self.overlay.overlay_ma(ax_main, indicators['VIDYA'], 'VIDYA', ma_colors[ci % len(ma_colors)], ':')\n",
    "                ci += 1\n",
    "            elif ov == 'VWMA' and 'VWMA' in indicators:\n",
    "                self.overlay.overlay_ma(ax_main, indicators['VWMA'], 'VWMA', ma_colors[ci % len(ma_colors)])\n",
    "                ci += 1\n",
    "            elif ov == 'Bollinger':\n",
    "                bb = {k.replace('BB_', ''): indicators[k] for k in indicators if k.startswith('BB_')}\n",
    "                if bb:\n",
    "                    self.overlay.overlay_bollinger(ax_main, bb)\n",
    "            elif ov == 'Ichimoku':\n",
    "                ichi = {k.replace('Ichimoku_', ''): indicators[k] for k in indicators if k.startswith('Ichimoku_')}\n",
    "                if ichi:\n",
    "                    self.overlay.overlay_ichimoku(ax_main, ichi)\n",
    "            elif ov == 'Parabolic_SAR' and 'Parabolic_SAR' in indicators:\n",
    "                self.overlay.overlay_sar(ax_main, indicators['Parabolic_SAR'])\n",
    "\n",
    "        ax_main.set_title(title, fontsize=self.viz.font_size_title, fontweight='bold')\n",
    "        ax_main.set_ylabel('수익률 (%)' if is_yield else '가격', fontsize=self.viz.font_size_label)\n",
    "        ax_main.legend(loc='upper left', fontsize=7, ncol=3)\n",
    "        ax_main.grid(alpha=self.viz.grid_alpha)\n",
    "        ax_idx += 1\n",
    "\n",
    "        if has_volume_panel:\n",
    "            ax_vol = axes[ax_idx]\n",
    "            colors = []\n",
    "            for i in range(len(df)):\n",
    "                if i == 0 or pd.isna(df['close'].iloc[i]):\n",
    "                    colors.append('gray')\n",
    "                elif df['close'].iloc[i] < df['close'].iloc[i-1]:\n",
    "                    colors.append(self.viz.colors['positive'])\n",
    "                else:\n",
    "                    colors.append(self.viz.colors['negative'])\n",
    "            ax_vol.bar(dates, df['volume'].fillna(0), width=0.6, color=colors, alpha=0.7)\n",
    "            ax_vol.set_ylabel('거래량', fontsize=8)\n",
    "            ax_vol.grid(alpha=self.viz.grid_alpha)\n",
    "            ax_idx += 1\n",
    "\n",
    "        for panel_name in subpanels:\n",
    "            ax = axes[ax_idx]\n",
    "            self._render_subpanel(ax, panel_name, indicators, dates)\n",
    "            ax_idx += 1\n",
    "\n",
    "        axes[-1].xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))\n",
    "        axes[-1].xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "        plt.setp(axes[-1].xaxis.get_majorticklabels(), rotation=45)\n",
    "        fig.tight_layout()\n",
    "        return fig, axes\n",
    "\n",
    "    def _render_subpanel(self, ax, name, indicators, dates):\n",
    "        if name == 'MACD':\n",
    "            if all(k in indicators for k in ['MACD', 'MACD_signal', 'MACD_hist']):\n",
    "                ax.plot(dates, indicators['MACD'], label='MACD', color='blue', linewidth=1)\n",
    "                ax.plot(dates, indicators['MACD_signal'], label='Signal', color='red', linewidth=1)\n",
    "                colors = ['green' if v >= 0 else 'red' for v in indicators['MACD_hist']]\n",
    "                ax.bar(dates, indicators['MACD_hist'], width=0.6, color=colors, alpha=0.5)\n",
    "                ax.axhline(0, color='black', linewidth=0.5)\n",
    "                ax.legend(loc='upper left', fontsize=7)\n",
    "            ax.set_ylabel('MACD', fontsize=8)\n",
    "        elif name == 'RSI':\n",
    "            if 'RSI' in indicators:\n",
    "                ax.plot(dates, indicators['RSI'], color='purple', linewidth=1)\n",
    "                ax.axhline(INDICATOR_CONFIG.rsi_overbought, color='red', linestyle='--', linewidth=0.5,\n",
    "                           label=f'{INDICATOR_CONFIG.rsi_overbought}')\n",
    "                ax.axhline(INDICATOR_CONFIG.rsi_oversold, color='green', linestyle='--', linewidth=0.5,\n",
    "                           label=f'{INDICATOR_CONFIG.rsi_oversold}')\n",
    "                ax.fill_between(dates, INDICATOR_CONFIG.rsi_oversold,\n",
    "                                INDICATOR_CONFIG.rsi_overbought, alpha=0.05, color='gray')\n",
    "                ax.set_ylim(0, 100)\n",
    "                ax.legend(loc='upper left', fontsize=6)\n",
    "            ax.set_ylabel('RSI', fontsize=8)\n",
    "        elif name == 'Stochastic':\n",
    "            if 'Stoch_K' in indicators:\n",
    "                ax.plot(dates, indicators['Stoch_K'], label='%K', color='blue', linewidth=1)\n",
    "                ax.plot(dates, indicators['Stoch_D'], label='%D', color='red', linewidth=1)\n",
    "                ax.axhline(80, color='red', linestyle='--', linewidth=0.5)\n",
    "                ax.axhline(20, color='green', linestyle='--', linewidth=0.5)\n",
    "                ax.set_ylim(0, 100)\n",
    "                ax.legend(loc='upper left', fontsize=7)\n",
    "            ax.set_ylabel('Stochastic', fontsize=8)\n",
    "        elif name == 'Williams_R':\n",
    "            if 'Williams_R' in indicators:\n",
    "                ax.plot(dates, indicators['Williams_R'], color='brown', linewidth=1)\n",
    "                ax.axhline(-20, color='red', linestyle='--', linewidth=0.5)\n",
    "                ax.axhline(-80, color='green', linestyle='--', linewidth=0.5)\n",
    "                ax.set_ylim(-100, 0)\n",
    "            ax.set_ylabel('Williams %R', fontsize=8)\n",
    "        elif name == 'DMI':\n",
    "            if all(k in indicators for k in ['DMI_plus_di', 'DMI_minus_di', 'DMI_adx']):\n",
    "                ax.plot(dates, indicators['DMI_plus_di'], label='+DI', color='green', linewidth=1)\n",
    "                ax.plot(dates, indicators['DMI_minus_di'], label='-DI', color='red', linewidth=1)\n",
    "                ax.plot(dates, indicators['DMI_adx'], label='ADX', color='black', linewidth=1.2)\n",
    "                ax.axhline(25, color='gray', linestyle='--', linewidth=0.5)\n",
    "                ax.legend(loc='upper left', fontsize=7)\n",
    "            ax.set_ylabel('DMI', fontsize=8)\n",
    "        elif name == 'CCI':\n",
    "            if 'CCI' in indicators:\n",
    "                ax.plot(dates, indicators['CCI'], color='teal', linewidth=1)\n",
    "                ax.axhline(100, color='red', linestyle='--', linewidth=0.5)\n",
    "                ax.axhline(-100, color='green', linestyle='--', linewidth=0.5)\n",
    "                ax.axhline(0, color='black', linewidth=0.5)\n",
    "            ax.set_ylabel('CCI', fontsize=8)\n",
    "        elif name == 'SONAR':\n",
    "            if 'SONAR' in indicators:\n",
    "                ax.plot(dates, indicators['SONAR'], color='navy', linewidth=1)\n",
    "                ax.axhline(0, color='black', linewidth=0.5)\n",
    "            ax.set_ylabel('SONAR', fontsize=8)\n",
    "        elif name == 'ATR':\n",
    "            if 'ATR' in indicators:\n",
    "                ax.plot(dates, indicators['ATR'], color='orange', linewidth=1)\n",
    "            ax.set_ylabel('ATR', fontsize=8)\n",
    "        elif name == 'Chaikin_Vol':\n",
    "            if 'Chaikin_Vol' in indicators:\n",
    "                ax.plot(dates, indicators['Chaikin_Vol'], color='brown', linewidth=1)\n",
    "                ax.axhline(0, color='black', linewidth=0.5)\n",
    "            ax.set_ylabel('Chaikin Vol', fontsize=8)\n",
    "        elif name == 'OBV':\n",
    "            if 'OBV' in indicators:\n",
    "                ax.plot(dates, indicators['OBV'], color='teal', linewidth=1)\n",
    "            ax.set_ylabel('OBV', fontsize=8)\n",
    "        elif name == 'AD_Line':\n",
    "            if 'AD_Line' in indicators:\n",
    "                ax.plot(dates, indicators['AD_Line'], color='purple', linewidth=1)\n",
    "            ax.set_ylabel('A/D Line', fontsize=8)\n",
    "        elif name == 'CMF':\n",
    "            if 'CMF' in indicators:\n",
    "                colors = ['green' if v >= 0 else 'red' for v in indicators['CMF']]\n",
    "                ax.bar(dates, indicators['CMF'], width=0.6, color=colors, alpha=0.6)\n",
    "                ax.axhline(0, color='black', linewidth=0.5)\n",
    "            ax.set_ylabel('CMF', fontsize=8)\n",
    "        elif name == 'Bollinger_BW':\n",
    "            if 'BB_bandwidth' in indicators:\n",
    "                ax.plot(dates, indicators['BB_bandwidth'], color='gray', linewidth=1)\n",
    "            ax.set_ylabel('BB Width', fontsize=8)\n",
    "        ax.grid(alpha=self.viz.grid_alpha)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Part 11: 시그널 분류 엔진\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class IndicatorSignal:\n",
    "    \"\"\"개별 지표 시그널\"\"\"\n",
    "    name: str\n",
    "    category: str\n",
    "    value: float\n",
    "    signal: str\n",
    "    description: str\n",
    "    abs_gauge: float\n",
    "    rel_gauges: Dict[str, float]\n",
    "    direction: str\n",
    "    divergence: bool\n",
    "\n",
    "\n",
    "class SignalClassifier:\n",
    "    \"\"\"채권 관점 시그널 분류 엔진\"\"\"\n",
    "\n",
    "    def __init__(self, config=None):\n",
    "        self.cfg = config or INDICATOR_CONFIG\n",
    "\n",
    "    def classify_rsi(self, rsi, close):\n",
    "        val = rsi.iloc[-1]\n",
    "        prev = rsi.iloc[-2] if len(rsi) > 1 else val\n",
    "        if np.isnan(val):\n",
    "            return self._na_signal('RSI', 'momentum')\n",
    "        if val > self.cfg.rsi_overbought:\n",
    "            sig, desc = 'buy', f'{val:.1f} 금리과매수→매수'\n",
    "        elif val < self.cfg.rsi_oversold:\n",
    "            sig, desc = 'sell', f'{val:.1f} 금리과매도→매도'\n",
    "        else:\n",
    "            sig, desc = 'neutral', f'{val:.1f} 중립'\n",
    "        abs_gauge = 1.0 - val / 100.0\n",
    "        return IndicatorSignal(\n",
    "            name='RSI', category='momentum', value=val, signal=sig,\n",
    "            description=desc, abs_gauge=abs_gauge,\n",
    "            rel_gauges=self._percentile_gauges(rsi),\n",
    "            direction=self._direction(val, prev),\n",
    "            divergence=self._check_divergence(rsi, close)\n",
    "        )\n",
    "\n",
    "    def classify_stochastic(self, k, d, close):\n",
    "        val = k.iloc[-1]\n",
    "        prev = k.iloc[-2] if len(k) > 1 else val\n",
    "        if np.isnan(val):\n",
    "            return self._na_signal('Stochastic', 'momentum')\n",
    "        if val > self.cfg.stoch_overbought:\n",
    "            sig, desc = 'buy', f'%K={val:.0f} 금리과매수'\n",
    "        elif val < self.cfg.stoch_oversold:\n",
    "            sig, desc = 'sell', f'%K={val:.0f} 금리과매도'\n",
    "        else:\n",
    "            sig, desc = 'neutral', f'%K={val:.0f} 중립'\n",
    "        return IndicatorSignal(\n",
    "            name='Stochastic', category='momentum', value=val, signal=sig,\n",
    "            description=desc, abs_gauge=1.0 - val / 100.0,\n",
    "            rel_gauges=self._percentile_gauges(k),\n",
    "            direction=self._direction(val, prev),\n",
    "            divergence=self._check_divergence(k, close)\n",
    "        )\n",
    "\n",
    "    def classify_williams(self, wr, close):\n",
    "        val = wr.iloc[-1]\n",
    "        prev = wr.iloc[-2] if len(wr) > 1 else val\n",
    "        if np.isnan(val):\n",
    "            return self._na_signal('Williams %R', 'momentum')\n",
    "        if val > self.cfg.williams_overbought:\n",
    "            sig, desc = 'buy', f'{val:.0f} 금리과매수→매수'\n",
    "        elif val < self.cfg.williams_oversold:\n",
    "            sig, desc = 'sell', f'{val:.0f} 금리과매도→매도'\n",
    "        else:\n",
    "            sig, desc = 'neutral', f'{val:.0f} 중립'\n",
    "        abs_gauge = (val + 100) / 100.0\n",
    "        return IndicatorSignal(\n",
    "            name='Williams %R', category='momentum', value=val, signal=sig,\n",
    "            description=desc, abs_gauge=abs_gauge,\n",
    "            rel_gauges=self._percentile_gauges(wr),\n",
    "            direction=self._direction(val, prev),\n",
    "            divergence=self._check_divergence(wr, close)\n",
    "        )\n",
    "\n",
    "    def classify_macd(self, macd, signal, hist, close):\n",
    "        val = hist.iloc[-1]\n",
    "        prev = hist.iloc[-2] if len(hist) > 1 else val\n",
    "        macd_val = macd.iloc[-1]\n",
    "        if np.isnan(val):\n",
    "            return self._na_signal('MACD', 'trend')\n",
    "        if val < 0 and (len(hist) < 2 or hist.iloc[-2] >= 0):\n",
    "            sig, desc = 'buy', f'{macd_val:.4f} 데드크로스'\n",
    "        elif val > 0 and (len(hist) < 2 or hist.iloc[-2] <= 0):\n",
    "            sig, desc = 'sell', f'{macd_val:.4f} 골든크로스'\n",
    "        elif val < 0:\n",
    "            sig, desc = 'buy', f'{macd_val:.4f} 하락추세'\n",
    "        elif val > 0:\n",
    "            sig, desc = 'sell', f'{macd_val:.4f} 상승추세'\n",
    "        else:\n",
    "            sig, desc = 'neutral', f'{macd_val:.4f} 중립'\n",
    "        return IndicatorSignal(\n",
    "            name='MACD', category='trend', value=macd_val, signal=sig,\n",
    "            description=desc, abs_gauge=0.5,\n",
    "            rel_gauges=self._percentile_gauges(hist),\n",
    "            direction=self._direction(val, prev),\n",
    "            divergence=self._check_divergence(macd, close)\n",
    "        )\n",
    "\n",
    "    def classify_dmi(self, plus_di, minus_di, adx):\n",
    "        pdi, mdi, adx_val = plus_di.iloc[-1], minus_di.iloc[-1], adx.iloc[-1]\n",
    "        prev_adx = adx.iloc[-2] if len(adx) > 1 else adx_val\n",
    "        if any(np.isnan(v) for v in [pdi, mdi, adx_val]):\n",
    "            return self._na_signal('DMI', 'trend')\n",
    "        if mdi > pdi and adx_val > 25:\n",
    "            sig, desc = 'buy', f'ADX {adx_val:.0f} 금리하락추세'\n",
    "        elif pdi > mdi and adx_val > 25:\n",
    "            sig, desc = 'sell', f'ADX {adx_val:.0f} 금리상승추세'\n",
    "        else:\n",
    "            sig, desc = 'neutral', f'ADX {adx_val:.0f} {\"추세 강화중\" if adx_val > 20 else \"비추세\"}'\n",
    "        abs_gauge = max(0, min(1, 0.5 - (pdi - mdi) / 100.0))\n",
    "        return IndicatorSignal(\n",
    "            name='DMI', category='trend', value=adx_val, signal=sig,\n",
    "            description=desc, abs_gauge=abs_gauge,\n",
    "            rel_gauges=self._percentile_gauges(adx),\n",
    "            direction=self._direction(adx_val, prev_adx),\n",
    "            divergence=False\n",
    "        )\n",
    "\n",
    "    def classify_cci(self, cci, close):\n",
    "        val = cci.iloc[-1]\n",
    "        prev = cci.iloc[-2] if len(cci) > 1 else val\n",
    "        if np.isnan(val):\n",
    "            return self._na_signal('CCI', 'trend')\n",
    "        if val > self.cfg.cci_overbought:\n",
    "            sig, desc = 'buy', f'{val:.0f} 금리과매수→매수'\n",
    "        elif val < self.cfg.cci_oversold:\n",
    "            sig, desc = 'sell', f'{val:.0f} 금리과매도→매도'\n",
    "        else:\n",
    "            sig, desc = 'neutral', f'{val:.0f} 중립'\n",
    "        abs_gauge = max(0, min(1, (val + 300) / 600.0))\n",
    "        return IndicatorSignal(\n",
    "            name='CCI', category='trend', value=val, signal=sig,\n",
    "            description=desc, abs_gauge=abs_gauge,\n",
    "            rel_gauges=self._percentile_gauges(cci),\n",
    "            direction=self._direction(val, prev),\n",
    "            divergence=self._check_divergence(cci, close)\n",
    "        )\n",
    "\n",
    "    def classify_bollinger(self, close, pctb, bw):\n",
    "        val = pctb.iloc[-1]\n",
    "        prev = pctb.iloc[-2] if len(pctb) > 1 else val\n",
    "        if np.isnan(val):\n",
    "            return self._na_signal('Bollinger', 'volatility')\n",
    "        if val > 1.0:\n",
    "            sig, desc = 'buy', f'%B={val:.2f} 상한돌파→매수'\n",
    "        elif val < 0.0:\n",
    "            sig, desc = 'sell', f'%B={val:.2f} 하한돌파→매도'\n",
    "        elif val > 0.8:\n",
    "            sig, desc = 'buy', f'%B={val:.2f} 상한근접'\n",
    "        elif val < 0.2:\n",
    "            sig, desc = 'sell', f'%B={val:.2f} 하한근접'\n",
    "        else:\n",
    "            sig, desc = 'neutral', f'%B={val:.2f} 중립'\n",
    "        return IndicatorSignal(\n",
    "            name='Bollinger', category='volatility', value=val, signal=sig,\n",
    "            description=desc, abs_gauge=max(0, min(1, val)),\n",
    "            rel_gauges=self._percentile_gauges(pctb),\n",
    "            direction=self._direction(val, prev),\n",
    "            divergence=False\n",
    "        )\n",
    "\n",
    "    def classify_atr(self, atr):\n",
    "        val = atr.iloc[-1]\n",
    "        prev = atr.iloc[-2] if len(atr) > 1 else val\n",
    "        if np.isnan(val):\n",
    "            return self._na_signal('ATR', 'volatility')\n",
    "        return IndicatorSignal(\n",
    "            name='ATR', category='volatility', value=val, signal='neutral',\n",
    "            description=f'{val:.4f} {\"고변동\" if val > atr.quantile(0.75) else \"보통\"}',\n",
    "            abs_gauge=0.5,\n",
    "            rel_gauges=self._percentile_gauges(atr),\n",
    "            direction=self._direction(val, prev),\n",
    "            divergence=False\n",
    "        )\n",
    "\n",
    "    def classify_obv(self, obv, close):\n",
    "        val = obv.iloc[-1]\n",
    "        prev = obv.iloc[-2] if len(obv) > 1 else val\n",
    "        if np.isnan(val):\n",
    "            return self._na_signal('OBV', 'volume')\n",
    "        obv_ma = obv.rolling(20).mean()\n",
    "        obv_trend = 'rising' if val > obv_ma.iloc[-1] else 'falling'\n",
    "        if obv_trend == 'rising':\n",
    "            sig, desc = 'sell', '상승 추세'\n",
    "        else:\n",
    "            sig, desc = 'buy', '하락 추세'\n",
    "        return IndicatorSignal(\n",
    "            name='OBV', category='volume', value=val, signal=sig,\n",
    "            description=desc, abs_gauge=0.5,\n",
    "            rel_gauges=self._percentile_gauges(obv),\n",
    "            direction=self._direction(val, prev),\n",
    "            divergence=self._check_divergence(obv, close)\n",
    "        )\n",
    "\n",
    "    def classify_cmf(self, cmf):\n",
    "        val = cmf.iloc[-1]\n",
    "        prev = cmf.iloc[-2] if len(cmf) > 1 else val\n",
    "        if np.isnan(val):\n",
    "            return self._na_signal('CMF', 'volume')\n",
    "        if val > 0.1:\n",
    "            sig, desc = 'sell', f'+{val:.2f} 강한 유입'\n",
    "        elif val > 0:\n",
    "            sig, desc = 'neutral', f'+{val:.2f} 약한 유입'\n",
    "        elif val > -0.1:\n",
    "            sig, desc = 'neutral', f'{val:.2f} 약한 유출'\n",
    "        else:\n",
    "            sig, desc = 'buy', f'{val:.2f} 강한 유출'\n",
    "        abs_gauge = max(0, min(1, 0.5 - val / 2.0))\n",
    "        return IndicatorSignal(\n",
    "            name='CMF', category='volume', value=val, signal=sig,\n",
    "            description=desc, abs_gauge=abs_gauge,\n",
    "            rel_gauges=self._percentile_gauges(cmf),\n",
    "            direction=self._direction(val, prev),\n",
    "            divergence=False\n",
    "        )\n",
    "\n",
    "    def classify_sonar(self, sonar, close):\n",
    "        val = sonar.iloc[-1]\n",
    "        prev = sonar.iloc[-2] if len(sonar) > 1 else val\n",
    "        if np.isnan(val):\n",
    "            return self._na_signal('SONAR', 'trend')\n",
    "        if val < 0:\n",
    "            sig, desc = 'buy', f'{val:.2f} 하락모멘텀→매수'\n",
    "        elif val > 0:\n",
    "            sig, desc = 'sell', f'{val:.2f} 상승모멘텀→매도'\n",
    "        else:\n",
    "            sig, desc = 'neutral', f'{val:.2f} 중립'\n",
    "        return IndicatorSignal(\n",
    "            name='SONAR', category='trend', value=val, signal=sig,\n",
    "            description=desc, abs_gauge=0.5,\n",
    "            rel_gauges=self._percentile_gauges(sonar),\n",
    "            direction=self._direction(val, prev),\n",
    "            divergence=self._check_divergence(sonar, close)\n",
    "        )\n",
    "\n",
    "    def classify_chaikin_vol(self, chvol):\n",
    "        val = chvol.iloc[-1]\n",
    "        prev = chvol.iloc[-2] if len(chvol) > 1 else val\n",
    "        if np.isnan(val):\n",
    "            return self._na_signal('Chaikin Vol', 'volatility')\n",
    "        if val > 0.1:\n",
    "            desc = f'{val:.3f} 변동성 확대'\n",
    "        elif val < -0.1:\n",
    "            desc = f'{val:.3f} 변동성 축소'\n",
    "        else:\n",
    "            desc = f'{val:.3f} 보통'\n",
    "        return IndicatorSignal(\n",
    "            name='Chaikin Vol', category='volatility', value=val, signal='neutral',\n",
    "            description=desc, abs_gauge=0.5,\n",
    "            rel_gauges=self._percentile_gauges(chvol),\n",
    "            direction=self._direction(val, prev),\n",
    "            divergence=False\n",
    "        )\n",
    "\n",
    "    def classify_ad_line(self, ad, close):\n",
    "        val = ad.iloc[-1]\n",
    "        prev = ad.iloc[-2] if len(ad) > 1 else val\n",
    "        if np.isnan(val):\n",
    "            return self._na_signal('A/D Line', 'volume')\n",
    "        ad_ma = ad.rolling(20).mean()\n",
    "        ad_trend = 'rising' if val > ad_ma.iloc[-1] else 'falling'\n",
    "        if ad_trend == 'rising':\n",
    "            sig, desc = 'sell', '매집→금리상승압력'\n",
    "        else:\n",
    "            sig, desc = 'buy', '분산→금리하락압력'\n",
    "        return IndicatorSignal(\n",
    "            name='A/D Line', category='volume', value=val, signal=sig,\n",
    "            description=desc, abs_gauge=0.5,\n",
    "            rel_gauges=self._percentile_gauges(ad),\n",
    "            direction=self._direction(val, prev),\n",
    "            divergence=self._check_divergence(ad, close)\n",
    "        )\n",
    "\n",
    "    def _na_signal(self, name, category):\n",
    "        return IndicatorSignal(\n",
    "            name=name, category=category, value=np.nan,\n",
    "            signal='n/a', description='데이터 부족', abs_gauge=0.5,\n",
    "            rel_gauges={'full': 0.5, 'short': 0.5, 'medium': 0.5, 'long': 0.5},\n",
    "            direction='stable', divergence=False\n",
    "        )\n",
    "\n",
    "    def _percentile_gauges(self, series):\n",
    "        val = series.iloc[-1]\n",
    "        if np.isnan(val):\n",
    "            return {'full': 0.5, 'short': 0.5, 'medium': 0.5, 'long': 0.5}\n",
    "\n",
    "        def _pct(subset):\n",
    "            s = subset.dropna()\n",
    "            if len(s) < 5:\n",
    "                return 0.5\n",
    "            return stats.percentileofscore(s.values, val, kind='rank') / 100.0\n",
    "\n",
    "        result = {}\n",
    "        result['full'] = _pct(series)\n",
    "        for label, window in [('short', self.cfg.gauge_short),\n",
    "                               ('medium', self.cfg.gauge_medium),\n",
    "                               ('long', self.cfg.gauge_long)]:\n",
    "            result[label] = _pct(series.iloc[-window:])\n",
    "        return result\n",
    "\n",
    "    def _direction(self, current, previous):\n",
    "        if np.isnan(current) or np.isnan(previous):\n",
    "            return 'stable'\n",
    "        diff = current - previous\n",
    "        if abs(diff) < 1e-8:\n",
    "            return 'stable'\n",
    "        return 'strengthening' if diff > 0 else 'weakening'\n",
    "\n",
    "    def _check_divergence(self, indicator, price, lookback=20):\n",
    "        if len(indicator) < lookback or len(price) < lookback:\n",
    "            return False\n",
    "        ind_tail = indicator.iloc[-lookback:]\n",
    "        price_tail = price.iloc[-lookback:]\n",
    "        if ind_tail.isna().all() or price_tail.isna().all():\n",
    "            return False\n",
    "        ind_trend = np.polyfit(range(len(ind_tail.dropna())), ind_tail.dropna(), 1)[0]\n",
    "        price_trend = np.polyfit(range(len(price_tail.dropna())), price_tail.dropna(), 1)[0]\n",
    "        return (ind_trend > 0 and price_trend < 0) or (ind_trend < 0 and price_trend > 0)\n",
    "\n",
    "    def classify_all(self, indicators, close):\n",
    "        signals = []\n",
    "        if 'RSI' in indicators:\n",
    "            signals.append(self.classify_rsi(indicators['RSI'], close))\n",
    "        if 'Stoch_K' in indicators and 'Stoch_D' in indicators:\n",
    "            signals.append(self.classify_stochastic(indicators['Stoch_K'], indicators['Stoch_D'], close))\n",
    "        if 'Williams_R' in indicators:\n",
    "            signals.append(self.classify_williams(indicators['Williams_R'], close))\n",
    "        if all(k in indicators for k in ['MACD', 'MACD_signal', 'MACD_hist']):\n",
    "            signals.append(self.classify_macd(indicators['MACD'], indicators['MACD_signal'],\n",
    "                                              indicators['MACD_hist'], close))\n",
    "        if all(k in indicators for k in ['DMI_plus_di', 'DMI_minus_di', 'DMI_adx']):\n",
    "            signals.append(self.classify_dmi(indicators['DMI_plus_di'], indicators['DMI_minus_di'],\n",
    "                                             indicators['DMI_adx']))\n",
    "        if 'CCI' in indicators:\n",
    "            signals.append(self.classify_cci(indicators['CCI'], close))\n",
    "        if 'BB_pctb' in indicators and 'BB_bandwidth' in indicators:\n",
    "            signals.append(self.classify_bollinger(close, indicators['BB_pctb'], indicators['BB_bandwidth']))\n",
    "        if 'ATR' in indicators:\n",
    "            signals.append(self.classify_atr(indicators['ATR']))\n",
    "        if 'OBV' in indicators:\n",
    "            signals.append(self.classify_obv(indicators['OBV'], close))\n",
    "        if 'CMF' in indicators:\n",
    "            signals.append(self.classify_cmf(indicators['CMF']))\n",
    "        if 'SONAR' in indicators:\n",
    "            signals.append(self.classify_sonar(indicators['SONAR'], close))\n",
    "        if 'Chaikin_Vol' in indicators:\n",
    "            signals.append(self.classify_chaikin_vol(indicators['Chaikin_Vol']))\n",
    "        if 'AD_Line' in indicators:\n",
    "            signals.append(self.classify_ad_line(indicators['AD_Line'], close))\n",
    "        return signals\n",
    "\n",
    "    def composite_score(self, signals):\n",
    "        valid = [s for s in signals if s.signal != 'n/a']\n",
    "        if not valid:\n",
    "            return {'score': 0, 'buy': 0, 'sell': 0, 'neutral': 0, 'na': len(signals)}\n",
    "        buy_count = sum(1 for s in valid if s.signal == 'buy')\n",
    "        sell_count = sum(1 for s in valid if s.signal == 'sell')\n",
    "        neutral_count = sum(1 for s in valid if s.signal == 'neutral')\n",
    "        na_count = sum(1 for s in signals if s.signal == 'n/a')\n",
    "        score = (buy_count - sell_count) / len(valid) if valid else 0\n",
    "        return {\n",
    "            'score': round(score, 2), 'buy': buy_count, 'sell': sell_count,\n",
    "            'neutral': neutral_count, 'na': na_count,\n",
    "            'total': len(signals), 'valid': len(valid),\n",
    "        }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# 전역 인스턴스\n",
    "# ============================================================================\n",
    "\n",
    "price_trend_engine = PriceTrendEngine()\n",
    "vol_momentum_engine = VolatilityMomentumEngine()\n",
    "volume_engine = VolumeStrengthEngine()\n",
    "chart_renderer = SpecialChartRenderer()\n",
    "indicator_overlay = IndicatorOverlay()\n",
    "composite_dashboard = CompositeDashboard()\n",
    "signal_classifier = SignalClassifier()\n",
    "\n",
    "print(\"Cell 1 완료: 모듈 로딩 (유틸리티 + 엔진 + 렌더러 + 시그널)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ══════════════════════════════════════════════════════════════\n",
    "# Cell 2: 데이터 로딩\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "import os\n",
    "\n",
    "# 확장 로더 인스턴스 생성\n",
    "bond_ohlcv_loader = BondOHLCVLoader()\n",
    "futures_loader = FuturesLoader()\n",
    "\n",
    "# 파일 경로 결정\n",
    "_nb_dir = Path(os.getcwd())\n",
    "_xlsb_path = _nb_dir / DATA_CONFIG.file_path\n",
    "\n",
    "if not _xlsb_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"데이터 파일을 찾을 수 없습니다: {_xlsb_path}\\n\"\n",
    "        f\"TA_rawdata.xlsb 파일이 노트북과 같은 디렉토리에 있어야 합니다.\"\n",
    "    )\n",
    "\n",
    "print(f\"데이터 파일: {_xlsb_path.name}\")\n",
    "\n",
    "# ── 1. 금리 데이터 (Rates 시트) ──\n",
    "rates = read_rates_dataframe(\n",
    "    _xlsb_path,\n",
    "    DATA_CONFIG.rates_sheet,\n",
    "    header_row=DATA_CONFIG.header_row,\n",
    "    data_start_row=DATA_CONFIG.data_start_row\n",
    ")\n",
    "\n",
    "# ── 2. 스프레드 데이터 (Spread 시트) ──\n",
    "spreads_vs_ktb = read_rates_dataframe(\n",
    "    _xlsb_path,\n",
    "    DATA_CONFIG.spread_sheet,\n",
    "    header_row=DATA_CONFIG.header_row,\n",
    "    data_start_row=DATA_CONFIG.data_start_row\n",
    ")\n",
    "\n",
    "# ── 3. 국고지표 OHLCV ──\n",
    "bond_ohlcv = bond_ohlcv_loader.load_from_xlsb(str(_xlsb_path))\n",
    "\n",
    "# ── 4. 국고선물 OHLCV ──\n",
    "futures = futures_loader.load_from_xlsb(str(_xlsb_path))\n",
    "\n",
    "# ── 5. 데이터 티어 탐지기 ──\n",
    "tier_detector = DataTierDetector(bond_ohlcv_loader, futures_loader)\n",
    "\n",
    "# ── 결과 요약 ──\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"데이터 로딩 완료\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "if not rates.empty:\n",
    "    print(f\"금리 데이터: {rates.shape}\")\n",
    "    print(f\"스프레드 데이터: {spreads_vs_ktb.shape}\")\n",
    "    print(f\"기간: {rates.index[0].date()} ~ {rates.index[-1].date()}\")\n",
    "    print(f\"거래일: {len(rates)}일\")\n",
    "    print(f\"종목 수: {len(rates.columns)}개\")\n",
    "else:\n",
    "    print(\"금리/스프레드: 데이터 없음\")\n",
    "\n",
    "if bond_ohlcv:\n",
    "    print(f\"OHLCV 종목: {list(bond_ohlcv.keys())}\")\n",
    "if futures:\n",
    "    print(f\"선물 종목: {list(futures.keys())}\")\n",
    "\n",
    "if bond_ohlcv or futures:\n",
    "    print(f\"\\n[데이터 티어 요약]\")\n",
    "    print(tier_detector.summary().to_string(index=False))\n",
    "\n",
    "# 경고 억제\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')\n",
    "logging.getLogger('matplotlib.category').setLevel(logging.ERROR)\n",
    "\n",
    "# 저장 디렉토리 생성\n",
    "if CFG.save_dir and (CFG.save_excel or CFG.save_graphs):\n",
    "    CFG.save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"\\n저장 디렉토리: {CFG.save_dir.resolve()}\")\n",
    "\n",
    "print(\"\\nCell 2 완료: 데이터 로딩\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ══════════════════════════════════════════════════════════════\n",
    "# Cell 3: 상관분석 (히트맵 + 롤링상관 + 금리비교)\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "from itertools import combinations\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "# ── 함수 정의 ──\n",
    "\n",
    "def build_spreads_corr(rates_df, columns):\n",
    "    \"\"\"종목 쌍별 스프레드 계산\"\"\"\n",
    "    result = pd.DataFrame(index=rates_df.index)\n",
    "    for i, j in combinations(range(len(columns)), 2):\n",
    "        name = f\"{columns[j]} - {columns[i]}\"\n",
    "        result[name] = rates_df[columns[j]] - rates_df[columns[i]]\n",
    "    return result\n",
    "\n",
    "\n",
    "def build_analysis_data(rates_df, spreads_df, columns, mode):\n",
    "    \"\"\"모드에 따른 분석 데이터 생성\"\"\"\n",
    "    source = spreads_df if mode in ['spreads_vs_ktb', 'spreads_vs_ktb_changes'] else rates_df\n",
    "    if columns is None:\n",
    "        cols = source.columns.tolist()\n",
    "    else:\n",
    "        cols = [c for c in columns if c in source.columns]\n",
    "        if not cols:\n",
    "            raise ValueError(\"유효한 종목이 없습니다\")\n",
    "    if mode == 'rates': return source[cols].dropna()\n",
    "    elif mode == 'rates_changes': return source[cols].diff().dropna()\n",
    "    elif mode == 'spreads': return build_spreads_corr(source, cols).dropna()\n",
    "    elif mode == 'spreads_changes': return build_spreads_corr(source, cols).diff().dropna()\n",
    "    elif mode == 'spreads_vs_ktb': return source[cols].dropna()\n",
    "    elif mode == 'spreads_vs_ktb_changes': return source[cols].diff().dropna()\n",
    "    else: raise ValueError(f\"알 수 없는 모드: {mode}\")\n",
    "\n",
    "\n",
    "def plot_correlation_heatmap(data, **kwargs):\n",
    "    \"\"\"상관관계 히트맵 (A4 Landscape)\"\"\"\n",
    "    start_date = kwargs.get('start_date')\n",
    "    end_date = kwargs.get('end_date')\n",
    "    mode = kwargs.get('mode', '')\n",
    "\n",
    "    df = data.copy()\n",
    "    if start_date: df = df[df.index >= pd.to_datetime(start_date)]\n",
    "    if end_date: df = df[df.index <= pd.to_datetime(end_date)]\n",
    "    if df.empty: raise ValueError(\"데이터가 없습니다\")\n",
    "\n",
    "    corr = df.corr()\n",
    "    n = len(corr)\n",
    "    disp_arr = corr.to_numpy(dtype=float, copy=True)\n",
    "    np.fill_diagonal(disp_arr, np.nan)\n",
    "    display = pd.DataFrame(disp_arr, index=corr.index, columns=corr.columns)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=A4_LANDSCAPE)\n",
    "    im = ax.imshow(display.values, cmap='RdYlBu_r',\n",
    "                   norm=TwoSlopeNorm(vmin=-1, vcenter=0, vmax=1), aspect='equal')\n",
    "    plt.colorbar(im, ax=ax, shrink=0.8, label='Correlation')\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            val = display.iloc[i, j]\n",
    "            if not np.isnan(val):\n",
    "                color = 'white' if abs(val) > 0.6 else 'black'\n",
    "                ax.text(j, i, f'{val:.2f}', ha='center', va='center', fontsize=8, color=color)\n",
    "\n",
    "    ax.set_xticks(range(n))\n",
    "    ax.set_yticks(range(n))\n",
    "    ax.set_xticklabels(corr.columns, fontsize=CHART_STYLE['label_fontsize'], rotation=45, ha='right')\n",
    "    ax.set_yticklabels(corr.index, fontsize=CHART_STYLE['label_fontsize'])\n",
    "    ax.set_xticks(np.arange(-0.5, n, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-0.5, n, 1), minor=True)\n",
    "    ax.grid(which='minor', color='white', linestyle='-', linewidth=1)\n",
    "    ax.tick_params(which='minor', size=0)\n",
    "\n",
    "    mode_names = {\n",
    "        'rates': '금리 수준', 'rates_changes': '금리 변화',\n",
    "        'spreads': '종목 간 스프레드', 'spreads_changes': '종목 간 스프레드 변화',\n",
    "        'spreads_vs_ktb': '국고채 대비 스프레드', 'spreads_vs_ktb_changes': '국고채 대비 스프레드 변화'\n",
    "    }\n",
    "    start_str = df.index[0].strftime('%Y-%m-%d')\n",
    "    end_str = df.index[-1].strftime('%Y-%m-%d')\n",
    "    ax.set_title(f\"상관관계 히트맵 ({mode_names.get(mode, mode)})\\n{start_str} ~ {end_str}, {len(df)}일\",\n",
    "                 fontsize=CHART_STYLE['title_fontsize'], fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    _all_figs.append((fig, 'heatmap'))\n",
    "    plt.show()\n",
    "    return corr\n",
    "\n",
    "\n",
    "def calculate_rolling_corr(data, col1, col2, window):\n",
    "    return data[col1].rolling(window=window).corr(data[col2])\n",
    "\n",
    "\n",
    "def calculate_rolling_stats(series, window):\n",
    "    rolling_mean = series.rolling(window=window).mean()\n",
    "    rolling_std = series.rolling(window=window).std()\n",
    "    z_score = (series - rolling_mean) / rolling_std\n",
    "    return rolling_mean, rolling_std, z_score\n",
    "\n",
    "\n",
    "def plot_rolling_analysis(data_full, data_filtered, data_hist, col1, col2,\n",
    "                          pair_name, window, hist_period_label):\n",
    "    \"\"\"단일 쌍 롤링 분석 그래프 (A4 Landscape)\"\"\"\n",
    "    corr_hist = calculate_rolling_corr(data_hist, col1, col2, window).dropna()\n",
    "    corr_filtered = calculate_rolling_corr(data_filtered, col1, col2, window).dropna()\n",
    "    corr_mean = corr_filtered.rolling(window=window).mean()\n",
    "    corr_std = corr_filtered.rolling(window=window).std()\n",
    "\n",
    "    spread_hist = data_hist[col2] - data_hist[col1]\n",
    "    spread_filtered = data_filtered[col2] - data_filtered[col1]\n",
    "    spread_mean, spread_std, spread_zscore = calculate_rolling_stats(spread_filtered, window)\n",
    "    _, spread_std_hist, spread_zscore_hist = calculate_rolling_stats(spread_hist, window)\n",
    "\n",
    "    corr_pct = stats.percentileofscore(corr_hist.dropna(), corr_filtered.iloc[-1])\n",
    "    spread_pct = stats.percentileofscore(spread_hist.dropna(), spread_filtered.iloc[-1])\n",
    "\n",
    "    fig = plt.figure(figsize=A4_LANDSCAPE, constrained_layout=True)\n",
    "    gs = fig.add_gridspec(4, 6, height_ratios=[1.2, 1, 1, 1],\n",
    "                          width_ratios=[1, 1, 1, 1, 1, 0.7], hspace=0.08, wspace=0.08)\n",
    "\n",
    "    ax_corr = fig.add_subplot(gs[0, :5])\n",
    "    ax_corr_hist = fig.add_subplot(gs[0, 5])\n",
    "    ax_spread = fig.add_subplot(gs[1, :5], sharex=ax_corr)\n",
    "    ax_spread_hist = fig.add_subplot(gs[1, 5])\n",
    "    ax_std = fig.add_subplot(gs[2, :5], sharex=ax_corr)\n",
    "    ax_std_hist = fig.add_subplot(gs[2, 5])\n",
    "    ax_zscore = fig.add_subplot(gs[3, :5], sharex=ax_corr)\n",
    "    ax_zscore_hist = fig.add_subplot(gs[3, 5])\n",
    "\n",
    "    lw = CHART_STYLE['linewidth']\n",
    "\n",
    "    # 1. 롤링 상관계수\n",
    "    upper_2s = (corr_mean + 2 * corr_std).clip(-1, 1)\n",
    "    lower_2s = (corr_mean - 2 * corr_std).clip(-1, 1)\n",
    "    ax_corr.fill_between(corr_filtered.index, lower_2s, upper_2s, color='#e8e8e8', alpha=0.7)\n",
    "    upper_1s = (corr_mean + corr_std).clip(-1, 1)\n",
    "    lower_1s = (corr_mean - corr_std).clip(-1, 1)\n",
    "    ax_corr.plot(corr_filtered.index, upper_1s, '--', color='red', linewidth=0.5, alpha=0.7)\n",
    "    ax_corr.plot(corr_filtered.index, lower_1s, '--', color='blue', linewidth=0.5, alpha=0.7)\n",
    "    ax_corr.plot(corr_filtered.index, corr_filtered, color='black', linewidth=lw)\n",
    "    ax_corr.axhline(y=0, color='gray', linewidth=0.5)\n",
    "    ax_corr.set_ylabel('Corr', fontsize=CHART_STYLE['label_fontsize'])\n",
    "    ax_corr.set_ylim(-1.05, 1.05)\n",
    "    ax_corr.set_title(f'{pair_name}  (Rolling {window}일)', fontsize=CHART_STYLE['title_fontsize'], fontweight='bold')\n",
    "    setup_date_axis(ax_corr, corr_filtered.index)\n",
    "    ax_corr.tick_params(axis='x', labelbottom=False)\n",
    "\n",
    "    ax_corr_hist.hist(corr_hist.dropna(), bins=30, orientation='horizontal', color='black', alpha=0.4, edgecolor='white')\n",
    "    ax_corr_hist.axhline(y=corr_filtered.iloc[-1], color='red', linewidth=1.5,\n",
    "                         label=f'{corr_filtered.iloc[-1]:.2f} ({corr_pct:.0f}%ile)')\n",
    "    ax_corr_hist.set_title(f'분포 ({hist_period_label})', fontsize=7)\n",
    "    ax_corr_hist.legend(loc='upper right', fontsize=5)\n",
    "    ax_corr_hist.yaxis.tick_right()\n",
    "    ax_corr_hist.set_ylim(-1.05, 1.05)\n",
    "\n",
    "    # 2. 스프레드\n",
    "    ax_spread.plot(spread_filtered.index, spread_filtered, color='#1f77b4', linewidth=lw)\n",
    "    ax_spread.plot(spread_mean.index, spread_mean, color='#ff7f0e', linewidth=0.8)\n",
    "    ax_spread.axhline(y=0, color='gray', linewidth=0.5)\n",
    "    ax_spread.set_ylabel('Spread', fontsize=CHART_STYLE['label_fontsize'])\n",
    "    ax_spread.tick_params(axis='x', labelbottom=False)\n",
    "\n",
    "    ax_spread_hist.hist(spread_hist.dropna(), bins=30, orientation='horizontal', color='#1f77b4', alpha=0.4, edgecolor='white')\n",
    "    ax_spread_hist.axhline(y=spread_filtered.iloc[-1], color='red', linewidth=1.5,\n",
    "                           label=f'{spread_filtered.iloc[-1]:.2f} ({spread_pct:.0f}%ile)')\n",
    "    ax_spread_hist.legend(loc='upper right', fontsize=5)\n",
    "    ax_spread_hist.yaxis.tick_right()\n",
    "\n",
    "    # 3. 변동성\n",
    "    ax_std.plot(spread_std.index, spread_std, color='#2ca02c', linewidth=lw)\n",
    "    ax_std.set_ylabel('Vol', fontsize=CHART_STYLE['label_fontsize'])\n",
    "    ax_std.tick_params(axis='x', labelbottom=False)\n",
    "\n",
    "    std_pct = stats.percentileofscore(spread_std_hist.dropna(), spread_std.iloc[-1])\n",
    "    ax_std_hist.hist(spread_std_hist.dropna(), bins=30, orientation='horizontal', color='#2ca02c', alpha=0.4, edgecolor='white')\n",
    "    ax_std_hist.axhline(y=spread_std.iloc[-1], color='red', linewidth=1.5,\n",
    "                        label=f'{spread_std.iloc[-1]:.4f} ({std_pct:.0f}%ile)')\n",
    "    ax_std_hist.legend(loc='upper right', fontsize=5)\n",
    "    ax_std_hist.yaxis.tick_right()\n",
    "\n",
    "    # 4. Z-score\n",
    "    ax_zscore.fill_between(spread_zscore.index, -2, 2, color='#e8e8e8', alpha=0.7)\n",
    "    ax_zscore.axhline(y=1, color='black', linewidth=0.5, linestyle='--', alpha=0.7)\n",
    "    ax_zscore.axhline(y=-1, color='black', linewidth=0.5, linestyle='--', alpha=0.7)\n",
    "    ax_zscore.plot(spread_zscore.index, spread_zscore, color='#ff7f0e', linewidth=lw)\n",
    "    ax_zscore.axhline(y=0, color='gray', linewidth=0.5)\n",
    "    ax_zscore.set_ylabel('Z-score', fontsize=CHART_STYLE['label_fontsize'])\n",
    "    ax_zscore.set_ylim(-4, 4)\n",
    "    setup_date_axis(ax_zscore, spread_zscore.index)\n",
    "\n",
    "    zscore_pct = stats.percentileofscore(spread_zscore_hist.dropna(), spread_zscore.iloc[-1])\n",
    "    ax_zscore_hist.hist(spread_zscore_hist.dropna(), bins=30, orientation='horizontal', color='#ff7f0e', alpha=0.4, edgecolor='white')\n",
    "    ax_zscore_hist.axhline(y=spread_zscore.iloc[-1], color='red', linewidth=1.5,\n",
    "                           label=f'{spread_zscore.iloc[-1]:.2f}σ ({zscore_pct:.0f}%ile)')\n",
    "    ax_zscore_hist.legend(loc='upper right', fontsize=5)\n",
    "    ax_zscore_hist.yaxis.tick_right()\n",
    "    ax_zscore_hist.set_ylim(-4, 4)\n",
    "\n",
    "    _all_figs.append((fig, 'rolling'))\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"  {pair_name}: corr={corr_filtered.iloc[-1]:.3f}({corr_pct:.0f}%ile) spread={spread_filtered.iloc[-1]:.4f} z={spread_zscore.iloc[-1]:.2f}σ\")\n",
    "    return {'pair_name': pair_name, 'fig': fig}\n",
    "\n",
    "\n",
    "def plot_rate_comparison(data, returns, pairs, window, start_date, end_date):\n",
    "    \"\"\"금리 수준 비교 (A4 Landscape)\"\"\"\n",
    "    plot_data = data.copy()\n",
    "    plot_returns = returns.copy()\n",
    "    if start_date:\n",
    "        plot_data = plot_data[plot_data.index >= pd.to_datetime(start_date)]\n",
    "        plot_returns = plot_returns[plot_returns.index >= pd.to_datetime(start_date)]\n",
    "    if end_date:\n",
    "        plot_data = plot_data[plot_data.index <= pd.to_datetime(end_date)]\n",
    "        plot_returns = plot_returns[plot_returns.index <= pd.to_datetime(end_date)]\n",
    "\n",
    "    n_total = len(pairs)\n",
    "    if n_total == 0: return\n",
    "    period_label = f\"{plot_data.index[0].strftime('%Y-%m-%d')} ~ {plot_data.index[-1].strftime('%Y-%m-%d')}\"\n",
    "\n",
    "    MAX_PER_PAGE = 12\n",
    "    n_pages = (n_total + MAX_PER_PAGE - 1) // MAX_PER_PAGE\n",
    "\n",
    "    for page in range(n_pages):\n",
    "        si = page * MAX_PER_PAGE\n",
    "        page_pairs = pairs[si:si + MAX_PER_PAGE]\n",
    "        n_items = len(page_pairs)\n",
    "\n",
    "        if n_items <= 2: nrows, ncols = 1, max(1, n_items)\n",
    "        elif n_items <= 4: nrows, ncols = 2, 2\n",
    "        elif n_items <= 6: nrows, ncols = 2, 3\n",
    "        elif n_items <= 9: nrows, ncols = 3, 3\n",
    "        else: nrows, ncols = 3, 4\n",
    "\n",
    "        fig, axes = plt.subplots(nrows, ncols, figsize=A4_LANDSCAPE, constrained_layout=True)\n",
    "        if nrows == 1 and ncols == 1: axes = np.array([[axes]])\n",
    "        elif nrows == 1: axes = axes.reshape(1, -1)\n",
    "        elif ncols == 1: axes = axes.reshape(-1, 1)\n",
    "\n",
    "        page_label = f\" ({page+1}/{n_pages})\" if n_pages > 1 else \"\"\n",
    "        fig.suptitle(f'금리 수준 비교{page_label}\\n{period_label}', fontsize=10, fontweight='bold')\n",
    "\n",
    "        for idx, (display_name, black_col, blue_col) in enumerate(page_pairs):\n",
    "            ax = axes[idx // ncols, idx % ncols]\n",
    "            ax.plot(plot_data.index, plot_data[black_col], color='black', linewidth=CHART_STYLE['linewidth'],\n",
    "                    label=black_col.replace('RF_', '_'))\n",
    "            ax.plot(plot_data.index, plot_data[blue_col], color=CHART_STYLE['color_secondary'],\n",
    "                    linewidth=CHART_STYLE['linewidth'], label=blue_col.replace('RF_', '_'))\n",
    "\n",
    "            corr = plot_returns[black_col].corr(plot_returns[blue_col]) if (\n",
    "                black_col in plot_returns.columns and blue_col in plot_returns.columns) else np.nan\n",
    "            ax.set_title(f\"{black_col.replace('RF_', '_')} vs {blue_col.replace('RF_', '_')}\\nr={corr:.3f}\",\n",
    "                         fontsize=7)\n",
    "            setup_date_axis(ax, plot_data.index)\n",
    "            apply_chart_style(ax)\n",
    "            ax.legend(loc='best', fontsize=5)\n",
    "\n",
    "        for idx in range(n_items, nrows * ncols):\n",
    "            axes[idx // ncols, idx % ncols].axis('off')\n",
    "\n",
    "        _all_figs.append((fig, 'comparison'))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def _get_compare_pairs(columns):\n",
    "    \"\"\"비교 쌍 자동 생성 (만기 > 등급 > 섹터 순서)\"\"\"\n",
    "    pairs = []\n",
    "    for c1, c2 in combinations(columns, 2):\n",
    "        pairs.append((f\"{c1} vs {c2}\", c1, c2))\n",
    "    return pairs\n",
    "\n",
    "\n",
    "# ── 실행 ──\n",
    "\n",
    "_all_figs = []  # (type, fig) 리스트 — Cell 6에서 저장용\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(\"Cell 3: 상관분석\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# (1) 히트맵\n",
    "print(f\"\\n[1/3] 히트맵: {CFG.corr_columns}, 모드={CFG.corr_mode}\")\n",
    "analysis_data = build_analysis_data(rates, spreads_vs_ktb, CFG.corr_columns, CFG.corr_mode)\n",
    "corr_matrix = plot_correlation_heatmap(\n",
    "    analysis_data, start_date=CFG.start_date, end_date=CFG.end_date, mode=CFG.corr_mode)\n",
    "\n",
    "# (2) 롤링 상관계수\n",
    "print(f\"\\n[2/3] 롤링 상관계수: 윈도우={CFG.rolling_window}일\")\n",
    "\n",
    "_corr_cols = CFG.corr_columns\n",
    "_corr_mode = CFG.corr_mode\n",
    "_data_full = build_analysis_data(rates, spreads_vs_ktb, _corr_cols, _corr_mode)\n",
    "\n",
    "_data_filtered = _data_full.copy()\n",
    "if CFG.start_date:\n",
    "    _data_filtered = _data_filtered[_data_filtered.index >= pd.to_datetime(CFG.start_date)]\n",
    "if CFG.end_date:\n",
    "    _data_filtered = _data_filtered[_data_filtered.index <= pd.to_datetime(CFG.end_date)]\n",
    "\n",
    "_data_hist = _data_full.copy()  # 히스토그램 기준 = 전체 기간\n",
    "\n",
    "_hist_label = f\"{_data_hist.index[0].strftime('%Y.%m')}~{_data_hist.index[-1].strftime('%Y.%m')}\"\n",
    "\n",
    "if _corr_mode in ['spreads', 'spreads_changes']:\n",
    "    _spread_names = []\n",
    "    for i, j in combinations(range(len(_corr_cols)), 2):\n",
    "        _spread_names.append(f\"{_corr_cols[j]} - {_corr_cols[i]}\")\n",
    "    _rolling_pairs = [(f\"({_spread_names[i]}) vs ({_spread_names[j]})\", _spread_names[i], _spread_names[j])\n",
    "                      for i, j in combinations(range(len(_spread_names)), 2)]\n",
    "else:\n",
    "    _rolling_pairs = [(f\"{_corr_cols[i]} vs {_corr_cols[j]}\", _corr_cols[i], _corr_cols[j])\n",
    "                      for i, j in combinations(range(len(_corr_cols)), 2)]\n",
    "\n",
    "for pair_name, col1, col2 in _rolling_pairs:\n",
    "    plot_rolling_analysis(_data_full, _data_filtered, _data_hist, col1, col2,\n",
    "                          pair_name, CFG.rolling_window, _hist_label)\n",
    "\n",
    "# (3) 금리 수준 비교\n",
    "print(f\"\\n[3/3] 금리 수준 비교: {len(CFG.compare_columns)}종목\")\n",
    "_compare_pairs = _get_compare_pairs(CFG.compare_columns)\n",
    "_compare_returns = rates[CFG.compare_columns].diff().dropna()\n",
    "plot_rate_comparison(rates, _compare_returns, _compare_pairs, CFG.rolling_window,\n",
    "                     CFG.compare_start, CFG.compare_end)\n",
    "\n",
    "print(f\"\\nCell 3 완료: 상관분석 ({len(_all_figs)}개 차트)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ══════════════════════════════════════════════════════════════\n",
    "# Cell 4: 기술적 지표 대시보드\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ── Step 1: 데이터 준비 ──────────────────────────────────────\n",
    "\n",
    "tier = tier_detector.detect(CFG.target)\n",
    "is_yield = CFG.data_source in ('bond_close', 'bond_ohlcv', 'futures_yield')\n",
    "\n",
    "if CFG.data_source == 'bond_close':\n",
    "    col_name = [c for c in rates.columns\n",
    "                if CFG.target.replace(' ', '') in c.replace(' ', '')]\n",
    "    if not col_name:\n",
    "        raise ValueError(f\"종목 '{CFG.target}' not found in rates\")\n",
    "    close_series = rates[col_name[0]].dropna()\n",
    "    ohlcv_df = pd.DataFrame({'close': close_series})\n",
    "    current_tier = '2'\n",
    "elif CFG.data_source == 'bond_ohlcv':\n",
    "    ohlcv_df = tier_detector.get_ohlcv(CFG.target, source_preference='bond_ohlcv')\n",
    "    if ohlcv_df is None:\n",
    "        raise ValueError(f\"종목 '{CFG.target}'에 대한 OHLCV 데이터 없음\")\n",
    "    current_tier = '1b'\n",
    "elif CFG.data_source == 'futures_price':\n",
    "    ohlcv_df = tier_detector.get_ohlcv(CFG.target, mode='price')\n",
    "    if ohlcv_df is None:\n",
    "        raise ValueError(f\"종목 '{CFG.target}'에 대한 선물 가격 데이터 없음\")\n",
    "    current_tier = tier.tier\n",
    "elif CFG.data_source == 'futures_yield':\n",
    "    ohlcv_df = tier_detector.get_ohlcv(CFG.target, mode='yield')\n",
    "    if ohlcv_df is None:\n",
    "        raise ValueError(f\"종목 '{CFG.target}'에 대한 선물 수익률 데이터 없음\")\n",
    "    current_tier = tier.tier\n",
    "else:\n",
    "    raise ValueError(f\"알 수 없는 data_source: {CFG.data_source}\")\n",
    "\n",
    "# 기간 필터\n",
    "if CFG.start_date:\n",
    "    ohlcv_df = ohlcv_df[ohlcv_df.index >= pd.to_datetime(CFG.start_date)]\n",
    "if CFG.end_date:\n",
    "    ohlcv_df = ohlcv_df[ohlcv_df.index <= pd.to_datetime(CFG.end_date)]\n",
    "\n",
    "if ohlcv_df.empty:\n",
    "    raise ValueError(\"필터링 후 데이터가 없습니다\")\n",
    "\n",
    "# 지표 계산\n",
    "indicators = {}\n",
    "indicators.update(price_trend_engine.compute_all(ohlcv_df, current_tier))\n",
    "indicators.update(vol_momentum_engine.compute_all(ohlcv_df, current_tier))\n",
    "indicators.update(volume_engine.compute_all(ohlcv_df, current_tier))\n",
    "\n",
    "# 편의 변수\n",
    "close = ohlcv_df['close']\n",
    "dates = ohlcv_df.index\n",
    "has_ohlc = all(c in ohlcv_df.columns for c in ['open', 'high', 'low', 'close'])\n",
    "has_volume = ('volume' in ohlcv_df.columns\n",
    "              and ohlcv_df['volume'].notna().any())\n",
    "\n",
    "# MA 색상\n",
    "MA_COLORS = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "\n",
    "# ── Step 2: 결과 수집 리스트 ─────────────────────────────────\n",
    "_all_figs = []\n",
    "\n",
    "\n",
    "# ── 유틸리티 ─────────────────────────────────────────────────\n",
    "\n",
    "def _style_ax(ax):\n",
    "    \"\"\"apply_chart_style + 스파인 제거\"\"\"\n",
    "    apply_chart_style(ax)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "\n",
    "def _finish_figure(fig, name='chart', tight_pad=1.5):\n",
    "    \"\"\"tight_layout 적용 후 _all_figs에 (fig, name) 튜플로 추가\"\"\"\n",
    "    fig.tight_layout(pad=tight_pad)\n",
    "    _all_figs.append((fig, name))\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# Page 1: 가격 + 추세 (A4 Portrait)\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "_p1_ratios = [4, 2, 2, 1, 1]\n",
    "fig1, axes1 = plt.subplots(\n",
    "    len(_p1_ratios), 1,\n",
    "    figsize=A4_PORTRAIT,\n",
    "    height_ratios=_p1_ratios,\n",
    "    sharex=True,\n",
    ")\n",
    "\n",
    "# ── Panel 1: Close + MA + Bollinger Bands ──\n",
    "ax = axes1[0]\n",
    "ax.plot(dates, close, color='black', linewidth=CHART_STYLE['linewidth'],\n",
    "        label='Close', zorder=3)\n",
    "\n",
    "# SMA overlays\n",
    "_sma_periods = [5, 20, 60, 120]\n",
    "for i, p in enumerate(_sma_periods):\n",
    "    key = f'SMA_{p}'\n",
    "    if key in indicators:\n",
    "        ax.plot(dates, indicators[key],\n",
    "                color=MA_COLORS[i % len(MA_COLORS)],\n",
    "                linewidth=CHART_STYLE['linewidth'],\n",
    "                label=key, alpha=0.8)\n",
    "\n",
    "# Bollinger Bands\n",
    "if 'BB_upper' in indicators:\n",
    "    ax.plot(dates, indicators['BB_upper'], color='gray',\n",
    "            linewidth=0.5, linestyle='--', alpha=0.6)\n",
    "    ax.plot(dates, indicators['BB_lower'], color='gray',\n",
    "            linewidth=0.5, linestyle='--', alpha=0.6)\n",
    "    ax.fill_between(dates, indicators['BB_upper'], indicators['BB_lower'],\n",
    "                    alpha=0.06, color='gray')\n",
    "\n",
    "ax.set_ylabel('수익률 (%)' if is_yield else '가격',\n",
    "              fontsize=CHART_STYLE['label_fontsize'])\n",
    "ax.legend(loc='upper left', fontsize=CHART_STYLE['legend_fontsize'],\n",
    "          ncol=3, framealpha=0.7)\n",
    "ax.set_title(f'{CFG.target} — 가격 + 추세 지표 ({CFG.data_source})',\n",
    "             fontsize=CHART_STYLE['title_fontsize'], fontweight='bold')\n",
    "_style_ax(ax)\n",
    "\n",
    "# ── Panel 2: MACD ──\n",
    "ax = axes1[1]\n",
    "if 'MACD' in indicators:\n",
    "    ax.plot(dates, indicators['MACD'], color='#1f77b4',\n",
    "            linewidth=CHART_STYLE['linewidth'], label='MACD')\n",
    "    ax.plot(dates, indicators['MACD_signal'], color='#ff7f0e',\n",
    "            linewidth=CHART_STYLE['linewidth'], label='Signal')\n",
    "    hist = indicators['MACD_hist']\n",
    "    colors_hist = ['#2ca02c' if v >= 0 else '#d62728'\n",
    "                   for v in hist.values]\n",
    "    ax.bar(dates, hist, color=colors_hist, width=0.8, alpha=0.6)\n",
    "    ax.axhline(0, color='black', linewidth=0.3)\n",
    "    ax.legend(loc='upper left', fontsize=CHART_STYLE['legend_fontsize'])\n",
    "ax.set_ylabel('MACD', fontsize=CHART_STYLE['label_fontsize'])\n",
    "_style_ax(ax)\n",
    "\n",
    "# ── Panel 3: DMI (+DI, -DI, ADX) ──\n",
    "ax = axes1[2]\n",
    "if 'DMI_plus_di' in indicators:\n",
    "    ax.plot(dates, indicators['DMI_plus_di'], color='#2ca02c',\n",
    "            linewidth=CHART_STYLE['linewidth'], label='+DI')\n",
    "    ax.plot(dates, indicators['DMI_minus_di'], color='#d62728',\n",
    "            linewidth=CHART_STYLE['linewidth'], label='-DI')\n",
    "    ax.plot(dates, indicators['DMI_adx'], color='black',\n",
    "            linewidth=CHART_STYLE['linewidth'], label='ADX')\n",
    "    ax.axhline(25, color='gray', linewidth=0.4, linestyle='--', alpha=0.5)\n",
    "    ax.legend(loc='upper left', fontsize=CHART_STYLE['legend_fontsize'])\n",
    "elif current_tier == '2':\n",
    "    ax.text(0.5, 0.5, 'DMI: OHLC 데이터 필요 (Tier 2 미지원)',\n",
    "            transform=ax.transAxes, ha='center', va='center',\n",
    "            fontsize=CHART_STYLE['label_fontsize'], color='gray')\n",
    "ax.set_ylabel('DMI', fontsize=CHART_STYLE['label_fontsize'])\n",
    "_style_ax(ax)\n",
    "\n",
    "# ── Panel 4: CCI ──\n",
    "ax = axes1[3]\n",
    "if 'CCI' in indicators:\n",
    "    ax.plot(dates, indicators['CCI'], color='#9467bd',\n",
    "            linewidth=CHART_STYLE['linewidth'])\n",
    "    ax.axhline(100, color='red', linewidth=0.4, linestyle='--', alpha=0.6)\n",
    "    ax.axhline(-100, color='green', linewidth=0.4, linestyle='--', alpha=0.6)\n",
    "    ax.axhline(0, color='black', linewidth=0.3)\n",
    "elif current_tier == '2':\n",
    "    ax.text(0.5, 0.5, 'CCI: OHLC 데이터 필요',\n",
    "            transform=ax.transAxes, ha='center', va='center',\n",
    "            fontsize=CHART_STYLE['label_fontsize'], color='gray')\n",
    "ax.set_ylabel('CCI', fontsize=CHART_STYLE['label_fontsize'])\n",
    "_style_ax(ax)\n",
    "\n",
    "# ── Panel 5: SONAR ──\n",
    "ax = axes1[4]\n",
    "if 'SONAR' in indicators:\n",
    "    ax.plot(dates, indicators['SONAR'], color='#8c564b',\n",
    "            linewidth=CHART_STYLE['linewidth'])\n",
    "    ax.axhline(0, color='black', linewidth=0.3)\n",
    "ax.set_ylabel('SONAR', fontsize=CHART_STYLE['label_fontsize'])\n",
    "_style_ax(ax)\n",
    "setup_date_axis(ax, dates)\n",
    "\n",
    "_finish_figure(fig1, 'price_trend')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# Page 2: 모멘텀 + 과매수/과매도 (A4 Portrait)\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "_p2_ratios = [3, 2, 2, 1.5, 1.5]\n",
    "fig2, axes2 = plt.subplots(\n",
    "    len(_p2_ratios), 1,\n",
    "    figsize=A4_PORTRAIT,\n",
    "    height_ratios=_p2_ratios,\n",
    "    sharex=True,\n",
    ")\n",
    "\n",
    "# ── Panel 1: Close + Bollinger Bands ──\n",
    "ax = axes2[0]\n",
    "ax.plot(dates, close, color='black', linewidth=CHART_STYLE['linewidth'],\n",
    "        label='Close', zorder=3)\n",
    "\n",
    "if 'BB_upper' in indicators:\n",
    "    ax.plot(dates, indicators['BB_middle'], color='#1f77b4',\n",
    "            linewidth=0.5, linestyle='--', label='BB Mid', alpha=0.7)\n",
    "    ax.plot(dates, indicators['BB_upper'], color='gray',\n",
    "            linewidth=0.5, linestyle='--', alpha=0.5)\n",
    "    ax.plot(dates, indicators['BB_lower'], color='gray',\n",
    "            linewidth=0.5, linestyle='--', alpha=0.5)\n",
    "    ax.fill_between(dates, indicators['BB_upper'], indicators['BB_lower'],\n",
    "                    alpha=0.08, color='#1f77b4', label='BB Band')\n",
    "\n",
    "ax.set_ylabel('수익률 (%)' if is_yield else '가격',\n",
    "              fontsize=CHART_STYLE['label_fontsize'])\n",
    "ax.legend(loc='upper left', fontsize=CHART_STYLE['legend_fontsize'],\n",
    "          ncol=2, framealpha=0.7)\n",
    "ax.set_title(f'{CFG.target} — 모멘텀 지표 ({CFG.data_source})',\n",
    "             fontsize=CHART_STYLE['title_fontsize'], fontweight='bold')\n",
    "_style_ax(ax)\n",
    "\n",
    "# ── Panel 2: RSI ──\n",
    "ax = axes2[1]\n",
    "if 'RSI' in indicators:\n",
    "    rsi = indicators['RSI']\n",
    "    ax.plot(dates, rsi, color='#9467bd',\n",
    "            linewidth=CHART_STYLE['linewidth'], label='RSI')\n",
    "    ax.axhline(INDICATOR_CONFIG.rsi_overbought, color='red',\n",
    "               linewidth=0.4, linestyle='--', alpha=0.6)\n",
    "    ax.axhline(INDICATOR_CONFIG.rsi_oversold, color='green',\n",
    "               linewidth=0.4, linestyle='--', alpha=0.6)\n",
    "    # overbought/oversold fill\n",
    "    ax.fill_between(dates, INDICATOR_CONFIG.rsi_overbought, 100,\n",
    "                    alpha=0.06, color='red')\n",
    "    ax.fill_between(dates, 0, INDICATOR_CONFIG.rsi_oversold,\n",
    "                    alpha=0.06, color='green')\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.legend(loc='upper left', fontsize=CHART_STYLE['legend_fontsize'])\n",
    "ax.set_ylabel('RSI', fontsize=CHART_STYLE['label_fontsize'])\n",
    "_style_ax(ax)\n",
    "\n",
    "# ── Panel 3: Stochastic %K / %D ──\n",
    "ax = axes2[2]\n",
    "if 'Stoch_K' in indicators:\n",
    "    ax.plot(dates, indicators['Stoch_K'], color='#1f77b4',\n",
    "            linewidth=CHART_STYLE['linewidth'], label='%K')\n",
    "    ax.plot(dates, indicators['Stoch_D'], color='#d62728',\n",
    "            linewidth=CHART_STYLE['linewidth'], label='%D')\n",
    "    ax.axhline(80, color='red', linewidth=0.4, linestyle='--', alpha=0.6)\n",
    "    ax.axhline(20, color='green', linewidth=0.4, linestyle='--', alpha=0.6)\n",
    "    ax.fill_between(dates, 80, 100, alpha=0.06, color='red')\n",
    "    ax.fill_between(dates, 0, 20, alpha=0.06, color='green')\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.legend(loc='upper left', fontsize=CHART_STYLE['legend_fontsize'])\n",
    "ax.set_ylabel('Stochastic', fontsize=CHART_STYLE['label_fontsize'])\n",
    "_style_ax(ax)\n",
    "\n",
    "# ── Panel 4: Williams %R ──\n",
    "ax = axes2[3]\n",
    "if 'Williams_R' in indicators:\n",
    "    ax.plot(dates, indicators['Williams_R'], color='#8c564b',\n",
    "            linewidth=CHART_STYLE['linewidth'])\n",
    "    ax.axhline(-20, color='red', linewidth=0.4, linestyle='--', alpha=0.6)\n",
    "    ax.axhline(-80, color='green', linewidth=0.4, linestyle='--', alpha=0.6)\n",
    "    ax.fill_between(dates, -20, 0, alpha=0.06, color='red')\n",
    "    ax.fill_between(dates, -100, -80, alpha=0.06, color='green')\n",
    "    ax.set_ylim(-100, 0)\n",
    "ax.set_ylabel('Williams %R', fontsize=CHART_STYLE['label_fontsize'])\n",
    "_style_ax(ax)\n",
    "\n",
    "# ── Panel 5: Bollinger %B + Bandwidth ──\n",
    "ax = axes2[4]\n",
    "if 'BB_pctb' in indicators:\n",
    "    ax.plot(dates, indicators['BB_pctb'], color='#1f77b4',\n",
    "            linewidth=CHART_STYLE['linewidth'], label='%B')\n",
    "    ax.axhline(1.0, color='red', linewidth=0.3, linestyle=':', alpha=0.5)\n",
    "    ax.axhline(0.0, color='green', linewidth=0.3, linestyle=':', alpha=0.5)\n",
    "    ax.axhline(0.5, color='gray', linewidth=0.3, linestyle=':', alpha=0.4)\n",
    "    ax.legend(loc='upper left', fontsize=CHART_STYLE['legend_fontsize'])\n",
    "\n",
    "if 'BB_bandwidth' in indicators:\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(dates, indicators['BB_bandwidth'], color='#ff7f0e',\n",
    "             linewidth=CHART_STYLE['linewidth'], alpha=0.7, label='Bandwidth')\n",
    "    ax2.set_ylabel('Bandwidth (%)', fontsize=CHART_STYLE['label_fontsize'])\n",
    "    ax2.tick_params(axis='y', labelsize=CHART_STYLE['tick_fontsize'])\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.legend(loc='upper right', fontsize=CHART_STYLE['legend_fontsize'])\n",
    "\n",
    "ax.set_ylabel('Bollinger %B', fontsize=CHART_STYLE['label_fontsize'])\n",
    "_style_ax(ax)\n",
    "setup_date_axis(ax, dates)\n",
    "\n",
    "_finish_figure(fig2, 'momentum')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# Page 3: 변동성 + 거래량 (A4 Portrait)\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "# 거래량 패널 존재 여부에 따라 레이아웃 결정\n",
    "_vol_panels_available = []\n",
    "if has_volume and 'OBV' in indicators:\n",
    "    _vol_panels_available.append('OBV')\n",
    "if has_volume and 'CMF' in indicators:\n",
    "    _vol_panels_available.append('CMF')\n",
    "if has_volume and 'AD_Line' in indicators:\n",
    "    _vol_panels_available.append('AD_Line')\n",
    "\n",
    "# 기본 3패널 (Close+Vol, ATR, Chaikin) + 거래량 지표 수만큼 추가\n",
    "_p3_base = [3, 1.5, 1.5]\n",
    "_p3_vol_ratios = [1.25] * len(_vol_panels_available)\n",
    "_p3_ratios = _p3_base + _p3_vol_ratios\n",
    "_p3_count = len(_p3_ratios)\n",
    "\n",
    "fig3, axes3 = plt.subplots(\n",
    "    _p3_count, 1,\n",
    "    figsize=A4_PORTRAIT,\n",
    "    height_ratios=_p3_ratios,\n",
    "    sharex=True,\n",
    ")\n",
    "if _p3_count == 1:\n",
    "    axes3 = [axes3]\n",
    "\n",
    "# ── Panel 1: Close + Volume (dual y-axis) ──\n",
    "ax = axes3[0]\n",
    "ax.plot(dates, close, color='black', linewidth=CHART_STYLE['linewidth'],\n",
    "        label='Close', zorder=3)\n",
    "\n",
    "if has_volume:\n",
    "    ax_vol = ax.twinx()\n",
    "    vol = ohlcv_df['volume']\n",
    "    ax_vol.bar(dates, vol, width=0.8, color='#7f7f7f', alpha=0.25,\n",
    "               label='Volume', zorder=1)\n",
    "    ax_vol.set_ylabel('거래량', fontsize=CHART_STYLE['label_fontsize'])\n",
    "    ax_vol.tick_params(axis='y', labelsize=CHART_STYLE['tick_fontsize'])\n",
    "    ax_vol.spines['top'].set_visible(False)\n",
    "    # 거래량 축 상단 30% 영역에 표시 (가격 차트와 겹치지 않게)\n",
    "    if vol.max() > 0:\n",
    "        ax_vol.set_ylim(0, vol.max() * 3.5)\n",
    "    ax_vol.legend(loc='upper right', fontsize=CHART_STYLE['legend_fontsize'])\n",
    "\n",
    "ax.set_ylabel('수익률 (%)' if is_yield else '가격',\n",
    "              fontsize=CHART_STYLE['label_fontsize'])\n",
    "ax.legend(loc='upper left', fontsize=CHART_STYLE['legend_fontsize'])\n",
    "ax.set_title(f'{CFG.target} — 변동성 + 거래량 지표 ({CFG.data_source})',\n",
    "             fontsize=CHART_STYLE['title_fontsize'], fontweight='bold')\n",
    "_style_ax(ax)\n",
    "\n",
    "# ── Panel 2: ATR ──\n",
    "ax = axes3[1]\n",
    "if 'ATR' in indicators:\n",
    "    ax.plot(dates, indicators['ATR'], color='#ff7f0e',\n",
    "            linewidth=CHART_STYLE['linewidth'])\n",
    "elif current_tier == '2':\n",
    "    ax.text(0.5, 0.5, 'ATR: OHLC 데이터 필요',\n",
    "            transform=ax.transAxes, ha='center', va='center',\n",
    "            fontsize=CHART_STYLE['label_fontsize'], color='gray')\n",
    "ax.set_ylabel('ATR', fontsize=CHART_STYLE['label_fontsize'])\n",
    "_style_ax(ax)\n",
    "\n",
    "# ── Panel 3: Chaikin Volatility ──\n",
    "ax = axes3[2]\n",
    "if 'Chaikin_Vol' in indicators:\n",
    "    ax.plot(dates, indicators['Chaikin_Vol'], color='#8c564b',\n",
    "            linewidth=CHART_STYLE['linewidth'])\n",
    "    ax.axhline(0, color='black', linewidth=0.3)\n",
    "elif current_tier == '2':\n",
    "    ax.text(0.5, 0.5, 'Chaikin Vol: OHLC 데이터 필요',\n",
    "            transform=ax.transAxes, ha='center', va='center',\n",
    "            fontsize=CHART_STYLE['label_fontsize'], color='gray')\n",
    "ax.set_ylabel('Chaikin Vol', fontsize=CHART_STYLE['label_fontsize'])\n",
    "_style_ax(ax)\n",
    "\n",
    "# ── 거래량 패널들 (3, 4, 5) — 거래량 있을 때만 ──\n",
    "if _vol_panels_available:\n",
    "    _vol_panel_idx = 3\n",
    "\n",
    "    # Panel 4: OBV\n",
    "    if 'OBV' in _vol_panels_available:\n",
    "        ax = axes3[_vol_panel_idx]\n",
    "        ax.plot(dates, indicators['OBV'], color='teal',\n",
    "                linewidth=CHART_STYLE['linewidth'])\n",
    "        ax.set_ylabel('OBV', fontsize=CHART_STYLE['label_fontsize'])\n",
    "        _style_ax(ax)\n",
    "        _vol_panel_idx += 1\n",
    "\n",
    "    # Panel 5: CMF\n",
    "    if 'CMF' in _vol_panels_available:\n",
    "        ax = axes3[_vol_panel_idx]\n",
    "        cmf = indicators['CMF']\n",
    "        colors_cmf = ['#2ca02c' if v >= 0 else '#d62728' for v in cmf.values]\n",
    "        ax.bar(dates, cmf, width=0.8, color=colors_cmf, alpha=0.6)\n",
    "        ax.axhline(0, color='black', linewidth=0.3)\n",
    "        ax.set_ylabel('CMF', fontsize=CHART_STYLE['label_fontsize'])\n",
    "        _style_ax(ax)\n",
    "        _vol_panel_idx += 1\n",
    "\n",
    "    # Panel 6: A/D Line\n",
    "    if 'AD_Line' in _vol_panels_available:\n",
    "        ax = axes3[_vol_panel_idx]\n",
    "        ax.plot(dates, indicators['AD_Line'], color='#9467bd',\n",
    "                linewidth=CHART_STYLE['linewidth'])\n",
    "        ax.set_ylabel('A/D Line', fontsize=CHART_STYLE['label_fontsize'])\n",
    "        _style_ax(ax)\n",
    "        _vol_panel_idx += 1\n",
    "\n",
    "# 하단 축 날짜 포맷\n",
    "setup_date_axis(axes3[-1], dates)\n",
    "\n",
    "_finish_figure(fig3, 'volatility_volume')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# Page 4: 특수차트 갤러리 (A4 Landscape) — 조건부\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "_show_page4 = (getattr(CFG, 'show_special_charts', False)\n",
    "               and has_ohlc)\n",
    "\n",
    "if _show_page4:\n",
    "    # 주석 텍스트\n",
    "    _annotations = {\n",
    "        'candlestick': '녹색=금리하락(채권강세), 적색=금리상승(채권약세)',\n",
    "        'pnf': 'X=금리상승, O=금리하락. 시간축 무관, 추세전환만 표시',\n",
    "        'three_line': '최근3봉 돌파시만 신규봉 생성. 노이즈 제거',\n",
    "        'counter_clock': '우상향→매집, 좌하향→분산. 시계 역방향 순환',\n",
    "        'volume_profile': 'POC(적색선)=최대거래 가격대. 지지/저항 판별',\n",
    "        'candle_volume': '캔들+거래량 동시 표시. 거래량 급증 구간 주목',\n",
    "    }\n",
    "\n",
    "    fig4, axes4 = plt.subplots(\n",
    "        2, 3,\n",
    "        figsize=A4_LANDSCAPE,\n",
    "    )\n",
    "\n",
    "    fig4.suptitle(f'{CFG.target} — 특수차트 갤러리',\n",
    "                  fontsize=CHART_STYLE['title_fontsize'], fontweight='bold',\n",
    "                  y=0.98)\n",
    "\n",
    "    # 최근 60일 슬라이스\n",
    "    _last60 = ohlcv_df.iloc[-60:] if len(ohlcv_df) > 60 else ohlcv_df\n",
    "\n",
    "    # (0,0) Candlestick\n",
    "    ax = axes4[0, 0]\n",
    "    try:\n",
    "        chart_renderer.candlestick(_last60, ax=ax,\n",
    "                                   title='캔들차트 (최근 60일)',\n",
    "                                   is_yield=is_yield)\n",
    "    except Exception:\n",
    "        ax.text(0.5, 0.5, '캔들차트 렌더링 실패',\n",
    "                transform=ax.transAxes, ha='center', va='center',\n",
    "                fontsize=CHART_STYLE['label_fontsize'], color='gray')\n",
    "    ax.text(0.5, -0.10, _annotations['candlestick'],\n",
    "            transform=ax.transAxes, ha='center',\n",
    "            fontsize=6, style='italic', color='#555555')\n",
    "    _style_ax(ax)\n",
    "\n",
    "    # (0,1) Point & Figure\n",
    "    ax = axes4[0, 1]\n",
    "    try:\n",
    "        chart_renderer.point_and_figure(close, ax=ax,\n",
    "                                        title='Point & Figure')\n",
    "    except Exception:\n",
    "        ax.text(0.5, 0.5, 'P&F 렌더링 실패',\n",
    "                transform=ax.transAxes, ha='center', va='center',\n",
    "                fontsize=CHART_STYLE['label_fontsize'], color='gray')\n",
    "    ax.text(0.5, -0.10, _annotations['pnf'],\n",
    "            transform=ax.transAxes, ha='center',\n",
    "            fontsize=6, style='italic', color='#555555')\n",
    "    _style_ax(ax)\n",
    "\n",
    "    # (0,2) Three Line Break\n",
    "    ax = axes4[0, 2]\n",
    "    try:\n",
    "        chart_renderer.three_line_break(close, ax=ax,\n",
    "                                        title='삼선전환도')\n",
    "    except Exception:\n",
    "        ax.text(0.5, 0.5, '삼선전환도 렌더링 실패',\n",
    "                transform=ax.transAxes, ha='center', va='center',\n",
    "                fontsize=CHART_STYLE['label_fontsize'], color='gray')\n",
    "    ax.text(0.5, -0.10, _annotations['three_line'],\n",
    "            transform=ax.transAxes, ha='center',\n",
    "            fontsize=6, style='italic', color='#555555')\n",
    "    _style_ax(ax)\n",
    "\n",
    "    # (1,0) Counter Clockwise — 거래량 필요\n",
    "    ax = axes4[1, 0]\n",
    "    if has_volume:\n",
    "        try:\n",
    "            chart_renderer.counter_clockwise(close, ohlcv_df['volume'],\n",
    "                                             ax=ax, title='역시계곡선')\n",
    "        except Exception:\n",
    "            ax.text(0.5, 0.5, '역시계곡선 렌더링 실패',\n",
    "                    transform=ax.transAxes, ha='center', va='center',\n",
    "                    fontsize=CHART_STYLE['label_fontsize'], color='gray')\n",
    "        ax.text(0.5, -0.10, _annotations['counter_clock'],\n",
    "                transform=ax.transAxes, ha='center',\n",
    "                fontsize=6, style='italic', color='#555555')\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, '역시계곡선: 거래량 데이터 필요',\n",
    "                transform=ax.transAxes, ha='center', va='center',\n",
    "                fontsize=CHART_STYLE['label_fontsize'], color='gray')\n",
    "        ax.set_title('역시계곡선', fontsize=CHART_STYLE['label_fontsize'])\n",
    "    _style_ax(ax)\n",
    "\n",
    "    # (1,1) Volume Profile — 거래량 필요\n",
    "    ax = axes4[1, 1]\n",
    "    if has_volume:\n",
    "        try:\n",
    "            chart_renderer.volume_profile(close, ohlcv_df['volume'],\n",
    "                                          ax=ax, title='볼륨프로파일')\n",
    "        except Exception:\n",
    "            ax.text(0.5, 0.5, '볼륨프로파일 렌더링 실패',\n",
    "                    transform=ax.transAxes, ha='center', va='center',\n",
    "                    fontsize=CHART_STYLE['label_fontsize'], color='gray')\n",
    "        ax.text(0.5, -0.10, _annotations['volume_profile'],\n",
    "                transform=ax.transAxes, ha='center',\n",
    "                fontsize=6, style='italic', color='#555555')\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, '볼륨프로파일: 거래량 데이터 필요',\n",
    "                transform=ax.transAxes, ha='center', va='center',\n",
    "                fontsize=CHART_STYLE['label_fontsize'], color='gray')\n",
    "        ax.set_title('볼륨프로파일', fontsize=CHART_STYLE['label_fontsize'])\n",
    "    _style_ax(ax)\n",
    "\n",
    "    # (1,2) Candle Volume — 거래량 + OHLC 필요\n",
    "    ax = axes4[1, 2]\n",
    "    if has_volume:\n",
    "        try:\n",
    "            # candle_volume expects (ax_price, ax_vol) but we only have\n",
    "            # a single axis in the grid — render candlestick with volume overlay\n",
    "            chart_renderer.candlestick(_last60, ax=ax,\n",
    "                                       title='캔들볼륨 (최근 60일)',\n",
    "                                       is_yield=is_yield)\n",
    "            # overlay volume as secondary axis\n",
    "            ax_cv = ax.twinx()\n",
    "            vol_60 = _last60['volume']\n",
    "            _cv_dates = mdates.date2num(_last60.index.to_pydatetime())\n",
    "            ax_cv.bar(_cv_dates, vol_60, width=0.4, color='gray',\n",
    "                      alpha=0.2, zorder=0)\n",
    "            ax_cv.set_ylabel('거래량', fontsize=5)\n",
    "            ax_cv.tick_params(axis='y', labelsize=5)\n",
    "            if vol_60.max() > 0:\n",
    "                ax_cv.set_ylim(0, vol_60.max() * 4)\n",
    "            ax_cv.spines['top'].set_visible(False)\n",
    "        except Exception:\n",
    "            ax.text(0.5, 0.5, '캔들볼륨 렌더링 실패',\n",
    "                    transform=ax.transAxes, ha='center', va='center',\n",
    "                    fontsize=CHART_STYLE['label_fontsize'], color='gray')\n",
    "        ax.text(0.5, -0.10, _annotations['candle_volume'],\n",
    "                transform=ax.transAxes, ha='center',\n",
    "                fontsize=6, style='italic', color='#555555')\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, '캔들볼륨: 거래량 데이터 필요',\n",
    "                transform=ax.transAxes, ha='center', va='center',\n",
    "                fontsize=CHART_STYLE['label_fontsize'], color='gray')\n",
    "        ax.set_title('캔들볼륨', fontsize=CHART_STYLE['label_fontsize'])\n",
    "    _style_ax(ax)\n",
    "\n",
    "    _finish_figure(fig4, 'special_charts', tight_pad=2.0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# Summary\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"종목: {CFG.target} | 소스: {CFG.data_source}\")\n",
    "print(f\"기간: {ohlcv_df.index[0].date()} ~ {ohlcv_df.index[-1].date()}\")\n",
    "print(f\"산출 지표 수: {len(indicators)}\")\n",
    "print(f\"생성 차트: {len(_all_figs)}페이지\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ══════════════════════════════════════════════════════════════\n",
    "# Cell 5: 시그널 종합 대시보드\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy as np\n",
    "from scipy.stats import percentileofscore\n",
    "\n",
    "# ── 게이지 기간 업데이트 ─────────────────────────────────────\n",
    "INDICATOR_CONFIG.gauge_short = CFG.gauge_short\n",
    "INDICATOR_CONFIG.gauge_medium = CFG.gauge_medium\n",
    "INDICATOR_CONFIG.gauge_long = CFG.gauge_long\n",
    "\n",
    "# ── 시그널 분류 ──────────────────────────────────────────────\n",
    "signals = signal_classifier.classify_all(indicators, ohlcv_df['close'])\n",
    "composite = signal_classifier.composite_score(signals)\n",
    "\n",
    "# ── 백분위 재계산 (방어적: 'full' 키 보장 + 정확도 향상) ──────\n",
    "SIGNAL_INDICATOR_MAP = {\n",
    "    'RSI': 'RSI', 'Stochastic': 'Stoch_K', 'Williams %R': 'Williams_R',\n",
    "    'MACD': 'MACD_hist', 'DMI': 'DMI_adx', 'CCI': 'CCI',\n",
    "    'Bollinger': 'BB_pctb', 'ATR': 'ATR', 'OBV': 'OBV', 'CMF': 'CMF',\n",
    "    'SONAR': 'SONAR', 'Chaikin Vol': 'Chaikin_Vol', 'A/D Line': 'AD_Line',\n",
    "}\n",
    "\n",
    "def _recompute_gauges(series, short_w, med_w, long_w):\n",
    "    \"\"\"indicators dict에서 직접 백분위 재계산\"\"\"\n",
    "    val = series.iloc[-1]\n",
    "    if np.isnan(val):\n",
    "        return {'full': 0.5, 'short': 0.5, 'medium': 0.5, 'long': 0.5}\n",
    "\n",
    "    def _pct(subset):\n",
    "        s = subset.dropna()\n",
    "        if len(s) < 5:\n",
    "            return 0.5\n",
    "        return percentileofscore(s.values, val, kind='rank') / 100.0\n",
    "\n",
    "    return {\n",
    "        'full': _pct(series),\n",
    "        'short': _pct(series.iloc[-short_w:]),\n",
    "        'medium': _pct(series.iloc[-med_w:]),\n",
    "        'long': _pct(series.iloc[-long_w:]),\n",
    "    }\n",
    "\n",
    "for _sig in signals:\n",
    "    _ind_key = SIGNAL_INDICATOR_MAP.get(_sig.name)\n",
    "    if _ind_key and _ind_key in indicators and _sig.signal != 'n/a':\n",
    "        _series = indicators[_ind_key]\n",
    "        if len(_series.dropna()) >= 5:\n",
    "            _sig.rel_gauges = _recompute_gauges(\n",
    "                _series, CFG.gauge_short, CFG.gauge_medium, CFG.gauge_long\n",
    "            )\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# Goldman Sachs 스타일 색상\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "C_BUY     = '#0a7c42'   # 포레스트 그린\n",
    "C_SELL    = '#b82025'   # 딥 레드\n",
    "C_NEUTRAL = '#555555'   # 미디엄 그레이\n",
    "C_NA      = '#aaaaaa'\n",
    "C_HDR_BG  = '#2d2d2d'   # 차콜\n",
    "C_HDR_FG  = '#f5f5f5'   # 오프화이트\n",
    "C_CAT_BG  = '#f0f0f0'   # 라이트 그레이\n",
    "C_CAT_FG  = '#333333'\n",
    "C_ROW_ODD = '#ffffff'\n",
    "C_ROW_EVEN= '#f9f9f9'\n",
    "C_BORDER  = '#d0d0d0'   # 라이트 보더\n",
    "C_BG      = '#ffffff'\n",
    "C_TITLE   = '#1a1a1a'   # 니어 블랙\n",
    "C_ACCENT  = '#0054a6'   # 블루 악센트\n",
    "\n",
    "# ── 카테고리 정의 ──\n",
    "CATEGORY_MAP = {\n",
    "    'trend':      ('추세',    ['MACD', 'DMI', 'CCI', 'SONAR', 'Bollinger']),\n",
    "    'momentum':   ('모멘텀',  ['RSI', 'Stochastic', 'Williams %R']),\n",
    "    'volatility': ('변동성',  ['ATR', 'Chaikin Vol', 'Bollinger']),\n",
    "    'volume':     ('거래량',  ['OBV', 'CMF', 'A/D Line']),\n",
    "}\n",
    "CAT_ORDER = ['trend', 'momentum', 'volatility', 'volume']\n",
    "\n",
    "# ── 기간 라벨 ──\n",
    "n_data = len(ohlcv_df)\n",
    "GAUGE_KEYS = ['full', 'short', 'medium', 'long']\n",
    "GAUGE_LABELS = [\n",
    "    f'지정기간({n_data}d)',\n",
    "    f'단기({CFG.gauge_short}d)',\n",
    "    f'중기({CFG.gauge_medium}d)',\n",
    "    f'장기({CFG.gauge_long}d)',\n",
    "]\n",
    "\n",
    "# ── 방향 반전 지표 (값 상승 = 매도 방향인 지표) ──\n",
    "INVERTED_INDICATORS = {'MACD', 'OBV', 'CMF', 'SONAR', 'A/D Line'}\n",
    "\n",
    "\n",
    "def _sig_color(s):\n",
    "    if s == 'buy':     return C_BUY\n",
    "    if s == 'sell':    return C_SELL\n",
    "    if s == 'neutral': return C_NEUTRAL\n",
    "    return C_NA\n",
    "\n",
    "def _sig_kr(s):\n",
    "    return {'buy': '매수', 'sell': '매도', 'neutral': '중립', 'n/a': '-'}.get(s, s)\n",
    "\n",
    "def _pct_str(v):\n",
    "    if v is None or np.isnan(v):\n",
    "        return '-'\n",
    "    return f'{v*100:.0f}%'\n",
    "\n",
    "def _pct_color(v):\n",
    "    \"\"\"백분위 → 색상 (0%=매수/녹, 50%=중립/회, 100%=매도/적)\"\"\"\n",
    "    if v is None or np.isnan(v):\n",
    "        return C_NA\n",
    "    if v <= 0.30:   return C_BUY\n",
    "    elif v >= 0.70: return C_SELL\n",
    "    return C_NEUTRAL\n",
    "\n",
    "def _direction_display(sig):\n",
    "    \"\"\"시그널 맥락 기반 방향 화살표 + 색상\n",
    "    ▲ = 매수 유리 방향 (녹), ▼ = 매도 유리 방향 (적)\n",
    "    \"\"\"\n",
    "    if sig.direction == 'stable' or sig.signal in ('neutral', 'n/a'):\n",
    "        return '-', C_NEUTRAL\n",
    "    value_rising = (sig.direction == 'strengthening')\n",
    "    is_inverted = sig.name in INVERTED_INDICATORS\n",
    "    buy_favorable = value_rising if not is_inverted else not value_rising\n",
    "    arrow = '\\u25b2' if buy_favorable else '\\u25bc'\n",
    "    color = C_BUY if buy_favorable else C_SELL\n",
    "    return arrow, color\n",
    "\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 시그널 그룹핑\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "signal_by_name = {s.name: s for s in signals}\n",
    "grouped = []\n",
    "_used = set()\n",
    "for ck in CAT_ORDER:\n",
    "    clbl, pref = CATEGORY_MAP[ck]\n",
    "    csigs = []\n",
    "    for pn in pref:\n",
    "        if pn in signal_by_name and pn not in _used:\n",
    "            csigs.append(signal_by_name[pn])\n",
    "            _used.add(pn)\n",
    "    for s in signals:\n",
    "        if s.category == ck and s.name not in _used:\n",
    "            csigs.append(s)\n",
    "            _used.add(s.name)\n",
    "    if csigs:\n",
    "        grouped.append((clbl, csigs))\n",
    "remaining = [s for s in signals if s.name not in _used]\n",
    "if remaining:\n",
    "    grouped.append(('기타', remaining))\n",
    "\n",
    "total_indicators = sum(len(sigs) for _, sigs in grouped)\n",
    "total_rows = total_indicators + len(grouped)\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# Figure — 테이블 스타일\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "N_COLS = 8\n",
    "COL_WIDTHS = [0.14, 0.12, 0.08, 0.05, 0.1525, 0.1525, 0.1525, 0.1525]\n",
    "COL_LABELS = ['지표', '현재값', '시그널', '방향'] + GAUGE_LABELS\n",
    "\n",
    "ROW_H = 0.035\n",
    "HDR_H = 0.036\n",
    "CAT_H = 0.028\n",
    "TITLE_H = 0.055\n",
    "SCORE_H = 0.065\n",
    "FOOTER_H = 0.025\n",
    "\n",
    "body_h = total_rows * ROW_H + len(grouped) * CAT_H\n",
    "total_h = TITLE_H + HDR_H + body_h + SCORE_H + FOOTER_H + 0.02\n",
    "\n",
    "fig_w, fig_h_max = A4_PORTRAIT\n",
    "fig_h = min(fig_h_max, max(6.0, total_h * fig_h_max))\n",
    "\n",
    "fig = plt.figure(figsize=(fig_w, fig_h), facecolor=C_BG)\n",
    "ax = fig.add_axes([0.03, 0.02, 0.94, 0.96])\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.axis('off')\n",
    "\n",
    "\n",
    "def _draw_rect(x, y, w, h, fc='none', ec=C_BORDER, lw=0.5):\n",
    "    ax.add_patch(mpatches.FancyBboxPatch(\n",
    "        (x, y), w, h, boxstyle='square,pad=0',\n",
    "        facecolor=fc, edgecolor=ec, linewidth=lw))\n",
    "\n",
    "def _draw_text(x, y, txt, **kw):\n",
    "    defaults = dict(fontsize=6.5, va='center', ha='center',\n",
    "                    transform=ax.transData, clip_on=False)\n",
    "    defaults.update(kw)\n",
    "    ax.text(x, y, txt, **defaults)\n",
    "\n",
    "def _draw_pct_bar(x, y, w, h, pct):\n",
    "    \"\"\"미니 수평 게이지 (셀 내부)\"\"\"\n",
    "    if pct is None or np.isnan(pct):\n",
    "        return\n",
    "    pct = np.clip(pct, 0, 1)\n",
    "    bar_w = w * 0.82\n",
    "    bar_h = h * 0.28\n",
    "    bar_x = x + (w - bar_w) / 2\n",
    "    bar_y = y + h * 0.12\n",
    "\n",
    "    # 배경 바\n",
    "    ax.add_patch(mpatches.Rectangle(\n",
    "        (bar_x, bar_y), bar_w, bar_h,\n",
    "        facecolor='#e8e8e8', edgecolor='#cccccc', linewidth=0.3))\n",
    "    # 채움 바\n",
    "    if pct > 0.005:\n",
    "        fill_color = _pct_color(pct)\n",
    "        ax.add_patch(mpatches.Rectangle(\n",
    "            (bar_x, bar_y), bar_w * pct, bar_h,\n",
    "            facecolor=fill_color, edgecolor='none', alpha=0.35))\n",
    "    # 위치 마커 (세로선)\n",
    "    marker_x = bar_x + bar_w * pct\n",
    "    ax.plot([marker_x, marker_x],\n",
    "            [bar_y - h * 0.02, bar_y + bar_h + h * 0.02],\n",
    "            color=_pct_color(pct), linewidth=1.2, solid_capstyle='round')\n",
    "    # 수치 텍스트 (바 위)\n",
    "    _draw_text(x + w / 2, y + h * 0.72, _pct_str(pct),\n",
    "               fontsize=5.8, fontweight='bold', color=_pct_color(pct))\n",
    "\n",
    "\n",
    "# ── 제목 영역 ──\n",
    "date_str = ohlcv_df.index[-1].strftime('%Y-%m-%d')\n",
    "data_label = '수익률' if is_yield else '가격'\n",
    "score_val = composite['score']\n",
    "\n",
    "title_y = 1.0 - TITLE_H\n",
    "_draw_text(0.5, title_y + TITLE_H * 0.65,\n",
    "           f'{CFG.target}  기술적 시그널 종합',\n",
    "           fontsize=11, fontweight='bold', ha='center', color=C_TITLE)\n",
    "_draw_text(0.5, title_y + TITLE_H * 0.22,\n",
    "           f'{date_str}   |   {data_label}   |   Tier {current_tier}   |   {CFG.data_source}',\n",
    "           fontsize=6.5, ha='center', color='#888888')\n",
    "\n",
    "# ── 헤더 행 (차콜 배경) ──\n",
    "hdr_y = title_y - HDR_H\n",
    "x_pos = 0.0\n",
    "for ci in range(N_COLS):\n",
    "    w = COL_WIDTHS[ci]\n",
    "    _draw_rect(x_pos, hdr_y, w, HDR_H, fc=C_HDR_BG, ec=C_HDR_BG)\n",
    "    _draw_text(x_pos + w/2, hdr_y + HDR_H/2, COL_LABELS[ci],\n",
    "               fontsize=5.8, fontweight='bold', color=C_HDR_FG)\n",
    "    x_pos += w\n",
    "\n",
    "# ── 데이터 행 ──\n",
    "cur_y = hdr_y\n",
    "row_idx = 0\n",
    "\n",
    "for cat_label, cat_sigs in grouped:\n",
    "    # 카테고리 행\n",
    "    cur_y -= CAT_H\n",
    "    _draw_rect(0, cur_y, 1.0, CAT_H, fc=C_CAT_BG, ec=C_BORDER, lw=0.3)\n",
    "    # 좌측 악센트 바\n",
    "    ax.add_patch(mpatches.Rectangle(\n",
    "        (0, cur_y), 0.004, CAT_H, facecolor=C_ACCENT, edgecolor='none'))\n",
    "    _draw_text(0.01 + COL_WIDTHS[0]/2, cur_y + CAT_H/2,\n",
    "               cat_label, fontsize=6.5, fontweight='bold',\n",
    "               color=C_CAT_FG, ha='center')\n",
    "\n",
    "    for sig in cat_sigs:\n",
    "        cur_y -= ROW_H\n",
    "        bg = C_ROW_ODD if row_idx % 2 == 0 else C_ROW_EVEN\n",
    "        _draw_rect(0, cur_y, 1.0, ROW_H, fc=bg, ec=C_BORDER, lw=0.15)\n",
    "\n",
    "        x = 0.0\n",
    "\n",
    "        # Col 0: 지표명\n",
    "        w = COL_WIDTHS[0]\n",
    "        name_str = sig.name\n",
    "        if sig.divergence:\n",
    "            name_str += ' [D]'\n",
    "        _draw_text(x + 0.008, cur_y + ROW_H/2, name_str,\n",
    "                   fontsize=6.5, fontweight='bold', ha='left', color='#1a1a1a')\n",
    "        x += w\n",
    "\n",
    "        # Col 1: 현재값 / 설명\n",
    "        w = COL_WIDTHS[1]\n",
    "        if sig.signal != 'n/a':\n",
    "            val_str = f'{sig.value:.2f}' if not np.isnan(sig.value) else '-'\n",
    "            _draw_text(x + w/2, cur_y + ROW_H*0.62, val_str,\n",
    "                       fontsize=5.8, ha='center', color='#333333')\n",
    "            desc = sig.description[:16] + '..' if len(sig.description) > 18 else sig.description\n",
    "            _draw_text(x + w/2, cur_y + ROW_H*0.28, desc,\n",
    "                       fontsize=4.2, ha='center', color='#999999')\n",
    "        else:\n",
    "            _draw_text(x + w/2, cur_y + ROW_H/2, '-', fontsize=6, color=C_NA)\n",
    "        x += w\n",
    "\n",
    "        # Col 2: 시그널\n",
    "        w = COL_WIDTHS[2]\n",
    "        sc = _sig_color(sig.signal)\n",
    "        sig_txt = _sig_kr(sig.signal)\n",
    "        _draw_text(x + w/2, cur_y + ROW_H/2, sig_txt,\n",
    "                   fontsize=6, fontweight='bold', color=sc)\n",
    "        x += w\n",
    "\n",
    "        # Col 3: 방향 (시그널 맥락 기반)\n",
    "        w = COL_WIDTHS[3]\n",
    "        arrow, arrow_c = _direction_display(sig)\n",
    "        _draw_text(x + w/2, cur_y + ROW_H/2, arrow,\n",
    "                   fontsize=7, fontweight='bold', color=arrow_c)\n",
    "        x += w\n",
    "\n",
    "        # Col 4~7: 백분위 게이지\n",
    "        is_na = (sig.signal == 'n/a')\n",
    "        for gi, gk in enumerate(GAUGE_KEYS):\n",
    "            w = COL_WIDTHS[4 + gi]\n",
    "            gval = sig.rel_gauges.get(gk, 0.5)\n",
    "            if is_na:\n",
    "                _draw_text(x + w/2, cur_y + ROW_H/2, '-',\n",
    "                           fontsize=6, color=C_NA)\n",
    "            else:\n",
    "                _draw_pct_bar(x, cur_y, w, ROW_H, gval)\n",
    "            x += w\n",
    "\n",
    "        row_idx += 1\n",
    "\n",
    "# ── 종합 스코어 영역 ──\n",
    "cur_y -= 0.006\n",
    "score_y = cur_y - SCORE_H\n",
    "\n",
    "_draw_rect(0, score_y, 1.0, SCORE_H, fc='#f5f5f5', ec=C_HDR_BG, lw=0.6)\n",
    "\n",
    "score_str = f'{score_val:+.2f}'\n",
    "if score_val > 0.2:     sc_color = C_BUY\n",
    "elif score_val < -0.2:  sc_color = C_SELL\n",
    "else:                    sc_color = C_NEUTRAL\n",
    "\n",
    "_draw_text(0.02, score_y + SCORE_H*0.58, '종합 스코어',\n",
    "           fontsize=8, fontweight='bold', ha='left', color=C_TITLE)\n",
    "_draw_text(0.22, score_y + SCORE_H*0.58, score_str,\n",
    "           fontsize=13, fontweight='bold', ha='left', color=sc_color)\n",
    "\n",
    "count_parts = [\n",
    "    (f'매수 {composite[\"buy\"]}', C_BUY),\n",
    "    (f'매도 {composite[\"sell\"]}', C_SELL),\n",
    "    (f'중립 {composite[\"neutral\"]}', C_NEUTRAL),\n",
    "]\n",
    "if composite.get('na', 0) > 0:\n",
    "    count_parts.append((f'N/A {composite[\"na\"]}', C_NA))\n",
    "\n",
    "cx = 0.42\n",
    "for ctxt, cc in count_parts:\n",
    "    _draw_text(cx, score_y + SCORE_H*0.58, ctxt,\n",
    "               fontsize=6.5, fontweight='bold', ha='left', color=cc)\n",
    "    cx += 0.12\n",
    "\n",
    "_draw_text(0.02, score_y + SCORE_H*0.20,\n",
    "           f'유효: {composite.get(\"valid\",0)}/{composite.get(\"total\",len(signals))}   |   '\n",
    "           f'{ohlcv_df.index[0].strftime(\"%Y-%m-%d\")} ~ {date_str} ({n_data}d)',\n",
    "           fontsize=5.5, ha='left', color='#999999')\n",
    "\n",
    "# ── 범례 ──\n",
    "footer_y = score_y - FOOTER_H - 0.003\n",
    "_draw_text(0.5, footer_y + FOOTER_H*0.5,\n",
    "           '0%=하위(채권매수) \\u2192 100%=상위(채권매도)   |   '\n",
    "           '\\u25b2 매수유리  \\u25bc 매도유리   |   [D] 다이버전스',\n",
    "           fontsize=4.8, ha='center', color='#aaaaaa', style='italic')\n",
    "\n",
    "# ── 저장 & 표시 ──\n",
    "_all_figs.append((fig, 'signal_dashboard'))\n",
    "plt.show()\n",
    "\n",
    "# ── 텍스트 요약 ──\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"시그널 대시보드: {CFG.target}\")\n",
    "print(f\"종합 스코어: {composite['score']:+.2f}\")\n",
    "print(f\"매수: {composite['buy']} / 매도: {composite['sell']} / 중립: {composite['neutral']}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# ── 백분위 상세 출력 (검증용) ──\n",
    "print(f\"\\n{'─'*60}\")\n",
    "print(f\"백분위 상세 (0%=하위/매수 → 100%=상위/매도):\")\n",
    "print(f\"  {'지표':15s}  {'지정기간':>7s}  {'단기':>7s}  {'중기':>7s}  {'장기':>7s}  시그널\")\n",
    "print(f\"  {'─'*15}  {'─'*7}  {'─'*7}  {'─'*7}  {'─'*7}  {'─'*6}\")\n",
    "for _s in signals:\n",
    "    _g = _s.rel_gauges\n",
    "    _f = lambda k: f\"{_g.get(k, -1)*100:5.1f}%\" if _g.get(k, -1) >= 0 else \"  N/A \"\n",
    "    print(f\"  {_s.name:15s}  {_f('full')}  {_f('short')}  {_f('medium')}  {_f('long')}  {_s.signal}\")\n",
    "print(f\"{'─'*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ══════════════════════════════════════════════════════════════\n",
    "# Cell 6: Excel/이미지 저장\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "today = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "# ── 저장 디렉토리 확인/생성 ──────────────────────────────────\n",
    "try:\n",
    "    CFG.save_dir.mkdir(parents=True, exist_ok=True)\n",
    "except Exception as e:\n",
    "    print(f\"[WARNING] 저장 디렉토리 생성 실패: {e}\")\n",
    "\n",
    "saved_files = []\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# Excel 저장\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "if CFG.save_excel:\n",
    "    excel_path = CFG.save_dir / f\"{CFG.target}_{CFG.data_source}_{today}.xlsx\"\n",
    "    try:\n",
    "        with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
    "\n",
    "            # ── Sheet 1: 지표원시값 ──────────────────────────\n",
    "            if indicators:\n",
    "                ind_df = pd.DataFrame(indicators, index=ohlcv_df.index)\n",
    "                ind_df.index.name = \"Date\"\n",
    "                ind_df.to_excel(writer, sheet_name=\"지표원시값\")\n",
    "            else:\n",
    "                pd.DataFrame({\"info\": [\"지표 데이터 없음\"]}).to_excel(\n",
    "                    writer, sheet_name=\"지표원시값\", index=False\n",
    "                )\n",
    "\n",
    "            # ── Sheet 2: 시그널요약 ──────────────────────────\n",
    "            if signals:\n",
    "                sig_records = []\n",
    "                for s in signals:\n",
    "                    rg = getattr(s, \"rel_gauges\", {})\n",
    "                    rec = {\n",
    "                        \"name\": s.name,\n",
    "                        \"category\": s.category,\n",
    "                        \"value\": s.value,\n",
    "                        \"signal\": s.signal,\n",
    "                        \"description\": s.description,\n",
    "                        \"abs_gauge\": s.abs_gauge,\n",
    "                        \"rel_gauge_short\": rg.get(\"short\", None),\n",
    "                        \"rel_gauge_medium\": rg.get(\"medium\", None),\n",
    "                        \"rel_gauge_long\": rg.get(\"long\", None),\n",
    "                        \"direction\": s.direction,\n",
    "                        \"divergence\": s.divergence,\n",
    "                    }\n",
    "                    sig_records.append(rec)\n",
    "                sig_df = pd.DataFrame(sig_records)\n",
    "                sig_df.to_excel(writer, sheet_name=\"시그널요약\", index=False)\n",
    "            else:\n",
    "                pd.DataFrame({\"info\": [\"시그널 데이터 없음\"]}).to_excel(\n",
    "                    writer, sheet_name=\"시그널요약\", index=False\n",
    "                )\n",
    "\n",
    "            # ── Sheet 3: 종합스코어 ──────────────────────────\n",
    "            comp_row = {\n",
    "                \"score\": composite.get(\"score\", None),\n",
    "                \"buy\": composite.get(\"buy\", 0),\n",
    "                \"sell\": composite.get(\"sell\", 0),\n",
    "                \"neutral\": composite.get(\"neutral\", 0),\n",
    "                \"na\": composite.get(\"na\", 0),\n",
    "                \"total\": composite.get(\"total\", 0),\n",
    "                \"valid\": composite.get(\"valid\", 0),\n",
    "                \"target\": CFG.target,\n",
    "                \"data_source\": CFG.data_source,\n",
    "                \"date\": today,\n",
    "                \"tier\": current_tier,\n",
    "            }\n",
    "            comp_df = pd.DataFrame([comp_row])\n",
    "            comp_df.to_excel(writer, sheet_name=\"종합스코어\", index=False)\n",
    "\n",
    "        saved_files.append((\"Excel\", excel_path))\n",
    "        print(f\"[OK] Excel 저장 완료: {excel_path.name}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Excel 저장 실패: {e}\")\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 이미지 저장 (PNG + PDF)\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "if CFG.save_graphs:\n",
    "    png_count = 0\n",
    "\n",
    "    if _all_figs:\n",
    "        # ── 개별 PNG 저장 ────────────────────────────────────\n",
    "        for fig, name in _all_figs:\n",
    "            try:\n",
    "                png_path = CFG.save_dir / f\"{CFG.target}_{name}_{today}.png\"\n",
    "                fig.savefig(png_path, dpi=150, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "                png_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"[WARNING] PNG 저장 실패 ({name}): {e}\")\n",
    "\n",
    "        if png_count:\n",
    "            saved_files.append((\"PNG\", f\"{png_count}개\"))\n",
    "            print(f\"[OK] PNG 저장 완료: {png_count}개\")\n",
    "\n",
    "        # ── 통합 PDF 저장 ────────────────────────────────────\n",
    "        try:\n",
    "            from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "            pdf_path = CFG.save_dir / f\"{CFG.target}_{CFG.data_source}_{today}_전체.pdf\"\n",
    "            with PdfPages(pdf_path) as pdf:\n",
    "                for fig, name in _all_figs:\n",
    "                    pdf.savefig(fig, bbox_inches=\"tight\", facecolor=\"white\")\n",
    "            saved_files.append((\"PDF\", pdf_path))\n",
    "            print(f\"[OK] PDF 저장 완료: {pdf_path.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[WARNING] PDF 저장 실패: {e}\")\n",
    "    else:\n",
    "        print(\"[INFO] 저장할 그래프가 없습니다 (_all_figs 비어 있음)\")\n",
    "\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "# 저장 요약\n",
    "# ══════════════════════════════════════════════════════════════\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"저장 완료\")\n",
    "print(f\"{'='*60}\")\n",
    "if CFG.save_excel:\n",
    "    print(f\"  Excel: {excel_path}\")\n",
    "if CFG.save_graphs:\n",
    "    print(f\"  이미지: {len(_all_figs)}개 PNG + 1 PDF\")\n",
    "    print(f\"  디렉토리: {CFG.save_dir.resolve()}\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}